{"createdTime":1761588815411,"shownInTree":["notes/math/transitive-property.html","notes/math/quantile.html","notes/math/probability.html","notes/math/variance.html","notes/math/standard-deviation.html","notes/math/range.html","notes/math/quartile.html","notes/math/propositional-logic.html","notes/math/outlier.html","notes/math/associative-property.html","notes/math/ordinal-data.html","notes/math/commutative-property.html","notes/math/nominal-data.html","notes/math/mode.html","notes/math/median.html","notes/math/measure-of-central-tendency.html","notes/math/mean.html","notes/math/manhattan-distance.html","notes/math/least-squares.html","notes/math/first-order-logic.html","notes/math/euclidean-distance.html","notes/math/binary-data.html","notes/ai/turing-test.html","textbooks/artificial-intelligence-a-modern-approach-summary.html","textbooks/computer-organization-and-design-risc-v-edition-summary.html","index.html"],"attachments":["site-lib/html/custom-head-content-content.html","site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/media/favicon.png","site-lib/styles/snippets.css","site-lib/styles/obsidian.css","site-lib/styles/theme.css","site-lib/styles/global-variable-styles.css","site-lib/styles/supported-plugins.css","site-lib/styles/main-styles.css","resources/multiplicationhardware-1.png","resources/multiplierparalleltree.png","resources/divisionhardware-1.png","resources/riscvfloatingpoint.png","resources/riscvdoubleprecision-1.png","resources/ieee754.png","resources/floatingpointadditionhardware-1.png","resources/risc-vdatapath.png","resources/riscvdatapath2-1.png","resources/alutruthtable.png","resources/riscvinstructionformats.png","resources/riscvcontrolunit-1.png","resources/riscvinstructionformatcontrol.png","resources/riscpipeline.png","resources/riscvpipeline2.png","resources/risvpipelinecontrol.png","resources/forwardingalu.png","resources/hazarddetectionunit.png","resources/riscvexceptions.png","resources/utilityofmoney.png","resources/decisionnetwork-1.png","resources/pasted-image-20250708093049.png","resources/highvslowstd.png","resources/pasted-image-20250708171735.png","resources/linearregression.png","site-lib/rss.xml","resources/ringtop.png","resources/crossbarnetwork.png","resources/designpatternsai.png","resources/gates.png","resources/srlatch.png","resources/dlatch.png","resources/dflipflop.png","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff"],"allFiles":["textbooks/computer-organization-and-design-risc-v-edition-summary.html","resources/dflipflop.png","resources/dlatch.png","resources/srlatch.png","resources/gates.png","resources/designpatternsai.png","resources/crossbarnetwork.png","resources/ringtop.png","textbooks/artificial-intelligence-a-modern-approach-summary.html","resources/riscvexceptions.png","resources/hazarddetectionunit.png","resources/forwardingalu.png","resources/risvpipelinecontrol.png","resources/riscvpipeline2.png","resources/riscpipeline.png","resources/riscvinstructionformatcontrol.png","resources/riscvcontrolunit-1.png","resources/riscvdatapath2-1.png","resources/riscvinstructionformats.png","resources/alutruthtable.png","resources/risc-vdatapath.png","resources/floatingpointadditionhardware-1.png","resources/ieee754.png","resources/riscvdoubleprecision-1.png","resources/riscvfloatingpoint.png","index.html","resources/divisionhardware-1.png","resources/multiplierparalleltree.png","resources/multiplicationhardware-1.png","notes/math/propositional-logic.html","notes/math/mean.html","notes/math/probability.html","site-lib/html/custom-head-content-content.html","notes/math/first-order-logic.html","notes/ai/turing-test.html","notes/math/euclidean-distance.html","notes/math/mode.html","notes/math/outlier.html","notes/math/quantile.html","notes/math/quartile.html","notes/math/range.html","notes/math/variance.html","notes/math/standard-deviation.html","notes/math/associative-property.html","notes/math/nominal-data.html","notes/math/transitive-property.html","notes/math/binary-data.html","notes/math/ordinal-data.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/least-squares.html","notes/math/manhattan-distance.html","notes/math/commutative-property.html","site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/media/favicon.png","site-lib/styles/snippets.css","site-lib/styles/obsidian.css","site-lib/styles/theme.css","site-lib/styles/global-variable-styles.css","site-lib/styles/supported-plugins.css","site-lib/styles/main-styles.css"],"webpages":{"notes/math/first-order-logic.html":{"title":"First-Order Logic","icon":"","description":"Author: <a data-href=\"Ernad Mujakic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ernad Mujakic</a>\nDate: 2025-08-29<br>First-order logic (FOL), also known as predicate logic, is a formalism which builds upon <a data-tooltip-position=\"top\" aria-label=\"Propositional Logic\" data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">propositional logic</a> by adding predicates, functions, variables, and quantifiers. The term \"first-order\" refers to the types of entities that can be quantified over. First-order logic only allows for the quantification over variables, while higher-order logics can quantify over predicates or functions.\nS. Russel and P. Norvig,&nbsp;Artificial intelligence: A Modern approach, 4th ed. Prentice Hall, 2021\n<br>Stanford Online, “Logic 7 - First Order Logic | Stanford CS221: AI (Autumn 2021),”&nbsp;YouTube, May 31, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.youtube.com/watch?v=Z-O0Q3_oTJM\" target=\"_self\">https://www.youtube.com/watch?v=Z-O0Q3_oTJM</a> (accessed Aug. 29, 2025)\n<br>“First-order logic,”&nbsp;Wikipedia, Nov. 03, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/First-order_logic\" target=\"_self\">https://en.wikipedia.org/wiki/First-order_logic</a>\n<br>GeeksforGeeks, “FirstOrder Logic in Artificial Intelligence,”&nbsp;GeeksforGeeks, Jun. 03, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/artificial-intelligence/first-order-logic-in-artificial-intelligence/\" target=\"_self\">https://www.geeksforgeeks.org/artificial-intelligence/first-order-logic-in-artificial-intelligence/</a>\n<br>Artificial Intelligence - First-order Logic,”&nbsp;Tutorialspoint.com, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_first_order_logic.htm\" target=\"_self\">https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_first_order_logic.htm</a> (accessed Aug. 29, 2025)\n","aliases":["FOL"],"inlineTags":[],"frontmatterTags":["#logic","#math","#unfinished"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"First-Order Logic","level":1,"id":"First-Order_Logic_0"},{"heading":"Syntax","level":3,"id":"Syntax_0"},{"heading":"Semantics","level":3,"id":"Semantics_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/propositional-logic.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html","pathToRoot":"../..","attachments":[],"createdTime":1756478536137,"modifiedTime":1756492064326,"sourceSize":1427,"sourcePath":"NOTES/Math/First-Order Logic.md","exportPath":"notes/math/first-order-logic.html","showInTree":true,"treeOrder":8,"backlinks":["index.html","notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/standard-deviation.html":{"title":"Standard Deviation","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-10Standard deviation is a <a data-href=\"Measure of Dispersion\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Dispersion</a> that summarizes the amount of variation in a dataset. It represents the average distance between each data point and the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a> of the population.\n<br>\nLow Standard Deviation: Indicates that the data points tend to be very close to the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"62\" to=\"66\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, suggesting consistency and reliability in the dataset. <br>\nHigh Standard Deviation: Implies that data points are more spread out across the <a data-tooltip-position=\"top\" aria-label=\"Range\" data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">range</a>, indicating greater variability and less predictability. <br><img alt=\"HighVsLowSTD.png\" src=\"https://emujakic.github.io/TechKB/resources/highvslowstd.png\" target=\"_self\">\nNon-Negative: The standard deviation can never be negative, since it is an average distance measure, and distance can also never be negative.\n<br>Sensitive to <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outliers</a>: Extreme <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"10\" to=\"18\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a> can have a significant impact on the standard deviation.\nSame Units: The standard deviation is expressed in the same units as the underlying dataset.\nThe standard deviation of a numeric attribute , denoted with , is defined as:For a population, the standard deviation is calculated using:Where:\n<br> represents the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"20\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> of the population. represents the number of observations.\nFor a sample, the standard deviation is calculated using:Where:\n<br> represents the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"20\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> of the sample. represents the number of observations.\n<br>The standard deviation is equal to the square root of the <a data-href=\"Variance\" href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Variance</a> of the same dataset. <a href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"22\" to=\"30\" origin-text=\"Variance\" class=\"internal-link virtual-link-a\">Variance</a> measures the average of the squared differences from the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"88\" to=\"92\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, providing insight into the spread of the data.Other common measures of dispersion include:\n<br><a data-href=\"Interquartile Range\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interquartile Range</a> (IQR): which is the distance covered by the middle 50% of the dataset.\n<br><a data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Range</a>: which is the difference between the maximum and minimum values in a dataset\n<br><a data-tooltip-position=\"top\" aria-label=\"Quartile\" data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quartiles</a>: which are the three values that divide a dataset into four equal parts. J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Standard Deviation Formula, Examples &amp; How to Calculate,”&nbsp;GeeksforGeeks, Jul. 06, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/standard-deviation-formula/\" target=\"_self\">https://www.geeksforgeeks.org/maths/standard-deviation-formula/</a>\n<br>J. Frost, “Standard Deviation: Interpretations and Calculations,”&nbsp;Statistics By Jim, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://statisticsbyjim.com/basics/standard-deviation/\" target=\"_self\">https://statisticsbyjim.com/basics/standard-deviation/</a>\n","aliases":["Standard Deviations"],"inlineTags":[],"frontmatterTags":["#math","#statistics","#unfinished"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Standard Deviation","level":1,"id":"Standard_Deviation_0"},{"heading":"Interpretation","level":3,"id":"Interpretation_0"},{"heading":"Properties","level":3,"id":"Properties_0"},{"heading":"Calculation","level":2,"id":"Calculation_0"},{"heading":"Population Standard Deviation","level":3,"id":"Population_Standard_Deviation_0"},{"heading":"Sample Standard Deviation","level":3,"id":"Sample_Standard_Deviation_0"},{"heading":"Relation to <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Variance.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"12\" to=\"20\" origin-text=\"Variance\" class=\"internal-link virtual-link-a\">Variance</a></span>","level":4,"id":"Relation_to_Variance_0"},{"heading":"Other Common Measures of Dispersion","level":2,"id":"Other_Common_Measures_of_Dispersion_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/range.html#_0","notes/math/outlier.html#_0","notes/math/outlier.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/variance.html#_0","notes/math/variance.html#_0","notes/math/variance.html#_0","notes/math/mean.html#_0",".html","notes/math/range.html#_0","notes/math/quartile.html#_0"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/resources/highvslowstd.png","fullURL":"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html","pathToRoot":"../..","attachments":["resources/highvslowstd.png"],"createdTime":1752158879614,"modifiedTime":1756435032494,"sourceSize":2852,"sourcePath":"NOTES/Math/Standard Deviation.md","exportPath":"notes/math/standard-deviation.html","showInTree":true,"treeOrder":23,"backlinks":["notes/math/outlier.html","notes/math/variance.html"],"type":"markdown"},"notes/math/commutative-property.html":{"title":"Commutative Property","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-20The commutative property states that the sums and products of values is unaffected by the order those values come in. It allows you to transform mathematical expressions into equivalent forms without altering its value.The commutative property applies to addition. For any numbers , and :The commutative property applies to multiplication. For any numbers , and :Operations such as subtraction or division are not commutative:\nSubtraction: , subtraction is actually <a data-href=\"Anti-Commutative\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Anti-Commutative</a>, meaning, Division: Exponentiation: Matrix Multiplication: For matrices , , and with compatible dimensions: The anti-commutative property refers to specific operations where switching the order of arguments negates the result of the expression.Subtraction is an anti-commutative operation. Meaning, for any 2 values and :<br>Some <a data-href=\"Logical Connectives\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logical Connectives</a> are commutative, allowing for the rearrangement of variables without changing the truth value of the logical expression.The commutative property applies to conjunction (AND), for any variables and :The commutative property applies to disjunction (OR), for any variables and :<br>In set theory, the commutative property refers to how the <a data-href=\"Union\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Union</a> and <a data-href=\"Intersection\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Intersection</a> of sets are unaffected by the order of the sets they are applied to.for any sets , and :for any sets , and :<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/associative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"24\" origin-text=\"associative property\" class=\"internal-link virtual-link-a\">associative property</a> states that the sum or product of any group of values is not affected by how the values are grouped.\nAddition: Multiplication: <br>“Commutative property,”&nbsp;Wikipedia, Dec. 04, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Commutative_property\" target=\"_self\">https://en.wikipedia.org/wiki/Commutative_property</a>\n<br>GeeksforGeeks, “Commutative Property Definition | Commutative Law and Examples,”&nbsp;GeeksforGeeks, Dec. 28, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/commutative-property/\" target=\"_self\">https://www.geeksforgeeks.org/maths/commutative-property/</a> (accessed Jul. 20, 2025).\n","aliases":["Commutative"],"inlineTags":[],"frontmatterTags":["#math","#algebra"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Commutative Property","level":1,"id":"Commutative_Property_0"},{"heading":"Commutative Operations","level":3,"id":"Commutative_Operations_0"},{"heading":"Addition","level":4,"id":"Addition_0"},{"heading":"Multiplication","level":4,"id":"Multiplication_0"},{"heading":"Non-Commutative Operations","level":3,"id":"Non-Commutative_Operations_0"},{"heading":"<a data-href=\"Anti-Commutative Property\" href=\"Anti-Commutative Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Anti-Commutative Property</a>","level":2,"id":"[[Anti-Commutative_Property]]_0"},{"heading":"Subtraction","level":3,"id":"Subtraction_0"},{"heading":"Logical Operations","level":2,"id":"Logical_Operations_0"},{"heading":"<a data-href=\"Conjunction\" href=\"Conjunction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Conjunction</a>","level":3,"id":"[[Conjunction]]_0"},{"heading":"<a data-href=\"Disjunction\" href=\"Disjunction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Disjunction</a>","level":3,"id":"[[Disjunction]]_0"},{"heading":"<a data-href=\"Set Theory\" href=\"Set Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Set Theory</a>","level":2,"id":"[[Set_Theory]]_0"},{"heading":"Union","level":3,"id":"Union_0"},{"heading":"Intersection","level":3,"id":"Intersection_0"},{"heading":"<a data-href=\"Associative Property\" href=\"Associative Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Associative Property</a>","level":2,"id":"[[Associative_Property]]_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html",".html",".html",".html",".html",".html","notes/math/associative-property.html#_0","notes/math/associative-property.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/commutative-property.html","pathToRoot":"../..","attachments":[],"createdTime":1753041273100,"modifiedTime":1754247519350,"sourceSize":2732,"sourcePath":"NOTES/Math/Commutative Property.md","exportPath":"notes/math/commutative-property.html","showInTree":true,"treeOrder":6,"backlinks":["notes/math/associative-property.html","notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/variance.html":{"title":"Variance","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-10Variance is a <a data-href=\"Measure of Dispersion\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Dispersion</a> that summarizes the spread of values in a dataset from the average. It represents the average squared distance from each data point to the <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> of the dataset.\n<br>\nLow Variance: Indicates that the data points tend to be very close to the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"62\" to=\"66\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, suggesting consistency and reliability in the dataset. <br>\nHigh Variance: Implies that data points are more spread out across the <a data-tooltip-position=\"top\" aria-label=\"Range\" data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">range</a>, indicating greater variability and less predictability. <br><img alt=\"HighVsLowSTD.png\" src=\"https://emujakic.github.io/TechKB/resources/highvslowstd.png\" target=\"_self\">\nNon-Negative: The variance can never be negative, since it is an average distance measure and distance can also never be negative.\nThe variance of a numeric attribute is defined as:For a population, the variance is calculated using:Where: represents the population variance.\n<br> represents the <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> of the population. represents the number of observations.\nFor a sample, the variance is calculated using:Where: represents the sample variance.\n<br> represents the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"20\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> of the sample. represents the number of observations.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"22\" origin-text=\"standard deviation\" class=\"internal-link virtual-link-a\">standard deviation</a> is equal to the square root of the variance of the same dataset. Standard deviation is expressed in the same units as the original data, while variance is expressed in squared units.<br>The expected value, or <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"23\" to=\"27\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, of a random variable , denoted , is a <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">measure of central tendency</a> that represents the average outcome of a random variable. Intuitively, it is the average of the outcomes of many samples from .<br>The variance of a random variable measures the dispersion of a random variable around its expected value . It is defined as the expected value of the squared differences from the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"74\" to=\"78\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>:Where: is the expected value of .\n<br>Covariance is vital in understanding the relationships between random variables in <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probability</a> distributions. The value of the covariance between two variables represents the direction of the linear relationship between them.<br>A <a data-href=\"Covariance Matrix\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Covariance Matrix</a> is a square matrix containing the covariance between multiple variables.The formula for calculating the covariance is:Where:\n<br> and represent the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"15\" to=\"19\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> of and respectively. represents the number of samples in the dataset. Positive Covariance: Indicates that as increases, increases.\nNegative Covariance: Indicates that as increases, decreases.\nZero/Near-Zero Covariance: Indicates no linear relationship between and .\nCovariance is a key step in calculating correlation, which normalizes the covariance value to a standard scale. Correlation is useful for assessing the strength and direction of the relationship between two variables.<br>A dataset is homoscedastic if the variance of the residuals (errors) is constant across the <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"92\" to=\"97\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of the independent variable(s). Conversely, if the variance changes as a function of the independent variable, the dataset is heteroscedastic.<br>Homoscedasticity is an important concept in <a data-href=\"Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Regression</a> analysis as it is an essential assumption for many regression models such as <a data-href=\"Linear Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Linear Regression</a> based on the <a data-href=\"Least Squares\" href=\"https://emujakic.github.io/TechKB/notes/math/least-squares.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Least Squares</a> method.\nResiduals vs. Fitted Values Plot: A scatter plot of residuals against the predicted values. A random scatter indicates that the dataset is homoscedastic.\n<br><a data-href=\"Breusch-Pagan Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Breusch-Pagan Test</a>: Creates an initial regression model, then fits a new model on the squared residuals of original model against the independent variable. If the corresponding <a data-href=\"P-Value\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">P-Value</a> from the <a data-href=\"Chi-Squared Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Chi-Squared Test</a> is less than some chosen significance level, then heteroscedasticity is assumed.\n<br><a data-href=\"White Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">White Test</a>: A more general test which can detect non-linear heteroscedastic relationships. The methodology is similar to that of the Breusch-Pagan test, though the White test involves regressing the squared residuals against the original independent variables, their squares, and their cross-products. <br><a data-href=\"Weighted Least Squares\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Weighted Least Squares</a>: Weighs the effect of observations on the regression line based on its estimated variance.\n<br>Transformations: Applying a <a data-href=\"Log Transformation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Log Transformation</a> or <a data-href=\"Box-Cox Transformation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Box-Cox Transformation</a> can potentially reduce or eliminate heteroscedasticity entirely. J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Variance,”&nbsp;GeeksforGeeks, Apr. 27, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/variance/\" target=\"_self\">https://www.geeksforgeeks.org/maths/variance/</a>\n<br>Wikipedia Contributors, “Variance,”&nbsp;Wikipedia, Jan. 08, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Variance\" target=\"_self\">https://en.wikipedia.org/wiki/Variance</a>\n<br>J. Starmer, “Covariance, Clearly Explained!!!,”&nbsp;YouTube. Jul. 29, 2019. Available: <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.youtube.com/watch?v=qtaqvPAeEJY\" target=\"_self\">https://www.youtube.com/watch?v=qtaqvPAeEJY</a>\n<br>GeeksforGeeks, “Covariance and Correlation,”&nbsp;GeeksforGeeks, Jun. 25, 2018. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/engineering-mathematics/mathematics-covariance-and-correlation/\" target=\"_self\">https://www.geeksforgeeks.org/engineering-mathematics/mathematics-covariance-and-correlation/</a> (accessed Jul. 16, 2025).\n<br>Z. Bobbit, “The Breusch-Pagan Test: Definition &amp; Example,”&nbsp;Statology, Dec. 31, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.statology.org/breusch-pagan-test/\" target=\"_self\">https://www.statology.org/breusch-pagan-test/</a>\n<br>J. Waples, “Heteroscedasticity: A Full Guide to Unequal Variance,”&nbsp;Datacamp.com, Dec. 10, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.datacamp.com/tutorial/heteroscedasticity\" target=\"_self\">https://www.datacamp.com/tutorial/heteroscedasticity</a>\n","aliases":["Variances"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Variance","level":1,"id":"Variance_0"},{"heading":"Interpretation","level":3,"id":"Interpretation_0"},{"heading":"Properties","level":3,"id":"Properties_0"},{"heading":"Calculation","level":2,"id":"Calculation_0"},{"heading":"Population Variance","level":3,"id":"Population_Variance_0"},{"heading":"Sample Variance","level":3,"id":"Sample_Variance_0"},{"heading":"Relation to <a data-href=\"Standard Deviation\" href=\"Standard Deviation\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Standard Deviation</a>","level":4,"id":"Relation_to_[[Standard_Deviation]]_0"},{"heading":"<a data-href=\"Expected Value\" href=\"Expected Value\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Expected Value</a>","level":2,"id":"[[Expected_Value]]_0"},{"heading":"Variance of Random Variables","level":3,"id":"Variance_of_Random_Variables_0"},{"heading":"<a data-href=\"Covariance\" href=\"Covariance\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Covariance</a>","level":2,"id":"[[Covariance]]_0"},{"heading":"Formula","level":3,"id":"Formula_0"},{"heading":"Interpretation","level":3,"id":"Interpretation_1"},{"heading":"<a data-href=\"Correlation\" href=\"Correlation\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Correlation</a>","level":3,"id":"[[Correlation]]_0"},{"heading":"<a data-href=\"Homoscedasticity\" href=\"Homoscedasticity\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Homoscedasticity</a> and <a data-href=\"Heteroscedasticity\" href=\"Heteroscedasticity\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Heteroscedasticity</a>","level":2,"id":"[[Homoscedasticity]]_and_[[Heteroscedasticity]]_0"},{"heading":"Regression Analysis","level":3,"id":"Regression_Analysis_0"},{"heading":"Statistical Tests","level":3,"id":"Statistical_Tests_0"},{"heading":"Addressing Heteroscedasticity","level":3,"id":"Addressing_Heteroscedasticity_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/range.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/standard-deviation.html#_0","notes/math/standard-deviation.html#_0",".html","notes/math/mean.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/mean.html#_0",".html","notes/math/probability.html#_0",".html","notes/math/mean.html#_0",".html",".html",".html","notes/math/range.html#_0",".html",".html","notes/math/least-squares.html#_0",".html",".html",".html",".html",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/resources/highvslowstd.png","fullURL":"https://emujakic.github.io/TechKB/notes/math/variance.html","pathToRoot":"../..","attachments":["resources/highvslowstd.png"],"createdTime":1752165687104,"modifiedTime":1756435151010,"sourceSize":6067,"sourcePath":"NOTES/Math/Variance.md","exportPath":"notes/math/variance.html","showInTree":true,"treeOrder":25,"backlinks":["notes/math/least-squares.html","notes/math/outlier.html","notes/math/standard-deviation.html"],"type":"markdown"},"notes/math/transitive-property.html":{"title":"Transitive Property","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-25If a relation is transitive then for all possible elements , and , if that relation holds for and , and that same relation holds between and , then that relation must hold between and .Where: is some relation such as equality or inequality. Equality: If and then .\nInequality: If and then .\nSet Inclusion: If and then .\nImplication: If and then .\nInheritance: If inherits from and inherits from then inherits from . Mathematics: Used extensively in algebra, geometry, and set theory to establish relationships between numbers, variables, or sets.\nComputer Science: Used in graph theory algorithms like <a data-href=\"Warshall's Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Warshall's Algorithm</a> which is used to determine the <a data-href=\"Transitive Closure\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transitive Closure</a> of a directed graph. The <a data-href=\"Transitive Closure\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transitive Closure</a> of a directed graph represents which vertices are reachable from others. The <a data-href=\"Transitive Reduction\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transitive Reduction</a> of a directed graph is the smallest reduction that has the same reachability relation as the original graph.\nLogic: The transitive property is a fundamental property in proofs and reasoning, allowing for the derivation of conclusions based on established relationships.\nThe reflexive property states that any value or expression is equal to itself. The equality relation is an example of a reflexive operation, since all real numbers or variables are equal to themselves.A relation is symmetric if for all possible elements and , if is related to , then is related to . Equality is an example of a symmetric relation.<br>An equivalence relation is a relation that is reflexive, symmetric, and transitive. Equivalence relations can group elements of a set into distinct categories called <a data-href=\"Equivalence Classes\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Equivalence Classes</a>, which are disjoint subsets containing elements that are equivalent to one another.<br>A partial order on a set is a binary relation that is reflexive, antisymmetric, and transitive. It is a way to order elements in a set where not all pairs of elements need to be comparable. Partial orders are visualized using a <a data-href=\"Hasse Diagram\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hasse Diagram</a>.<br>Preorder is a binary relation defined on a set that is both reflexive and transitive. It is a generalization of partial orders in the sense that it does not require antisymmetry. Preorders are commonly applied in <a data-href=\"Decision Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Theory</a> to model preferences, or in <a data-href=\"Game Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Game Theory</a> to compare strategies.\nA binary relation is intransitive if there exists three values where transitivity does not hold.\nAntitransitivity is a stronger property which holds if for any three values, transitivity never holds. <br>GeeksforGeeks, “Transitive Property,”&nbsp;GeeksforGeeks, Mar. 07, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/transitive-property/\" target=\"_self\">https://www.geeksforgeeks.org/maths/transitive-property/</a> (accessed Jul. 25, 2025)\n<br>“Transitive relation,”&nbsp;Wikipedia, Jan. 29, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Transitive_relation\" target=\"_self\">https://en.wikipedia.org/wiki/Transitive_relation</a>\n<br>GeeksforGeeks, “Equivalence Relations,”&nbsp;GeeksforGeeks, Nov. 09, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/equivalence-relations/\" target=\"_self\">https://www.geeksforgeeks.org/maths/equivalence-relations/</a>\n<br>“Intransitivity,”&nbsp;Wikipedia, Mar. 07, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Intransitivity\" target=\"_self\">https://en.wikipedia.org/wiki/Intransitivity</a>\n","aliases":["Transitivity","Transitive"],"inlineTags":[],"frontmatterTags":["#math"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Transitive Property","level":1,"id":"Transitive_Property_0"},{"heading":"Relations","level":3,"id":"Relations_0"},{"heading":"Applications","level":3,"id":"Applications_0"},{"heading":"Related Properties","level":2,"id":"Related_Properties_0"},{"heading":"<a data-href=\"Reflexive Property\" href=\"Reflexive Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Reflexive Property</a>","level":3,"id":"[[Reflexive_Property]]_0"},{"heading":"<a data-href=\"Symmetric Property\" href=\"Symmetric Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Symmetric Property</a>","level":3,"id":"[[Symmetric_Property]]_0"},{"heading":"<a data-href=\"Equivalence Relation\" href=\"Equivalence Relation\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Equivalence Relation</a>","level":3,"id":"[[Equivalence_Relation]]_0"},{"heading":"<a data-href=\"Preorder\" href=\"Preorder\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Preorder</a> &amp; <a data-href=\"Partial Order\" href=\"Partial Order\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Partial Order</a>","level":3,"id":"[[Preorder]]_&_[[Partial_Order]]_0"},{"heading":"Intransitivity &amp; Antitransitivity","level":3,"id":"Intransitivity_&_Antitransitivity_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/transitive-property.html","pathToRoot":"../..","attachments":[],"createdTime":1753469739589,"modifiedTime":1755694339571,"sourceSize":3732,"sourcePath":"NOTES/Math/Transitive Property.md","exportPath":"notes/math/transitive-property.html","showInTree":true,"treeOrder":24,"backlinks":["notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/probability.html":{"title":"Probability","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-02Probability is a branch of mathematics that deals with the analysis of events and their likelihood of occurring. The probability of an event, written is a number between 0 and 1, with 0 representing impossible and 1 representing certainty. Probability theory is a framework for making inferences of events that have elements of uncertainty or randomness within them or their outcomes. Random Experiment - any process or action that yields uncertain outcomes.Sample Space - commonly denoted as , is the set of all possible outcomes of a random experiment.Event - a subset of the sample space, representing specific outcomes.Power Set: The set of all possible subsets of a sample space, including the empty set or .The probability of an event is calculated by dividing the number of favorable outcomes by the total size of the sample space:Joint probability is the probability of 2 events happening simultaneously. If 2 events are independent, then their joint probability is:If 2 events are mutually exclusive, then the probability of one or the other occurring is equal to the sum of their probabilities:If 2 events aren't necessarily mutually exclusive, then you simply subtract their intersection in order to prevent counting the values in their intersection twice:The probability of one event occurring, given that another has already occurred, denoted as (the probability of A given B), is:Bayes' Theorem states that:\nNon-Negativity: The probability of an event can never be negative: Normalization: The probability of an entire sample space is always 1: Countable Additivity: The probability of any countable sequence of disjoint (mutually exclusive) events, is equal to the sum of the probabilities of the individual events: Complement Rule: The complement of is denoted as or and is equal to: Mutual Exclusivity: If events A and B are mutually exclusive, that is they can never occur simultaneously, then: Empty Set: The probability of the empty set is always 0: <a data-href=\"Law of Total Probability\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Law of Total Probability</a>: If events are mutually exclusive and form a partition of the sample space, and is any event, the law of total probability states: <br><a data-href=\"Central Limit Theorem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Central Limit Theorem</a>: States that if we take random samples from any population, the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a> of those samples will form a normal distribution as the sample size gets sufficiently large.\n<br><a data-href=\"Law of Large Numbers\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Law of Large Numbers</a>: States that the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"18\" to=\"22\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> of the outcomes obtained from a large number of independent samples will converge to the expected value of the underlying probability distribution.\nThe factorial of a non-negative integer , denoted , is the product of all positive integers less than or equal to :\nA permutation of a set is a possible arrangement of its elements, where the order of the elements matters. The number of possible permutations of elements from a set with total elements is given by:\nA combination of a set is a selection of its elements where the order does not matter. The number of combinations of objects from a set with total elements is given by:\nA random variable is a formalization that assigns a numerical value to the outcome of a random event or experiment. Random variables can be classified into two main types:\nDiscrete random variables take on a countable number of distinct values.\n<br>Continuous random variables take on a infinite number of values within a <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"46\" to=\"51\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a>.\nRandom variables are typically denoted by capital letters. For example, the set can represent the random variables 'heads' and 'tails' in a coin flip experiment. Their values are represented with their corresponding lowercase letter.A probability distribution is a mathematical function which describes the likelihood of different outcomes for the domain of a random variable. The probability of each outcome is between 0 and 1 (inclusive), and the sum of probabilities of each outcome must sum to 1.Discrete probability distributions describe the probability of each possible value in the domain of a discrete random variable.<br>The <a data-href=\"Probability Mass Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Mass Function</a> (PMF) gives the probability of each possible value of a random variable :The sum of all outcomes must sum to 1:Common Discrete Distributions:\n<br><a data-href=\"Binomial Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Binomial Distribution</a> - Models the number of successes in a fixed amount of independent Bernoulli trials.\n<br><a data-href=\"Bernoulli Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bernoulli Distribution</a> - Models the distribution of a random variable with two possible outcomes.\n<br><a data-href=\"Poisson Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Poisson Distribution</a> - Models the probability of a number of events occurring in a fixed interval given a constant <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"95\" to=\"99\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> rate .\n<br>Continuous probability distributions describe the probability of a continuous random variable. These distributions are characterized by a <a data-href=\"Probability Density Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Density Function</a> (PDF).<br>The probability density function describes the likelihood of a random variable taking on a value in a specific <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"111\" to=\"116\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a>:where is the PDF and must satisfy:Common Continuous Distributions:\n<br><a data-href=\"Normal Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Normal Distribution</a> - Also called the Gaussian distribution, represents a bell curve that is symmetric around the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"95\" to=\"99\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>.\n<br><a data-href=\"Exponential Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Exponential Distribution</a> - Skewed to the right, often used to model the time or space between events in a <a data-href=\"Poisson Process\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Poisson Process</a>.\n<br><a data-href=\"Uniform Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Uniform Distribution</a> - Rectangle shape, indicating that all outcomes are equally likely.\n<br>The expected value, or <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"23\" to=\"27\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, of a random variable , denoted , is a <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">measure of central tendency</a> that represents the average outcome of a random variable. This concept is crucial in various fields, including artificial intelligence, especially in the context of stochastic (random) task environments, where uncertainty plays a significant role.For discrete probability distributions, the expected value is defined as:<br>Where is the <a data-href=\"Probability Mass Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Mass Function</a>.For continuous probability distributions, the expected value is defined as:<br>Where is the <a data-href=\"Probability Density Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Density Function</a>.Probability is the foundation of many Machine Learning algorithms such as:\n<br><a data-href=\"Naïve Bayes Classifier\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Naïve Bayes Classifier</a> - a classification model based on Bayes' theorem with strong assumptions about feature independence.\n<br><a data-href=\"Hidden Markov Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hidden Markov Model</a> - A statistical model that represents a system which is assumed to be a <a data-href=\"Markov Process\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Process</a>.\nDecision theory utilizes probability to make rational decisions under uncertainty. Relevant subject include:\n<br><a data-href=\"Utility Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Utility Function</a> - Assigning subjective desirability to outcomes.\n<br><a data-href=\"Markov Decision Process\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Decision Process</a> - A framework for modeling sequential decision-making with stochastic outcomes.\nA Bayesian Network is a probabilistic model implemented as a directed acyclic graph that represents a set of random variables and their conditional dependencies, as well as a set of conditional probability distribution tables.Game theory is a mathematical framework for modelling strategic interactions in a multi-agent interdependent environment. Probability is crucial for game theory, where agents face uncertainty over the actions of other players as well as the state of the game.<br>A Markov process is a mathematical model which models a stochastic environment that satisfies the <a data-href=\"Markov Property\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Property</a>. The Markov property states that the future state depends only on the present state and not past states. Markov processes have transition probabilities between states, quantifying the chance of moving from one state to another.<br>Bayesian statistics is subfield of <a data-href=\"Statistics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Statistics</a> that uses Bayes' theorem to update the probability of a hypothesis as new evidence becomes available. Bayesian methods are widely used in classification, regression, and decision-making algorithms.\nPeter. R. Norvig, Artificial Intelligence: A Modern Approach, Global Edition. 2021.\n<br>Wikipedia contributors, “Probability theory,” Wikipedia, Apr. 23, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Probability_theory\" target=\"_self\">https://en.wikipedia.org/wiki/Probability_theory</a>\n<br>Wikipedia Contributors, “Probability axioms,”&nbsp;Wikipedia, Dec. 05, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Probability_axioms\" target=\"_self\">https://en.wikipedia.org/wiki/Probability_axioms</a>\n<br>J. Soch, “Kolmogorov axioms of probability,”&nbsp;The Book of Statistical Proofs, Jul. 30, 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://statproofbook.github.io/D/prob-ax.html\" target=\"_self\">https://statproofbook.github.io/D/prob-ax.html</a> (accessed Mar. 16, 2025)\n<br>Wikipedia Contributors, “Factorial,”&nbsp;Wikipedia, Oct. 18, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Factorial\" target=\"_self\">https://en.wikipedia.org/wiki/Factorial</a>\n<br>Wikipedia Contributors, “Permutation,”&nbsp;Wikipedia, Sep. 22, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Permutation\" target=\"_self\">https://en.wikipedia.org/wiki/Permutation</a>\n<br>“Bayesian statistics,”&nbsp;Wikipedia, May 29, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Bayesian_statistics\" target=\"_self\">https://en.wikipedia.org/wiki/Bayesian_statistics</a>\n","aliases":["Probabilities"],"inlineTags":[],"frontmatterTags":["#AI","#math","#statistics","#probability"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Probability","level":1,"id":"Probability_0"},{"heading":"Basic Definitions","level":2,"id":"Basic_Definitions_0"},{"heading":"Mathematics","level":2,"id":"Mathematics_0"},{"heading":"Joint Probability","level":3,"id":"Joint_Probability_0"},{"heading":"Conditional Probabilities","level":3,"id":"Conditional_Probabilities_0"},{"heading":"<a data-href=\"Bayes' Theorem\" href=\"Bayes' Theorem\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Bayes' Theorem</a>","level":4,"id":"[[Bayes'_Theorem]]_0"},{"heading":"Axioms of Probability","level":2,"id":"Axioms_of_Probability_0"},{"heading":"<a data-href=\"Kolmogorov's Axioms\" href=\"Kolmogorov's Axioms\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Kolmogorov's Axioms</a>","level":3,"id":"[[Kolmogorov's_Axioms]]_0"},{"heading":"Properties of Probability","level":3,"id":"Properties_of_Probability_0"},{"heading":"<a data-href=\"Counting Techniques\" href=\"Counting Techniques\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Counting Techniques</a>","level":2,"id":"[[Counting_Techniques]]_0"},{"heading":"<a data-href=\"Factorial\" href=\"Factorial\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Factorial</a>","level":3,"id":"[[Factorial]]_0"},{"heading":"<a data-href=\"Permutation\" href=\"Permutation\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Permutation</a>","level":3,"id":"[[Permutation]]_0"},{"heading":"<a data-href=\"Combination\" href=\"Combination\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Combination</a>","level":3,"id":"[[Combination]]_0"},{"heading":"<a data-href=\"Random Variable\" href=\"Random Variable\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Random Variable</a>","level":2,"id":"[[Random_Variable]]_0"},{"heading":"<a data-href=\"Probability Distribution\" href=\"Probability Distribution\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Probability Distribution</a>","level":2,"id":"[[Probability_Distribution]]_0"},{"heading":"1. Discrete Probability Distributions","level":4,"id":"1._[[Discrete_Probability_Distributions]]_0"},{"heading":"2. Continuous Probability Distributions","level":4,"id":"2._[[Continuous_Probability_Distributions]]_0"},{"heading":"<a data-href=\"Expected Value\" href=\"Expected Value\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Expected Value</a>","level":2,"id":"[[Expected_Value]]_0"},{"heading":"Discrete Distributions","level":3,"id":"Discrete_Distributions_0"},{"heading":"Continuous Distributions","level":3,"id":"Continuous_Distributions_0"},{"heading":"Applications","level":2,"id":"Applications_0"},{"heading":"<a data-href=\"Machine Learning\" href=\"Machine Learning\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Machine Learning</a>","level":3,"id":"[[Machine_Learning]]_0"},{"heading":"<a data-href=\"Decision Theory\" href=\"Decision Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Decision Theory</a>","level":3,"id":"[[Decision_Theory]]_0"},{"heading":"<a data-href=\"Bayesian Network\" href=\"Bayesian Network\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Bayesian Network</a>","level":3,"id":"[[Bayesian_Network]]_0"},{"heading":"<a data-href=\"Game Theory\" href=\"Game Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Game Theory</a>","level":3,"id":"[[Game_Theory]]_0"},{"heading":"Advanced Topics","level":2,"id":"Advanced_Topics_0"},{"heading":"<a data-href=\"Markov Process\" href=\"Markov Process\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Markov Process</a>","level":3,"id":"[[Markov_Process]]_0"},{"heading":"<a data-href=\"Bayesian Statistics\" href=\"Bayesian Statistics\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Bayesian Statistics</a>","level":3,"id":"[[Bayesian_Statistics]]_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html",".html","notes/math/mean.html#_0",".html","notes/math/mean.html#_0",".html",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html","notes/math/mean.html#_0",".html",".html","notes/math/range.html#_0",".html","notes/math/mean.html#_0",".html",".html",".html",".html","notes/math/mean.html#_0","notes/math/measure-of-central-tendency.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/probability.html","pathToRoot":"../..","attachments":[],"createdTime":1751495555242,"modifiedTime":1756912870248,"sourceSize":10595,"sourcePath":"NOTES/Math/Probability.md","exportPath":"notes/math/probability.html","showInTree":true,"treeOrder":18,"backlinks":["index.html","notes/math/binary-data.html","notes/math/mean.html","notes/math/variance.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/range.html":{"title":"Range","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-15The range is a <a data-href=\"Measure of Dispersion\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Dispersion</a> that represents the difference between the smallest and largest value in a dataset. The range is calculated as:\nEasy to compute: Very easy value to calculate even by hand.\nIntuitive: Illustrates the spread of the data by a simple value that is in the same scale as the underlying dataset making it easy to understand. <br>Sensitive to <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outliers</a>: The range, in the worst case, can be entirely determined by two <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"66\" to=\"74\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a> that do not accurately represent the underlying dataset, making the range a misleading metric in such a case.\nVague: Does not provide much information regarding the distribution of a population, making it very uninformative. <br><a data-href=\"Interquartile Range\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interquartile Range</a>: The IQR of a dataset is the difference between the first <a data-tooltip-position=\"top\" aria-label=\"Quartile\" data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">quartile</a> , and the third <a href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"24\" origin-text=\"quartile\" class=\"internal-link virtual-link-a\">quartile</a> . It provides the spread of the middle 50% of the data.\n<br><a data-href=\"Midrange\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Midrange</a>: The midrange of a dataset is the <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> of the maximum and minimum values. It is calculated as: J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Range in Statistics,”&nbsp;GeeksforGeeks, Oct. 08, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/range-in-statistics/\" target=\"_self\">https://www.geeksforgeeks.org/maths/range-in-statistics/</a>\n","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Range","level":1,"id":"Range_0"},{"heading":"Advantages","level":3,"id":"Advantages_0"},{"heading":"Disadvantages","level":3,"id":"Disadvantages_0"},{"heading":"Types of Ranges","level":3,"id":"Types_of_Ranges_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/outlier.html#_0","notes/math/outlier.html#_0",".html","notes/math/quartile.html#_0","notes/math/quartile.html#_0",".html","notes/math/mean.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/range.html","pathToRoot":"../..","attachments":[],"createdTime":1752606554931,"modifiedTime":1756435173717,"sourceSize":1544,"sourcePath":"NOTES/Math/Range.md","exportPath":"notes/math/range.html","showInTree":true,"treeOrder":22,"backlinks":["notes/math/euclidean-distance.html","notes/math/manhattan-distance.html","notes/math/mean.html","notes/math/outlier.html","notes/math/standard-deviation.html","notes/math/variance.html"],"type":"markdown"},"notes/math/quartile.html":{"title":"Quartile","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-07Quartiles are a type of <a data-href=\"Quantile\" href=\"https://emujakic.github.io/TechKB/notes/math/quantile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quantile</a> that divide an ordered dataset into 4 equal parts. The quartiles of a dataset are three values, where each value represents a certain <a data-href=\"Percentile\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Percentile</a> of the data. Quartiles are a <a data-href=\"Measure of Dispersion\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Dispersion</a>, meaning it assesses the spread of a population.\n<br>First Quartile (Q1): The 25th percentile, meaning that 25% of the data falls below the first quartile. It can be thought of as the <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a> of the lower half of the data.\n<br>Second Quartile (Q2): The 50th percentile, or the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"31\" to=\"37\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> of the dataset. 50% of the data falls below the second quartile.\nThird Quartile (Q3): The 75th percentile, 75% of the data falls below the third quartile. It can be thought of as the median of the upper half of the dataset.\nThe five-number summary is a set of five values that describe the distribution of a dataset or population and consists of the following:\nMinimum: The smallest value in the dataset.\nFirst Quartile (Q1): The 25th percentile.\n<br><a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"6\" origin-text=\"Median\" class=\"internal-link virtual-link-a\">Median</a> (Q2): The 50th percentile.\nThird Quartile (Q3): The 75th percentile.\nMaximum: The largest value in the dataset.<br>\nThe five-number summary can be visualized using a <a data-href=\"Boxplot\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Boxplot</a> and is useful for identifying potential <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outliers</a> in a population.\nTo calculate the quartiles of a dataset, follow these steps:\nSort the data, typically in ascending order.\n<br>Find the median (Q2), which divides the dataset in half. If there’s an odd number of data points, exclude the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"90\" to=\"96\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a>; if even, include it in both halves.\nFind the first quartile, which is the median of the lower half of the dataset.\nFind the third quartile, which is the median of the upper half of the dataset.\n<br>The Interquartile <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"18\" to=\"23\" origin-text=\"Range\" class=\"internal-link virtual-link-a\">Range</a> (IQR) is a measure of statistical dispersion that represents the range within which the central 50% of the data points lie. It is defined as:<br>The IQR provides insights on the spread of the data around the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"63\" to=\"69\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a>, and is commonly used to identify <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"104\" to=\"112\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a> where values that are below or above are considered outliers.<br>A boxplot, sometimes referred to as a whisker plot, provides a visual summary of a distribution of a dataset. The plot depicts the values of the <a data-href=\"Five-Number Summary\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Five-Number Summary</a> which consists of the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"23\" to=\"29\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a>, first and third quartiles, and the maximum and minimum values.The boxplot consists of:\n<br>The Box: Which represents the <a data-href=\"Interquartile Range\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interquartile Range</a> of the distribution, which can be thought of as the middle 50% of the data.\n<br>Median Line: The line in the center of the box which represents the second quartile, or the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"81\" to=\"87\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> of the dataset.\nWhiskers: The lines extending from the box to the value of the minimum or maximum value of the distribution. It is common for the whiskers to be set to the smallest and largest values with 1.5 times the IQR, rather than the true minimum and maximum values of the population.<br>\n<img alt=\"Pasted image 20250708093049.png\" src=\"https://emujakic.github.io/TechKB/resources/pasted-image-20250708093049.png\" target=\"_self\"><br>\n<a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.machinelearningplus.com/plots/python-boxplot/\" target=\"_self\">https://www.machinelearningplus.com/plots/python-boxplot/</a> J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>“Quartile,”&nbsp;Wikipedia, Nov. 26, 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Quartile\" target=\"_self\">https://en.wikipedia.org/wiki/Quartile</a>\n<br>“Find a Five-Number Summary in Statistics: Easy Steps,”&nbsp;Statistics How To. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.statisticshowto.com/statistics-basics/how-to-find-a-five-number-summary-in-statistics/\" target=\"_self\">https://www.statisticshowto.com/statistics-basics/how-to-find-a-five-number-summary-in-statistics/</a>\n<br>M. Yi, “A Complete Guide to Box Plots,”&nbsp;Atlassian, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.atlassian.com/data/charts/box-plot-complete-guide\" target=\"_self\">https://www.atlassian.com/data/charts/box-plot-complete-guide</a>\n<br>S. Glen, “Interquartile <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"24\" to=\"29\" origin-text=\"Range\" class=\"internal-link virtual-link-a\">Range</a> (IQR): What it is and How to Find it,”&nbsp;Statistics How To, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.statisticshowto.com/probability-and-statistics/interquartile-range/\" target=\"_self\">https://www.statisticshowto.com/probability-and-statistics/interquartile-range/</a>\n","aliases":["Quartiles"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Quartile","level":1,"id":"Quartile_0"},{"heading":"<a data-href=\"Five-Number Summary\" href=\"Five-Number Summary\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Five-Number Summary</a>","level":3,"id":"[[Five-Number_Summary]]_0"},{"heading":"Calculation","level":2,"id":"Calculation_0"},{"heading":"<a data-href=\"Interquartile Range\" href=\"Interquartile Range\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Interquartile Range</a> (IQR)","level":2,"id":"[[Interquartile_Range]]_(IQR)_0"},{"heading":"<a data-href=\"Boxplot\" href=\"Boxplot\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Boxplot</a> and <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Outlier.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"5\" to=\"12\" origin-text=\"Outlier\" class=\"internal-link virtual-link-a\">Outlier</a></span> Detection","level":2,"id":"[[Boxplot]]_and_Outlier_Detection_0"},{"heading":"Components","level":3,"id":"Components_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/quantile.html#_0",".html",".html","notes/math/median.html#_0","notes/math/median.html#_0",".html","notes/math/median.html#_0",".html","notes/math/outlier.html#_0","notes/math/median.html#_0",".html","notes/math/range.html#_0","notes/math/median.html#_0","notes/math/outlier.html#_0",".html","notes/math/outlier.html#_0",".html","notes/math/median.html#_0",".html","notes/math/median.html#_0","notes/math/range.html#_0"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/HTML/resources/pasted-image-20250708093049.png","fullURL":"https://emujakic.github.io/TechKB/notes/math/quartile.html","pathToRoot":"../..","attachments":["resources/pasted-image-20250708093049.png"],"createdTime":1751928764242,"modifiedTime":1756435200221,"sourceSize":4048,"sourcePath":"NOTES/Math/Quartile.md","exportPath":"notes/math/quartile.html","showInTree":true,"treeOrder":21,"backlinks":["notes/math/mean.html","notes/math/median.html","notes/math/outlier.html","notes/math/quantile.html","notes/math/range.html","notes/math/standard-deviation.html"],"type":"markdown"},"notes/math/quantile.html":{"title":"Quantile","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-16Quantiles are points in a dataset which divide the dataset into equal parts. Some examples of quantiles include the:\n<a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a>: which divides the dataset into two equal parts;\n<br><a data-tooltip-position=\"top\" aria-label=\"Quartile\" data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quartiles</a>: which divide the dataset into four equal parts; and <br><a data-href=\"Percentiles\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Percentiles</a>: which divide the dataset into 100 equal parts.\n<br><img alt=\"Quartiles &amp; Quantiles | Calculation, Definition &amp; Interpretation\" src=\"https://www.scribbr.com/wp-content/uploads/2022/05/Quartiles-probability-distribution.webp\" referrerpolicy=\"no-referrer\" target=\"_self\" class=\"is-unresolved\"><br>\n<a data-tooltip-position=\"top\" aria-label=\"https://www.scribbr.com/statistics/quartiles-quantiles/\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.scribbr.com/statistics/quartiles-quantiles/\" target=\"_self\">Quartiles &amp; Quantiles | Calculation, Definition &amp; Interpretation</a>Q-quantiles are the values which divide a dataset into equal (or nearly equal) parts. The 100-quantiles (percentiles), for example, divide the dataset into 100 parts.To divide a dataset into equal parts:\nSort the dataset in ascending order.\nCalculate the position of the th quantile using: <br>If is an integer, the quantile is the value at that position in the sorted dataset. If is not an integer, <a data-href=\"Interpolate\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interpolate</a> it, that is, round it up, and take the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a> of the values at positions and .\nNumPy has multiple functions for computing quantiles including:\nnumpy.percentile(): Which takes a dataset and percentile (e.g. 50) as arguments, and returns the value at that percentile.\nnumpy.quantile(): Which takes a dataset and a decimal value representing the percentile (e.g. 0.50) as input, and returns the value at that quantile.\n<br>Quantiles are commonly used to summarize the distribution of a dataset, and is commonly used as both a <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">measure of central tendency</a> and a <a data-href=\"Measure of Dispersion\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Dispersion</a>.<br>Quantiles are commonly used to identify <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"40\" to=\"48\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>. One method involves flagging any observations that are more than 1.5 times the <a data-href=\"Interquartile Range\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interquartile Range</a> (IQR) above the third <a href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"23\" to=\"31\" origin-text=\"quartile\" class=\"internal-link virtual-link-a\">quartile</a> or below the first quartile.\n<br>\n<a data-href=\"Box Plot\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Box Plot</a>: Visualizes the <a data-href=\"Five-Number Summary\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Five-Number Summary</a> of a dataset, where the box represents the IQR, the line in the box is the <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a>, the \"whiskers\" represent the 25% of the data below and above the first and third <a href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"83\" to=\"91\" origin-text=\"quartile\" class=\"internal-link virtual-link-a\">quartile</a> respectively, and the lines at the edge of each whisker represents the minimum and maximum values. <br>\n<a data-href=\"Q-Q Plot\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Q-Q Plot</a>: A comparative visualization method which plots the quantiles of two distributions against each other, where typically, a real dataset is plotted against a theoretical dataset (usually a normal distribution). <br>\n<a data-href=\"Violin Plot\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Violin Plot</a>: Overlays density curves over a box plot, where the width of the curve indicates the density of data points at specific values. J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Quantiles in Machine Learning,”&nbsp;GeeksforGeeks, Mar. 12, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/data-science/quantiles-in-machine-learning/\" target=\"_self\">https://www.geeksforgeeks.org/data-science/quantiles-in-machine-learning/</a>\n<br>“Quantile,”&nbsp;Wikipedia, Dec. 12, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Quantile\" target=\"_self\">https://en.wikipedia.org/wiki/Quantile</a>\n<br>Atlassian, “A Complete Guide to Violin Plots,”&nbsp;Atlassian. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.atlassian.com/data/charts/violin-plot-complete-guide\" target=\"_self\">https://www.atlassian.com/data/charts/violin-plot-complete-guide</a>\n","aliases":["Quantiles"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Quantile","level":1,"id":"Quantile_0"},{"heading":"Q-Quantiles","level":4,"id":"Q-Quantiles_0"},{"heading":"Calculation","level":2,"id":"Calculation_0"},{"heading":"Using <a data-href=\"NumPy\" href=\"NumPy\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">NumPy</a>","level":3,"id":"Using_[[NumPy]]_0"},{"heading":"Applications","level":2,"id":"Applications_0"},{"heading":"Descriptive Statistics","level":3,"id":"Descriptive_Statistics_0"},{"heading":"<a data-href=\"Outlier\" href=\"Outlier\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Outlier</a> Detection","level":3,"id":"[[Outlier]]_Detection_0"},{"heading":"Visualization","level":3,"id":"Visualization_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/median.html#_0","notes/math/quartile.html#_0",".html",".html","notes/math/mean.html#_0",".html","notes/math/measure-of-central-tendency.html#_0",".html","notes/math/outlier.html#_0","notes/math/outlier.html#_0",".html","notes/math/quartile.html#_0",".html",".html","notes/math/median.html#_0","notes/math/quartile.html#_0",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"https://www.scribbr.com/wp-content/uploads/2022/05/Quartiles-probability-distribution.webp","fullURL":"https://emujakic.github.io/TechKB/notes/math/quantile.html","pathToRoot":"../..","attachments":[],"createdTime":1752697090804,"modifiedTime":1756435351475,"sourceSize":3483,"sourcePath":"NOTES/Math/Quantile.md","exportPath":"notes/math/quantile.html","showInTree":true,"treeOrder":20,"backlinks":["notes/math/quartile.html"],"type":"markdown"},"notes/math/propositional-logic.html":{"title":"Propositional Logic","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-08-02Propositional logic is a branch of <a data-href=\"Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic</a> that deals with propositions, which are statements that are either true or false. An example of a proposition is the sentence, \"Tomorrow is Thursday\", since it's either true or false.<br>\nPropositional logic is <a data-tooltip-position=\"top\" aria-label=\"Monotonicity\" data-href=\"Monotonicity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Monotonic</a>, meaning that when you add knowledge to a propositional <a data-href=\"Knowledge Base\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Base</a>, it cannot lead to the loss of previously established truths.Propositional logic is made up of:\nPropositional Symbols: Symbols that start with an uppercase letter and refer to a proposition. For example, , , and are examples of propositional symbols. Each symbol represents a distinct statement that can be true or false. Individual symbols are commonly referred to as literals. A literal is negative if there is a negation applied to it (e.g. ), else, it's a positive literal.\nLogical Connectives: Operators which combine propositional symbols to create complex sentences. The primary logical connectives include: Negation (NOT, ¬)\nConjunction (AND, ∧)\nDisjunction (OR, ∨)\nImplication (IMPLIES, →)\nBiconditional (IF AND ONLY IF, ↔) Atomic Sentence: An atomic sentence consists of a single propositional symbol and represents a basic assertion.\nComplex Sentence: A complex sentence is made up of propositional symbols connected by parenthesis and logical connectives. They are also called formulas.\nPropositional logic is often seen as a precursor to more complex logic systems including:\n<br><a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a>: Extends propositional logic by introducing quantifiers and predicates, allowing for the representation of the relationships between objects.\n<br><a data-href=\"Modal Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Modal Logic</a>: Incorporates modalities like possibility, necessity, or knowledge.\n<br><a data-href=\"Temporal Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Temporal Logic</a>: Allows for reasoning about change over time by introducing temporal operators.\n<br><a data-href=\"Automated Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Automated Theorem Proving</a>: Uses propositional logic as the basis for many theorem proving techniques.\n<br>Negation flips the truth value of the propositional symbol it is applied to. Negating gives , which can be understood in English as \"not \". The <a data-href=\"Truth Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Truth Table</a> for negation is as follows:A conjunction of two conjuncts is true only if both of its conjuncts is true. This can be understood in English as \"and\", and is denoted in propositional logic with the symbol . The truth table for conjunction is as follows:A disjunction of two disjuncts is true if either of its disjuncts are true. This can be understood as the English word \"or\", meaning if one or the other is true, then the disjunction is true. Disjunction is denoted with the symbol . The truth table for disjunction is as follows:An Implication is a binary operator with its left-hand side being the premise, and the right-hand side being the conclusion. An implication states that if the premise is true, then the premise must be true. Implications can be thought of as if-then statements and are denoted with the symbols or . An implication is only false if its premise is true, while the conclusion is false. The truth table for implication is as follows:As shown in the truth table above, an implication is always true if its premise is false. This occurs because the sentence provides no information. It is like saying, \"If , which is false, were true, then \". Since is false, the sentence holds no substantive meaning.\nThe concept of vacuous truth will be relevant later in the Mathematical Induction subsection, particularly in establishing base cases.A biconditional can be thought of as double implication, meaning both sides imply the other. Biconditionals are true only if both symbols are the same truth value. The symbols used to denote biconditional is or , and can be thought of in English as \"if and only if\". The truth table for a biconditional is:A NAND can be thought of as a negation applied to a conjunction, . A NAND is true as long as one of its operands it false. It's represented symbolically as or as , and has the following truth table:A XOR, or exclusive or, is true when exactly one of its operands is true. It can be thought of as the English word 'or', in the context of when only one thing or the other is the case. XOR is denoted using the symbol, and its truth table is as follows:A NOR can be thought of as a negation applied to an OR operator, . A NOR is true only when both of its operands are false and is represented symbolically as . The truth table for NOR is as follows: A XNOR can be thought of as a negation applied to the XOR gate, . Where a XOR is true only when both of its operands are different, a XNOR is true only when both of its operands are the same. It has the same truth table as a biconditional, which is as follows:The order of precedence of logical connectives is as follows:\nNegation (NOT, ¬)\nConjunction (AND, ∧)\nDisjunction (OR, ),\nImplication (IMPLIES, →)\nBiconditional (IF AND ONLY IF, ↔)\n<br>Two sentences are said to be logically equivalent if they have the same truth table. This is denoted using the symbol. A <a data-href=\"Rule of Replacement\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Rule of Replacement</a> is a logical principle that allows for the substitution of one logical expression, for another, logically equivalent expression. Rules of replacement are used to construct proofs, simply logical expressions, and verify the correctness of logical statements. Propositional equivalence is vital for many domains, including:\n<br>Digital Logic Design: Used to simplify expressions in <a data-href=\"Boolean Algebra\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Boolean Algebra</a>, thereby optimizing and simplifying digital circuits.\n<br>Artificial Intelligence: Used to in <a data-href=\"Knowledge Representation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Representation</a> as well as inference algorithms, to derive new facts from an existing <a data-href=\"Knowledge Base\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Base</a>.\n<br><a data-href=\"Control Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Control Theory</a>: Used for simplifying systems equations, analyze conditions, and modeling states and transitions.\nMathematical Proofs: Used to transform sentences into equivalent forms which are easier to prove.\nThe double negation law is a rule of replacement which states that, when negation is applied twice to an expression, the truth table for that expression remains the same. This is because the second negation 'cancels out' the first one, leaving only the original expression left.\nThe identity laws state that, any proposition conjoined with a true value, is logically equivalent to the proposition alone. For disjunction, any proposition disjoined with a false value, is logically equivalent to the proposition alone. This is because it both cases, the expression's truth value relies entirely on the value of the proposition.\nThe domination laws state that, any proposition conjoined with a false value is always false, and any proposition disjoined with a true value is always true. This is because, in the case of conjunction, the AND operation requires both operands to be true for the result to be true. Since one operand is false, the entire expression cannot be true, regardless of the value of the other operand. In the case of disjunction, the OR operation requires at least one operand to be true for the result to be true. Since one operand is true, the entire expression will always evaluate to true.\nThe idempotent laws state that a proposition conjoined or disjoined with itself is logically equivalent to the proposition alone. This means that applying conjunction or disjunction to a proposition with itself multiple times yields the same truth table as the original proposition.\nThe distributive laws describe how conjunction (AND) and disjunction (OR) interact with each other in propositional logic, allowing us to distribute one operation over the other.\nThe first distributive law states that a conjunction of with disjunction of and is logically equivalent to the disjunction of AND with AND R.\nThe second distributive law states that the disjunction of with the conjunction of and is logically equivalent to the conjunction of OR with OR .\nDe Morgan's Laws consist of two rules of replacement which define the relationship between disjunctions and conjunctions through negation.\nDe Morgan's first law states that the negation of a conjunction is logically equivalent to the disjunction of the negated conjuncts. This is directly equivalent to the definition of the NAND operator and can be seen as a direct implementation of De Morgan's first law.\nDe Morgan's second law states that the negation of a disjunction is logically equivalent to the conjunction of the negated disjuncts. This is directly equivalent to the definition of the NOR operator and can be seen as a direct implementation of De Morgan's second law.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"15\" origin-text=\"commutative\" class=\"internal-link virtual-link-a\">commutative</a> laws state that the order of operands in a conjunction and disjunction are logically equivalent.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/associative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"15\" origin-text=\"associative\" class=\"internal-link virtual-link-a\">associative</a> laws state that the grouping of operands in a conjunction or disjunction does not affect the truth value of expression.\nA clause is a disjunction/conjunction of literals. When talking about clauses, usually it refers to a disjunctive clause, which is a logical expression formed by connecting literals with the OR operator.\nThe empty clause is a clause with no literals, commonly denoted as , , or . An empty disjunctive clause is always false, making it analogous to a contradiction. This is an important concept in proof by contradiction, as reaching an empty clause indicates that a contradiction has been proven.A Horn clause is a disjunctive clause with at most one positive literal.\nDefinite Clause: If a Horn clause has exactly one positive literal, it is a definite clause. For example, .\nGoal Clause: If it has no positive literals, it is a goal clause. For example, .\nA Horn clause can be represented in disjunctive form:\nA Horn clause can also be represented in implicative form:\nIn both cases, is the only positive literal.<br>Horn clauses are computationally efficient for algorithms such as <a data-href=\"Resolution Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Resolution Theorem Proving</a>, or for <a data-href=\"Forward/Backward Chaining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Forward/Backward Chaining</a>. This makes them the basis of many <a data-href=\"Logic Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic Programming</a> languages, as well as for automated theorem proving or database querying.A sentence is considered to be in conjunctive normal form (CNF) if it's a conjunction (AND) of one or more clauses.\nEvery sentence in propositional logic can be converted into an equivalent CNF form using the following steps:\nImplication/biconditional elimination (will be discussed later)\nMoving Negations Inward using De Morgan's laws.\nDouble negation elimination\nUsing the distributive property to distribute OR over AND, for example: A sentence is considered to be in disjunctive normal form (DNF) if it is a disjunction (OR) of conjunctions (AND).\nEvery sentence in propositional logic can be converted to DNF in the following steps:\nImplication/biconditional elimination\nMoving Negations Inward using De Morgan's laws.\nDouble negation elimination\nUsing the distributive property to distribute AND over OR, for example: <br>In logic, an argument consists of a set of sentences called premises, which, if all are true, the conclusion sentence must follow. This is a form of reasoning called <a data-href=\"Deductive Reasoning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Deductive Reasoning</a> which uses general statements to derive specific conclusions.<br>Logical entailment, or logical consequence, refers to a relationship between premises and a conclusion. The conclusion is said to be entailed by the premises if there is no assignment of truth values such that the premises are true while the conclusion is false. In other words, entailment states that the conclusion follows the premises; whenever the premises are true, so is the conclusion. Entailment is closely related to the idea of <a data-tooltip-position=\"top\" aria-label=\"Tautology\" data-href=\"Tautology\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">tautologies</a>, as tautologies represent statements that are universally true and can help establish the validity of entailments.\nEntailment is represented symbolically as . For example: Valid: An argument is valid if its conclusion must follow its premises. Meaning that if the argument's premises are true, then the conclusion must be true as well, otherwise, the argument is invalid.\nSound: An argument is sound if its premises are true. If any of its premises are false, then the argument is unsound.\nSatisfiable: A formula is satisfiable if there is at least one assignment of truth values which makes the formula true. If there is no assignment of truth values to make the formula true, then it is unsatisfiable, also called a contradiction.\nIf an argument is valid and sound, then its conclusion must be true. A sound argument is always valid, while a valid argument may be unsound.\nArgument forms are patterns or templates that represent valid structures for arguments.\n<br><a data-tooltip-position=\"top\" aria-label=\"Syllogism\" data-href=\"Syllogism\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Syllogisms</a> are argument forms that consist of two premises which support a conclusion.\nModus Ponens is a syllogistic argument form and rule of inference. It has the following structure:\nIf then .\n.\nTherefore, .\n<br>The first two sentences are the arguments premises, and the final sentence is the conclusion. Modus Ponens is represented in <a data-href=\"Gentzen Notation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gentzen Notation</a> as:\nModus Tollens is another valid syllogistic argument form, similar to Modus Ponens. Though, unlike Modus Ponens, Modus Tollens affirms the negation of antecedent from the negation of the consequent. The structure of Modus Tollens is as follows:\nIf then .\n.\nTherefore, .\nLike Modus Ponens, the first two sentences are the arguments premises, and the final sentence is the conclusion. Modus Tollens is represented symbolically as:\nA disjunctive syllogism is a syllogistic argument form with a disjunction as one of its premises. It says that if one of the two disjuncts is true, and we know that one is false, then the other must be true. The structure of disjunctive syllogisms is as follows: or .\n.\nTherefore, .\nIn Gentzen notation:\n<br>A hypothetical syllogism, also called the chain rule, is an argument form which uses the <a data-tooltip-position=\"top\" aria-label=\"Transitive Property\" data-href=\"Transitive Property\" href=\"https://emujakic.github.io/TechKB/notes/math/transitive-property.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">transitive property</a> of implication. The structure of a hypothetical syllogism is as follows:\nIf then .\nIf then .\nTherefore, if then .\nHypothetical syllogisms are represented in Gentzen notation as:\nRules of inference are logical rules that dictate derivations of conclusions from premises. Rules of inference differ from rules of replacement which state that two expressions are logically equivalent and can be freely swapped for one another.Implication introduction is a rule of inference which is used to express implications in terms of disjunctions. The rule is as follows:\nImplication introduction is crucial when converting formulas to normal forms like CNF or DNF.Biconditional introduction is a rule of inference which allow for the inference of a biconditional from two implications:\nThis transformation can also be done the opposite way, called biconditional elimination, where two implications can be inferred from a biconditional:\nand:\nConjunction introduction is a rule of inference which states that if two propositions are known to be true, then there conjunction is also known to be true:\nConjunction elimination states that if the conjunction of two propositions is known to be true, then either of its conjuncts is also known to be true:\nDisjunction introduction is a rule of inference which states that if a proposition is known to be true, any disjunction it is a part of is also known to be true:\nDisjunction elimination works the opposite way, stating that if you have a disjunction where each disjunct implies a third proposition , then can be inferred:\nIn propositional logic, proofs are essential for establishing the truth of a statement or the validity of an argument. A proof is a demonstration that a conclusion follows from a set of premises.<br><a data-tooltip-position=\"top\" aria-label=\"Proof System\" data-href=\"Proof System\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Proof Systems</a> are frameworks which provide the structure and methodology for constructing proofs. Proof systems are made up of:\nAxioms: Foundational propositions that are accepted as true without having been proven.\nRules of Inference: Rules which provide the structure for how new statements can be derived from existing ones.\nSyntax: The symbols used to represent statements.\nSemantics: The interpretation of the meaning of the statements within the proof system.\nThe most common proof systems include Natural Deduction and Sequent Calculus.\nA proof system is complete if every statement that is semantically true can be proven within that system. Otherwise, the system is incomplete.\nA tautology is a propositional formula which is true for all possible assignments of truth values. A contradiction is a formula that is always false for all possible assignments of truth values.\nMany proof techniques rely on tautologies and contradictions to prove that a particular formula entails another, or to prove that a particular formula is unsatisfiable. A direct proof is one of the most common and straightforward methods for deriving conclusions. The structure of a direct proof is as follows:\nIdentify the premises: Clearly state the premises which you will use to derive the conclusion.\nState the conclusion: State the conclusion you wish to prove from the premises.\nLogical deduction: Use the rules of inference to derive the conclusion from the premises step by step.\nProof by contradiction is an indirect proof that assumes the conclusion is false, then proves that this assumption leads to a contradiction. If assuming the conclusion is false does lead to a contradiction, then the conclusion must be true. The structure of a proof by contradiction is as follows:\nIdentify the premises: Clearly state the premises which you will use to derive the conclusion.\nState the conclusion: State the conclusion you wish to prove from the premises.\nAssume the negation: Assume that the conclusion is false.\nLogical deduction: Use the rules of inference to derive a contradiction. A contradiction typically manifests as the empty sentence , which is a statement that is always false.\nConclude the Conclusion: If the assumption that the conclusion is false did lead to a contradiction, then the original conclusion must be true.\nProof by contrapositive is an indirect proof which proves a conclusion by proving its contrapositive. Since a sentence and its contrapositive are logically equivalent, proving one proves the other. The structure for a proof by contrapositive is as follows:\nState the conclusion: State the conclusion you wish to prove, for example, .\nIdentify the contrapositive: Identify the contrapositive of the conclusion, for example, .\nLogical deduction: Use the rules of inference to prove the contrapositive.\nConclude the Original Implication: If the contrapositive can be proven, then the original conclusion is also proven.\nResolution resolves two clauses which contain complementary literals. Two literals are complements of one another if one is the negation of the other (e.g. and ). Resolution is defined:\nThe above example resolves and resulting in a new clause called the resolvent.<br>\nIn the context of <a data-href=\"Resolution Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Resolution Theorem Proving</a>, resolution is applied repeatedly to derive a contradiction, thereby proving that the negation of the statement that's being proven, is unsatisfiable. Ensuring all formulas are in Conjunctive Normal Form (CNF) dramatically improves the efficiency of resolution-based automated theorem proving.Mathematical induction is a proof technique for statements that apply to all natural numbers. It starts with proving the base case—typically or . Then the inductive hypothesis assumes that the formula is true for some arbitrary natural number , where . Then, using this assumption, the inductive step involves proving the formula holds for .\nFor example, let's say were trying to inductively prove : The base case, where , is:\nNow, we assume the inductive hypothesis is true:\nUsing the assumption, the inductive step involves proving:\nUsing Algebra, we get:\nTherefore, is true for all natural number greater than or equal to 1.\n<br>Artificial Intelligence: Propositional logic is used for knowledge representation, <a data-href=\"Decision Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Theory</a>, and inference algorithms in AI agents.\n<br><a data-href=\"Automated Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Automated Theorem Proving</a>: Uses propositional logic as the basis for many theorem proving techniques. Database Querying: Allows for complex queries using logical operators like AND, NOT, and OR. Queries can also utilize propositional conditional statements.\n<br><a data-href=\"Satisfiability Problems\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Satisfiability Problems</a>: Propositional logic is central to many SAT solvers. <br><a data-href=\"Digital Circuit Design\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Digital Circuit Design</a>: Propositional logic is used to design and analyze digital circuits. Digital <a data-tooltip-position=\"top\" aria-label=\"Logic Gate\" data-href=\"Logic Gate\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic Gates</a> correspond to the propositional logical operators.\n<br><a data-href=\"Boolean Algebra\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Boolean Algebra</a>: Propositional logic serves as the basis of Boolean algebra, which is essential for circuit design and programming. Proof Techniques: Many proof techniques, including direct proof, proof by contradiction, and mathematical induction is built upon propositional logic.\n<br><a data-href=\"Set Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Set Theory</a>: Used to express relationships and operations on sets.\n<br>Logical Foundation: Propositional logic serves as the base for more complex logic systems like <a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a>, modal logic, and temporal logic. Strategy Representation: Propositional logic can be used to design strategies for players. Fault Detection: Propositional logic can be employed to detect faults in systems by establishing logical relations between system states and expected behavior. S. J. Russell and P. Norvig,&nbsp;Artificial Intelligence: a Modern Approach, 4th ed. Upper Saddle River: Pearson, 2020.\nWikipedia Contributors, “Propositional calculus,”&nbsp;Wikipedia, Oct. 21, 2024.\n<br>GeeksforGeeks, “Propositional Logic,”&nbsp;GeeksforGeeks, Jun. 19, 2015. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/engineering-mathematics/proposition-logic/\" target=\"_self\">https://www.geeksforgeeks.org/engineering-mathematics/proposition-logic/</a>\n<br>C. Franks, “Propositional Logic,”&nbsp;Stanford Encyclopedia of Philosophy, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://plato.stanford.edu/entries/logic-propositional/\" target=\"_self\">https://plato.stanford.edu/entries/logic-propositional/</a>\n<br>GeeksforGeeks, “Propositional Equivalences,”&nbsp;GeeksforGeeks, Jun. 22, 2015. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/engineering-mathematics/mathematical-logic-propositional-equivalences/\" target=\"_self\">https://www.geeksforgeeks.org/engineering-mathematics/mathematical-logic-propositional-equivalences/</a> (accessed Aug. 03, 2025).\n<br>“Propositional Logic: Part I -Semantics 12-0.” Available: <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.cas.mcmaster.ca/~lawford/2F03/Notes/prop.pdf\" target=\"_self\">https://www.cas.mcmaster.ca/~lawford/2F03/Notes/prop.pdf</a>\nWikipedia Contributors, “Rule of replacement,”&nbsp;Wikipedia, Mar. 03, 2025.\n<br>GeeksforGeeks, “Idempotent Laws,”&nbsp;GeeksforGeeks, Sep. 08, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/idempotent-laws/\" target=\"_self\">https://www.geeksforgeeks.org/maths/idempotent-laws/</a> (accessed Aug. 03, 2025).\n<br>Wikipedia Contributors, “De Morgan’s laws,”&nbsp;Wikipedia, Sep. 05, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/De_Morgan%27s_laws\" target=\"_self\">https://en.wikipedia.org/wiki/De_Morgan%27s_laws</a>\n<br>“1.2: Basic Notions - Propositions and Arguments,”&nbsp;Humanities LibreTexts, Sep. 26, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://human.libretexts.org/Bookshelves/Philosophy/Fundamental_Methods_of_Logic_(Knachel)/01%3A_The_Basics_of_Logical_Analysis/1.02%3A_Basic_Notions_-_Propositions_and_Arguments\" target=\"_self\">https://human.libretexts.org/Bookshelves/Philosophy/Fundamental_Methods_of_Logic_(Knachel)/01%3A_The_Basics_of_Logical_Analysis/1.02%3A_Basic_Notions_-_Propositions_and_Arguments</a>\n<br>Dr. Trefor Bazett, “Logical Arguments - Modus Ponens &amp; Modus Tollens,”&nbsp;YouTube. May 23, 2017. Accessed: Sep. 02, 2022. [Online]. Available: <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.youtube.com/watch?v=NTSZMdGlo4g\" target=\"_self\">https://www.youtube.com/watch?v=NTSZMdGlo4g</a>\n<br>Wikipedia Contributors, “Modus ponens,”&nbsp;Wikipedia, Jan. 20, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Modus_ponens\" target=\"_self\">https://en.wikipedia.org/wiki/Modus_ponens</a>\n<br>“Disjunctive syllogism,”&nbsp;Wikipedia, Mar. 03, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Disjunctive_syllogism\" target=\"_self\">https://en.wikipedia.org/wiki/Disjunctive_syllogism</a>\n<br>TrevTutor, “[Logic] Proofs and Rules #1,”&nbsp;<a data-tooltip-position=\"top\" aria-label=\"http://www.youtube.com\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://www.youtube.com\" target=\"_self\">www.youtube.com</a>. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.youtube.com/watch?v=m2j0TX-e8NY\" target=\"_self\">https://www.youtube.com/watch?v=m2j0TX-e8NY</a> (accessed Aug. 4, 2025).\nWikipedia Contributors, “Resolution (logic),”&nbsp;Wikipedia, May 28, 2025.\n<br>“Introduction to Logic - Chapter 6,”&nbsp;Stanford.edu, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://intrologic.stanford.edu/chapters/chapter_06.html\" target=\"_self\">http://intrologic.stanford.edu/chapters/chapter_06.html</a> (accessed Aug. 05, 2025).\n<br>Wikipedia Contributors, “Horn clause,”&nbsp;Wikipedia, Dec. 18, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Horn_clause\" target=\"_self\">https://en.wikipedia.org/wiki/Horn_clause</a>\nWikipedia Contributors, “Biconditional introduction,”&nbsp;Wikipedia, Aug. 01, 2023.\n<br>“Tautology (logic),”&nbsp;Wikipedia, Sep. 17, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Tautology_(logic)\" target=\"_self\">https://en.wikipedia.org/wiki/Tautology_(logic)</a>\n<br>“Introduction to Logic - Chapter 6,”&nbsp;Stanford.edu, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://intrologic.stanford.edu/chapters/chapter_06.html\" target=\"_self\">http://intrologic.stanford.edu/chapters/chapter_06.html</a>\nWikipedia Contributors, “Resolution (logic),”&nbsp;Wikipedia, May 28, 2025.\n","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#logic","#propositionalLogic"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Propositional Logic","level":1,"id":"Propositional_Logic_0"},{"heading":"Syntax","level":3,"id":"Syntax_0"},{"heading":"Sentences","level":3,"id":"Sentences_0"},{"heading":"Relation to Other Logics","level":3,"id":"Relation_to_Other_Logics_0"},{"heading":"Logical Connectives","level":2,"id":"Logical_Connectives_0"},{"heading":"Negation (NOT, ¬)","level":3,"id":"Negation_(NOT,_¬)_0"},{"heading":"Conjunction (AND, ∧)","level":3,"id":"Conjunction_(AND,_∧)_0"},{"heading":"Disjunction (OR, <span class=\"math math-inline is-loaded\"><mjx-container class=\"MathJax\" jax=\"CHTML\"><mjx-math class=\"MJX-TEX\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2228\"></mjx-c></mjx-mo></mjx-math></mjx-container></span>)","level":3,"id":"Disjunction_(OR,_$\\lor$)_0"},{"heading":"Implication (IMPLIES, →)","level":3,"id":"Implication_(IMPLIES,_→)_0"},{"heading":"<a data-href=\"Vacuous Truth\" href=\"Vacuous Truth\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Vacuous Truth</a>","level":4,"id":"[[Vacuous_Truth]]_0"},{"heading":"Biconditional (IF AND ONLY IF, ↔)","level":3,"id":"Biconditional_(IF_AND_ONLY_IF,_↔)_0"},{"heading":"NAND (NOT AND, <span class=\"math math-inline is-loaded\"><mjx-container class=\"MathJax\" jax=\"CHTML\"><mjx-math class=\"MJX-TEX\"><mjx-texatom texclass=\"ORD\"><mjx-mover><mjx-over style=\"padding-bottom: 0.105em; padding-left: 0.334em; margin-bottom: -0.544em;\"><mjx-mo class=\"mjx-n\" style=\"width: 0px; margin-left: -0.25em;\"><mjx-c class=\"mjx-cAF\"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2227\"></mjx-c></mjx-mo></mjx-base></mjx-mover></mjx-texatom></mjx-math></mjx-container></span>)","level":3,"id":"NAND_(NOT_AND,_$\\bar{\\land}$)_0"},{"heading":"XOR (EXCLUSIVE OR, <span class=\"math math-inline is-loaded\"><mjx-container class=\"MathJax\" jax=\"CHTML\"><mjx-math class=\"MJX-TEX\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2295\"></mjx-c></mjx-mo></mjx-math></mjx-container></span>)","level":3,"id":"XOR_(EXCLUSIVE_OR,_$\\oplus$)_0"},{"heading":"NOR (NOT OR, <span class=\"math math-inline is-loaded\"><mjx-container class=\"MathJax\" jax=\"CHTML\"><mjx-math class=\"MJX-TEX\"><mjx-texatom texclass=\"ORD\"><mjx-mover><mjx-over style=\"padding-bottom: 0.105em; padding-left: 0.334em; margin-bottom: -0.544em;\"><mjx-mo class=\"mjx-n\" style=\"width: 0px; margin-left: -0.25em;\"><mjx-c class=\"mjx-cAF\"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2228\"></mjx-c></mjx-mo></mjx-base></mjx-mover></mjx-texatom></mjx-math></mjx-container></span>)","level":3,"id":"NOR_(NOT_OR,_$\\bar{\\lor}$)_0"},{"heading":"XNOR (EXCLUSIVE NOT OR, <span class=\"math math-inline is-loaded\"><mjx-container class=\"MathJax\" jax=\"CHTML\"><mjx-math class=\"MJX-TEX\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2299\"></mjx-c></mjx-mo></mjx-math></mjx-container></span>)","level":3,"id":"XNOR_(EXCLUSIVE_NOT_OR,_$\\odot$)_0"},{"heading":"Precedence of Logical Connectives","level":3,"id":"Precedence_of_Logical_Connectives_0"},{"heading":"Logical Equivalence","level":2,"id":"Logical_Equivalence_0"},{"heading":"Properties and Laws","level":3,"id":"Properties_and_Laws_0"},{"heading":"Double Negation Law","level":4,"id":"Double_Negation_Law_0"},{"heading":"Identity Laws","level":4,"id":"Identity_Laws_0"},{"heading":"Domination Laws","level":4,"id":"Domination_Laws_0"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"Idempotent Property\" data-href=\"Idempotent Property\" href=\"Idempotent Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Idempotent</a> Laws","level":4,"id":"[[Idempotent_Property|Idempotent]]_Laws_0"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"Distributive Property\" data-href=\"Distributive Property\" href=\"Distributive Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Distributive</a> Laws","level":4,"id":"[[Distributive_Property|_Distributive]]_Laws_0"},{"heading":"<a data-href=\"De Morgan's Laws\" href=\"De Morgan's Laws\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">De Morgan's Laws</a>","level":4,"id":"[[De_Morgan's_Laws]]_0"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"Commutative Property\" data-href=\"Commutative Property\" href=\"Commutative Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Commutative</a> Laws","level":4,"id":"[[Commutative_Property|Commutative]]_Laws_0"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"Associative Property\" data-href=\"Associative Property\" href=\"Associative Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Associative</a> Laws","level":4,"id":"[[Associative_Property|Associative]]_Laws_0"},{"heading":"Clauses and Normal Form","level":2,"id":"Clauses_and_Normal_Form_0"},{"heading":"Horn Clause","level":3,"id":"Horn_Clause_0"},{"heading":"<a data-href=\"Conjunctive Normal Form\" href=\"Conjunctive Normal Form\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Conjunctive Normal Form</a>","level":3,"id":"[[Conjunctive_Normal_Form]]_0"},{"heading":"<a data-href=\"Disjunctive Normal Form\" href=\"Disjunctive Normal Form\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Disjunctive Normal Form</a>","level":3,"id":"[[Disjunctive_Normal_Form]]_0"},{"heading":"Arguments","level":2,"id":"Arguments_0"},{"heading":"Entailment","level":3,"id":"Entailment_0"},{"heading":"Validity, Soundness, and Satisfiability","level":3,"id":"Validity,_Soundness,_and_Satisfiability_0"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"Argument Form\" data-href=\"Argument Form\" href=\"Argument Form\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Argument Forms</a>","level":3,"id":"[[Argument_Form|Argument_Forms]]_0"},{"heading":"<a data-href=\"Modus Ponens\" href=\"Modus Ponens\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Modus Ponens</a>","level":4,"id":"[[Modus_Ponens]]_0"},{"heading":"<a data-href=\"Modus Tollens\" href=\"Modus Tollens\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Modus Tollens</a>","level":4,"id":"[[Modus_Tollens]]_0"},{"heading":"<a data-href=\"Disjunctive Syllogism\" href=\"Disjunctive Syllogism\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Disjunctive Syllogism</a>","level":4,"id":"[[Disjunctive_Syllogism]]_0"},{"heading":"<a data-href=\"Hypothetical Syllogism\" href=\"Hypothetical Syllogism\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Hypothetical Syllogism</a>","level":4,"id":"[[Hypothetical_Syllogism]]_0"},{"heading":"<a data-href=\"Transformation Rules\" href=\"Transformation Rules\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Transformation Rules</a>","level":3,"id":"[[Transformation_Rules]]_0"},{"heading":"Implication Introduction","level":4,"id":"Implication_Introduction_0"},{"heading":"Biconditional Elimination / Introduction","level":4,"id":"Biconditional_Elimination_/_Introduction_0"},{"heading":"Conjunction Elimination / Introduction","level":4,"id":"Conjunction_Elimination_/_Introduction_0"},{"heading":"Disjunction Elimination / Introduction","level":4,"id":"Disjunction_Elimination_/_Introduction_0"},{"heading":"Proofs","level":2,"id":"Proofs_0"},{"heading":"Proof Systems","level":4,"id":"Proof_Systems_0"},{"heading":"<a data-href=\"Tautology\" href=\"Tautology\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Tautology</a> and Contradiction","level":3,"id":"[[Tautology]]_and_Contradiction_0"},{"heading":"Common Proof Techniques","level":3,"id":"Common_Proof_Techniques_0"},{"heading":"<a data-href=\"Direct Proof\" href=\"Direct Proof\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Direct Proof</a>","level":4,"id":"[[Direct_Proof]]_0"},{"heading":"<a data-href=\"Proof by Contradiction\" href=\"Proof by Contradiction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Proof by Contradiction</a>","level":4,"id":"[[Proof_by_Contradiction]]_0"},{"heading":"<a data-href=\"Proof by Contrapositive\" href=\"Proof by Contrapositive\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Proof by Contrapositive</a>","level":4,"id":"[[Proof_by_Contrapositive]]_0"},{"heading":"<a data-href=\"Resolution\" href=\"Resolution\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Resolution</a>","level":4,"id":"[[Resolution]]_0"},{"heading":"<a data-href=\"Mathematical Induction\" href=\"Mathematical Induction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Mathematical Induction</a>","level":4,"id":"[[Mathematical_Induction]]_0"},{"heading":"Applications","level":2,"id":"Applications_0"},{"heading":"Computer Science","level":3,"id":"Computer_Science_0"},{"heading":"Computer Engineering","level":3,"id":"Computer_Engineering_0"},{"heading":"Mathematics","level":3,"id":"Mathematics_0"},{"heading":"<a data-href=\"Game Theory\" href=\"Game Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Game Theory</a>","level":3,"id":"[[Game_Theory]]_0"},{"heading":"<a data-href=\"Control Theory\" href=\"Control Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Control Theory</a>","level":3,"id":"[[Control_Theory]]_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html","notes/math/first-order-logic.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/commutative-property.html#_0","notes/math/commutative-property.html#_0","notes/math/associative-property.html#_0","notes/math/associative-property.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/transitive-property.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/first-order-logic.html#_0",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html","pathToRoot":"../..","attachments":[],"createdTime":1754173984748,"modifiedTime":1757260326000,"sourceSize":30125,"sourcePath":"NOTES/Math/Propositional Logic.md","exportPath":"notes/math/propositional-logic.html","showInTree":true,"treeOrder":19,"backlinks":["index.html","notes/math/associative-property.html","notes/math/first-order-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/outlier.html":{"title":"Outlier","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-08Outliers are data points that differ significantly from the other observations in a dataset. Outliers may occur due to measurement or recording error, or could possibly represent an important anomaly warranting further analysis. There is no fixed definition of what constitutes as an outlier, typically, specific domain knowledge is usually necessary to understand whether a specific observation is an outlier, or is a natural phenomenon of the dataset.\nMeasurement Error: Outliers may occur due to user error in the data collection process, or could occur due to errors in autonomous systems, such as sensor failure.\nNatural Variation: Outliers may represent perfectly legitimate values that are an inherent part of the naturally occurring variations in the underlying domain of the dataset.\nAnomaly: Outliers may represent unusual behavior, such as fraudulent transactions, which warrant further investigation and analysis. Outliers can have a significant impact on various statistical measures, such as <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a>, <a data-href=\"Standard Deviation\" href=\"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Standard Deviation</a>, or <a data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Range</a>.\n<br>Outliers could also hinder the performance of some machine learning models such as <a data-href=\"Logistic Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logistic Regression</a> or <a data-href=\"K-Nearest-Neighbors\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">K-Nearest-Neighbors</a>. Global Outliers: A global outlier deviates significantly from the entire population globally.\nCollective Outliers: A group or subset of data points that collectively deviate considerably from the overall distribution. Typically, require special techniques to detect.\nContextual/Local Outliers: Data points whose value deviate significantly relative to other data points within the same \"context.\" Contextual outliers may not be considered outliers when considered globally, meaning they need special attention to be properly detected and analyzed.\nWhile the terms outliers and extreme values may be used interchangeably, they have distinct definitions in statistics:\nOutlier: is a data point that varies significantly from the rest of the dataset.\nExtreme values: values that reside at the outer edges of the dataset, representing the highest and lowest points in a dataset. Extreme values may be outliers, or they be a natural part of a distribution.\n<br>Z-score, sometimes called the standard score, measures how many <a data-tooltip-position=\"top\" aria-label=\"Standard Deviation\" data-href=\"Standard Deviation\" href=\"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Standard Deviations</a> a data object is from the <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> of the distribution. A positive z-score indicates the values is greater than the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"82\" to=\"86\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, while a negative score indicates it is less than the mean.Mathematically, the z-score is defined as:Where: is the z-score. is the given data value.\n<br> is the population <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"19\" to=\"23\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>.\n<br> is the population <a href=\"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"20\" to=\"38\" origin-text=\"standard deviation\" class=\"internal-link virtual-link-a\">standard deviation</a>.\nThe z-score is commonly used to detect outliers by flagging any values that are outside a specified threshold (commonly -3 and 3).<br>The Interquartile <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"18\" to=\"23\" origin-text=\"Range\" class=\"internal-link virtual-link-a\">Range</a> (IQR) is a measure of statistical dispersion that represents the range within which the central 50% of the data points lie.Mathematically, the IQR is defined as:Where:\n<br> is the value of the 3rd <a data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quartile</a>.\n<br> is the value of the 1st <a href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"25\" to=\"33\" origin-text=\"Quartile\" class=\"internal-link virtual-link-a\">Quartile</a>.\nThe IQR is commonly used to detect outliers by flagging any values that are outside of a specified boundary, typically:\nLower Bound: Upper Bound: Any data point below the lower bound or above the upper bound is considered an outlier.\n<br>K-Nearest Neighbors is a supervised machine learning algorithm which can be used for both classification and regression tasks. The algorithm relies on <a data-tooltip-position=\"top\" aria-label=\"Distance Metric\" data-href=\"Distance Metric\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Distance Metrics</a> such as <a data-href=\"Euclidean Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Euclidean Distance</a>, <a data-href=\"Manhattan Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/manhattan-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Manhattan Distance</a>, or <a data-href=\"Minkowski Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Minkowski Distance</a> to find the \"-nearest neighbors\" of a data object, where is a parameter indicating the number of neighbors to consider when making a prediction.\n<br>Regression: For regression tasks, the algorithm takes the average values of the k-nearest-neighbors of the data object, where the neighbors come from the training set. Then the <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> of the neighbors' values is the predicted value for the object.\nClassification: For classification tasks, a majority vote among the object's k-nearest-neighbors is taken to determine the category for the given data object.\nK-nearest-neighbors is used to detect outliers by assigning an outlier score to a data object, which is done by measuring the distance of an object from its nearest neighbors. Though, this approach is not effective for collective outliers.DBSCAN is a density-based clustering algorithm that clusters data based on the density of data points. DBSCAN excels at identifying an arbitrary number of clusters, and can handle nested clusters of arbitrary shapes.\nTwo parameters are chosen, represents the radius within which to classify neighbors; and minPts, which represents the minimum number of neighbors within to classify the point as a \"core point.\"\nA data point is considered a core point if the amount of other data points that falls within its radius is at least minPts.\nAfter all core points are identified, for each core point, create a cluster of the core point and all the points within its radius.\nExpand the cluster by iterating through all reachable points and adding them to the cluster if they're core points.\nPoints that are not reachable from any core points are labelled as noise or outliers.\nDBSCAN is popular algorithm for anomaly detection, since outliers are detected based on relative density of data.<br>One straightforward method for dealing with outliers is simply to remove them from the dataset. This approach if effective as long as outliers are not relevant to the analysis, such as the case where the focus is not on <a data-href=\"Anomaly Detection\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Anomaly Detection</a>.Transformations can be applied to the data to minimize the effect of outliers. Some popular techniques include:\n<br><a data-href=\"Scaling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Scaling</a>: Adjusting the <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"21\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of the data to reduce the influence of extreme values. This includes methods such as <a data-href=\"Min-Max Scaling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Min-Max Scaling</a> or <a data-href=\"Z-Score Normalization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Z-Score Normalization</a>.\n<br><a data-href=\"Winsorization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Winsorization</a>: Replacing outlier values with the nearest value within a specific percentile range. For example, any values outside the middle 95% percentile are replaced with the nearest values within that range.\n<br><a data-href=\"Log Transformation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Log Transformation</a>: Applying logarithmic transformations to reduce <a data-href=\"Variance\" href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Variance</a> and make the data more normally distributed.\n<br>Another approach to handling outliers is explicitly modeling them. This can be done by adding a new <a data-href=\"Binary Data\" href=\"https://emujakic.github.io/TechKB/notes/math/binary-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Binary Data</a> attribute that specifies whether a given data object is an outlier or not.\nJ. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>I. Cohen, “Outlier Detection &amp; Analysis: The Different Types of Outliers,”&nbsp;Anodot, Feb. 25, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.anodot.com/blog/quick-guide-different-types-outliers/\" target=\"_self\">https://www.anodot.com/blog/quick-guide-different-types-outliers/</a>\n<br>GeeksforGeeks, “Types of Outliers in Data Mining,”&nbsp;GeeksforGeeks, Jul. 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/data-analysis/types-of-outliers-in-data-mining/\" target=\"_self\">https://www.geeksforgeeks.org/data-analysis/types-of-outliers-in-data-mining/</a> (accessed Jul. 08, 2025).\n<br>S. Glen, “Outliers: Finding Them in Data, Formula, Examples. Easy Steps and Video,”&nbsp;Statistics How To. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.statisticshowto.com/statistics-basics/find-outliers/\" target=\"_self\">https://www.statisticshowto.com/statistics-basics/find-outliers/</a>\n<br>Wikipedia Contributors, “Outlier,”&nbsp;Wikipedia, Apr. 07, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Outlier\" target=\"_self\">https://en.wikipedia.org/wiki/Outlier</a>\n<br>GeeksforGeeks, “How to Detect Outliers in Machine Learning,”&nbsp;GeeksforGeeks, Jan. 12, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/machine-learning/machine-learning-outlier/\" target=\"_self\">https://www.geeksforgeeks.org/machine-learning/machine-learning-outlier/</a> (accessed Jul. 10, 2025).\n<br>Wikipedia Contributors, “Standard score,”&nbsp;Wikipedia, Sep. 12, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Standard_score\" target=\"_self\">https://en.wikipedia.org/wiki/Standard_score</a>\n","aliases":["Outliers"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Outlier","level":1,"id":"Outlier_0"},{"heading":"Causes of Outliers","level":3,"id":"Causes_of_Outliers_0"},{"heading":"Impact","level":3,"id":"Impact_0"},{"heading":"Types of Outliers","level":3,"id":"Types_of_Outliers_0"},{"heading":"Outliers vs. Extreme Values","level":3,"id":"Outliers_vs._Extreme_Values_0"},{"heading":"Detection","level":2,"id":"Detection_0"},{"heading":"<a data-href=\"Z-Score\" href=\"Z-Score\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Z-Score</a>","level":3,"id":"[[Z-Score]]_0"},{"heading":"Formula","level":4,"id":"Formula_0"},{"heading":"Application","level":4,"id":"Application_0"},{"heading":"<a data-href=\"Interquartile Range\" href=\"Interquartile Range\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Interquartile Range</a> (IQR)","level":3,"id":"[[Interquartile_Range]]_(IQR)_0"},{"heading":"Formula","level":4,"id":"Formula_1"},{"heading":"Application","level":4,"id":"Application_1"},{"heading":"<a data-href=\"K-Nearest Neighbors\" href=\"K-Nearest Neighbors\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">K-Nearest Neighbors</a>","level":3,"id":"[[K-Nearest_Neighbors]]_0"},{"heading":"Intuition","level":4,"id":"Intuition_0"},{"heading":"Application","level":4,"id":"Application_2"},{"heading":"<a data-tooltip-position=\"top\" aria-label=\"DBSCAN\" data-href=\"DBSCAN\" href=\"DBSCAN\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Density-Based Spatial Clustering of Applications with Noise</a> (DBSCAN)","level":3,"id":"[[DBSCAN|Density-Based_Spatial_Clustering_of_Applications_with_Noise]]_(DBSCAN)_0"},{"heading":"Intuition","level":4,"id":"Intuition_1"},{"heading":"Application","level":4,"id":"Application_3"},{"heading":"Handling Outliers","level":2,"id":"Handling_Outliers_0"},{"heading":"Removal","level":3,"id":"Removal_0"},{"heading":"Transformation","level":3,"id":"Transformation_0"},{"heading":"Explicit Modeling","level":3,"id":"Explicit_Modeling_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/mean.html#_0","notes/math/standard-deviation.html#_0","notes/math/range.html#_0",".html",".html",".html","notes/math/standard-deviation.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/standard-deviation.html#_0",".html","notes/math/range.html#_0","notes/math/quartile.html#_0","notes/math/quartile.html#_0",".html",".html","notes/math/euclidean-distance.html#_0","notes/math/manhattan-distance.html#_0",".html","notes/math/mean.html#_0",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html","notes/math/variance.html#_0","notes/math/binary-data.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/outlier.html","pathToRoot":"../..","attachments":[],"createdTime":1752013301145,"modifiedTime":1756435404209,"sourceSize":8379,"sourcePath":"NOTES/Math/Outlier.md","exportPath":"notes/math/outlier.html","showInTree":true,"treeOrder":17,"backlinks":["notes/math/euclidean-distance.html","notes/math/least-squares.html","notes/math/manhattan-distance.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/quantile.html","notes/math/quartile.html","notes/math/range.html","notes/math/standard-deviation.html"],"type":"markdown"},"notes/math/ordinal-data.html":{"title":"Ordinal Data","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-07Ordinal data is a type of <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a> that represents categories that a defined order or ranking. Unlike <a data-href=\"Nominal Data\" href=\"https://emujakic.github.io/TechKB/notes/math/nominal-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Nominal Data</a>, which has no intrinsic ordering, ordinal data allows for the comparison of the relative positioning of items.A key property of ordinal data is that the interval between adjacent ranks is not necessarily equal. For example, the interval between \"expensive\" and \"average\" is not necessarily equal to the interval between \"cheap\" and \"average.\"Another key property of Ordinal data is that it is non-numeric. While ordinal variables may be represented by numbers (e.g. 1, 2, 3), these numbers are only labels that indicate orders and not precise values.Examples of ordinal data include attributes like education levels (e.g. High School, Bachelor's, Masters), or survey responses (e.g. Unsatisfied, Neutral, Satisfied).The analysis of ordinal data requires specific statistical techniques that respect the inherent order of the categories while acknowledging that the intervals between them are not necessarily uniform.\n<br>The <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a> and <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a> can be used to summarize the central tendencies and identify the most frequent categories.\n<br><a data-tooltip-position=\"top\" aria-label=\"Bar Chart\" data-href=\"Bar Chart\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bar Charts</a> can visualize the frequency distribution of categories and illustrate the most common or uncommon values. <br>Because ordinal data does not meet the assumptions required for <a data-tooltip-position=\"top\" aria-label=\"Parametric Test\" data-href=\"Parametric Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Parametric Tests</a>, <a data-tooltip-position=\"top\" aria-label=\"Non-Parametric Test\" data-href=\"Non-Parametric Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Non-Parametric Tests</a>, such as <a data-href=\"Mann-Whitney U Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mann-Whitney U Test</a> or <a data-href=\"Kruskal-Wallis Test\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Kruskal-Wallis Test</a> are often used to analyze the difference between groups.\n<br><a data-href=\"Spearman's Rank\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Spearman's Rank</a> correlation can be used to assess relationships between ordinal attributes, providing potential insights on the strength and direction of correlations. J. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Haryana, India ; Burlington, Ma: Elsevier, 2018.\n<br>“Types of Data | Introduction to Data Science,”&nbsp;<a data-tooltip-position=\"top\" aria-label=\"http://www.stat.lsa.umich.edu\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://www.stat.lsa.umich.edu\" target=\"_self\">www.stat.lsa.umich.edu</a>. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://dept.stat.lsa.umich.edu/~kshedden/introds/topics/types_of_data/\" target=\"_self\">https://dept.stat.lsa.umich.edu/~kshedden/introds/topics/types_of_data/</a>\n<br>“Ordinal data,”&nbsp;Wikipedia, Apr. 03, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Ordinal_data\" target=\"_self\">https://en.wikipedia.org/wiki/Ordinal_data</a>\n","aliases":["Ordinal"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Ordinal Data","level":1,"id":"Ordinal_Data_0"},{"heading":"Unequal Intervals","level":4,"id":"Unequal_Intervals_0"},{"heading":"Non-Numeric","level":4,"id":"Non-Numeric_0"},{"heading":"Examples","level":4,"id":"Examples_0"},{"heading":"Analysis","level":2,"id":"Analysis_0"},{"heading":"Descriptive Statistics","level":3,"id":"Descriptive_Statistics_0"},{"heading":"Statistical Techniques","level":3,"id":"Statistical_Techniques_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/nominal-data.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0",".html",".html",".html",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/ordinal-data.html","pathToRoot":"../..","attachments":[],"createdTime":1751919439086,"modifiedTime":1754247549994,"sourceSize":2402,"sourcePath":"NOTES/Math/Ordinal Data.md","exportPath":"notes/math/ordinal-data.html","showInTree":true,"treeOrder":16,"backlinks":["notes/math/measure-of-central-tendency.html","notes/math/nominal-data.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"notes/math/nominal-data.html":{"title":"Nominal Data","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-07Nominal data is a type of <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a> that represents categories that don't have a specific order or ranking. Unlike <a data-href=\"Ordinal Data\" href=\"https://emujakic.github.io/TechKB/notes/math/ordinal-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ordinal Data</a>, which has a defined order, nominal data is purely qualitative. It describes specific qualities without conveying any measure of numerical significance.<br>Since nominal data lacks numerical significance, data operations such as <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a> or <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a> cannot be performed. However, the frequency of nominal data values can be analyzed, and a measure like the <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a> can describe the most common category within a given dataset.<br>A specific type of nominal data is <a data-href=\"Binary Data\" href=\"https://emujakic.github.io/TechKB/notes/math/binary-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Binary Data</a>, which consists of only two categories, typically represented as 1 and 0. Binary fields are commonly used to represent whether a certain feature is present or not in a given data object.Examples of nominal data include attributes like eye color (e.g., blue, brown, green), gender (e.g., male, female, non-binary), and nationality (e.g., American, Canadian). These categories do not imply any hierarchy or order.<br>Nominal data, lacking any numerical significance, primarily relies on frequency distribution analysis for meaningful insights. One of the most effective techniques for this is the use of a <a data-href=\"Bar Chart\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bar Chart</a>, which visually represent the frequency of each category.\nJ. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Haryana, India ; Burlington, Ma: Elsevier, 2018.\n<br>“Types of Data | Introduction to Data Science,”&nbsp;_<a data-tooltip-position=\"top\" aria-label=\"http://www.stat.lsa.umich.edu.\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://www.stat.lsa.umich.edu.\" target=\"_self\">www.stat.lsa.umich.edu.</a> <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://dept.stat.lsa.umich.edu/~kshedden/introds/topics/types_of_data/\" target=\"_self\">https://dept.stat.lsa.umich.edu/~kshedden/introds/topics/types_of_data/</a>\nWikipedia Contributors, “Nominal category,”&nbsp;Wikipedia, Oct. 07, 2024.\n","aliases":["Nominal"],"inlineTags":[],"frontmatterTags":["#math","#statistics","#unfinished"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Nominal Data","level":1,"id":"Nominal_Data_0"},{"heading":"No Numerical Significance","level":4,"id":"No_Numerical_Significance_0"},{"heading":"<span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Binary Data.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"0\" to=\"11\" origin-text=\"Binary Data\" class=\"internal-link virtual-link-a\">Binary Data</a></span>","level":4,"id":"Binary_Data_0"},{"heading":"Examples","level":4,"id":"Examples_0"},{"heading":"Analysis","level":4,"id":"Analysis_0"},{"heading":"Encoding","level":2,"id":"Encoding_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/ordinal-data.html#_0","notes/math/mean.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0","notes/math/binary-data.html#_0","notes/math/binary-data.html#_0",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/nominal-data.html","pathToRoot":"../..","attachments":[],"createdTime":1751914187819,"modifiedTime":1756434962714,"sourceSize":1919,"sourcePath":"NOTES/Math/Nominal Data.md","exportPath":"notes/math/nominal-data.html","showInTree":true,"treeOrder":15,"backlinks":["notes/math/binary-data.html","notes/math/measure-of-central-tendency.html","notes/math/ordinal-data.html"],"type":"markdown"},"notes/math/mode.html":{"title":"Mode","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-08The mode is a <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a> which represents the most frequently occurring value in a dataset or population. The mode is particularly versatile since it can be applied to both <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a> and <a data-href=\"Numerical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Numerical Data</a>.\nUnimodal: A dataset with only one mode.\nBimodal: A dataset with exactly two modes.\nMultimodal: A dataset with three or more modes.\n<br>In a discrete <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"14\" to=\"25\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distribution, the mode is the value that has the highest probability of occurring.<br>In a continuous <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"27\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distribution, the mode is the value at which the <a data-href=\"Probability Density Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Density Function</a> reaches its maximum. It represents the peak of the distribution.<br>Other common <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measures of Central Tendency</a> include the <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a>, which represents the middle value when the data is ordered, the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a>, which represents the average value of a population, and the <a data-href=\"Midrange\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Midrange</a>, calculated as the average of the maximum and minimum values.\nJ. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Mode in Statistics | Definition, Formula, How to Calculate Mode,”&nbsp;GeeksforGeeks, Sep. 20, 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/what-is-mode/\" target=\"_self\">https://www.geeksforgeeks.org/maths/what-is-mode/</a>\n<br>Wikipedia Contributors, “Mode (statistics),”&nbsp;Wikipedia, Oct. 10, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Mode_(statistics)\" target=\"_self\">https://en.wikipedia.org/wiki/Mode_(statistics)</a>\n","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Mode","level":1,"id":"Mode_0"},{"heading":"Types of Modes","level":3,"id":"Types_of_Modes_0"},{"heading":"Mode in <a data-href=\"Probability Distributions\" href=\"Probability Distributions\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Probability Distributions</a>","level":2,"id":"Mode_in_[[Probability_Distributions]]_0"},{"heading":"<a data-href=\"Discrete Probability Distribution\" href=\"Discrete Probability Distribution\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Discrete Probability Distribution</a>","level":4,"id":"[[Discrete_Probability_Distribution]]_0"},{"heading":"<a data-href=\"Continuous Probability Distribution\" href=\"Continuous Probability Distribution\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Continuous Probability Distribution</a>","level":4,"id":"[[Continuous_Probability_Distribution]]_0"},{"heading":"Other <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Measure of Central Tendency.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"6\" to=\"34\" origin-text=\"Measures of Central Tendency\" class=\"internal-link virtual-link-a\">Measures of Central Tendency</a></span>","level":2,"id":"Other_Measures_of_Central_Tendency_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/measure-of-central-tendency.html#_0",".html",".html",".html",".html","notes/math/probability.html#_0",".html","notes/math/probability.html#_0",".html","notes/math/measure-of-central-tendency.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/median.html#_0","notes/math/mean.html#_0",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/mode.html","pathToRoot":"../..","attachments":[],"createdTime":1752009968333,"modifiedTime":1756435446906,"sourceSize":1719,"sourcePath":"NOTES/Math/Mode.md","exportPath":"notes/math/mode.html","showInTree":true,"treeOrder":14,"backlinks":["notes/math/binary-data.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/nominal-data.html","notes/math/ordinal-data.html"],"type":"markdown"},"notes/math/median.html":{"title":"Median","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-07The Median is a <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a> that represents the middle value of an ordered dataset. It is particularly useful in scenarios where the data is skewed or contains <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">outliers</a>, as it provides a more accurate representation of the center of the dataset compared to other measures like the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a>. The median can only be applied to <a data-href=\"Numerical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Numerical Data</a> and not <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a>.<br>The median is defined as the 50th <a data-href=\"Percentile\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Percentile</a> or the second <a data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quartile</a> (Q2), which divides the dataset into two equal halves. This means that half of the data points are below the median and half are above it.\nUniqueness: In a finite dataset, the median is unique, meaning there is only one median.\n<br>Robustness: The median is robust to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"26\" to=\"34\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>, making it a reliable measure in skewed or noisy datasets.\nNon-Parametric: The median does not assume a particular distribution of the underlying data.\nInvariance: The median remains unchanged under linear transformations of the dataset.\nIf is even, the formula for the median is:While if is odd, the formula for the median is:<br>The multivariate median extends the concept of the median to multiple dimensions. One of the most common multivariate median is the <a data-href=\"Geometric Median\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Geometric Median</a> which focuses on minimizing the <a data-tooltip-position=\"top\" aria-label=\"Euclidean Distance\" data-href=\"Euclidean Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Euclidean distance</a> of a set of points in a Euclidean space. The geometric median is defined as:Where:\n<br> denotes the <a href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"13\" to=\"31\" origin-text=\"Euclidean distance\" class=\"internal-link virtual-link-a\">Euclidean distance</a>. represents the -th data point in -dimensional space. <br>Machine Learning: Multivariate medians are commonly employed in machine learning, particularly in clustering algorithms when dealing with centroid initialization, such as in <a data-href=\"DBSCAN\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">DBSCAN</a>.\nComputer Vision: The geometric median can be used to find a central point among pixel locations, helping in tasks such as object tracking.\n<br><a data-href=\"Robust Statistics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Robust Statistics</a>: Multivariate medians are utilized as a <a href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"41\" to=\"68\" origin-text=\"measure of central tendency\" class=\"internal-link virtual-link-a\">measure of central tendency</a> over other measures such as the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"101\" to=\"105\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, due to median's robustness to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"137\" to=\"145\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>.\n<br>Other common <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measures of Central Tendency</a> include the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a>, which represents the average value of a population, the <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a>, which identifies the most frequently occurring value in a set, and the <a data-href=\"Midrange\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Midrange</a>, calculated as the average of the maximum and minimum values.\nJ. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>Wikipedia, “Median,”&nbsp;Wikipedia, Apr. 17, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Median\" target=\"_self\">https://en.wikipedia.org/wiki/Median</a>\n","aliases":["Medians"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Median","level":1,"id":"Median_0"},{"heading":"Definition","level":4,"id":"Definition_0"},{"heading":"Properties","level":4,"id":"Properties_0"},{"heading":"Formula","level":2,"id":"Formula_0"},{"heading":"Multivariate Median","level":2,"id":"Multivariate_Median_0"},{"heading":"Applications","level":3,"id":"Applications_0"},{"heading":"Other <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Measure of Central Tendency.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"6\" to=\"34\" origin-text=\"Measures of Central Tendency\" class=\"internal-link virtual-link-a\">Measures of Central Tendency</a></span>","level":2,"id":"Other_Measures_of_Central_Tendency_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/measure-of-central-tendency.html#_0","notes/math/outlier.html#_0","notes/math/mean.html#_0",".html",".html",".html","notes/math/quartile.html#_0","notes/math/outlier.html#_0",".html","notes/math/euclidean-distance.html#_0","notes/math/euclidean-distance.html#_0",".html",".html","notes/math/measure-of-central-tendency.html#_0","notes/math/mean.html#_0","notes/math/outlier.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/mean.html#_0","notes/math/mode.html#_0",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/median.html","pathToRoot":"../..","attachments":[],"createdTime":1751927785580,"modifiedTime":1754247536481,"sourceSize":3023,"sourcePath":"NOTES/Math/Median.md","exportPath":"notes/math/median.html","showInTree":true,"treeOrder":13,"backlinks":["notes/math/binary-data.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/mode.html","notes/math/nominal-data.html","notes/math/ordinal-data.html","notes/math/quantile.html","notes/math/quartile.html"],"type":"markdown"},"notes/math/measure-of-central-tendency.html":{"title":"Measure of Central Tendency","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-06A measure of central tendency is a statistical measure that attempts to describe the center of a dataset. The measure attempts to summarize the dataset with a single value that represents the middle or \"average\" of the data. The most common measures are the <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a>, <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a>, and <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a>. Depending on the characteristics of the underlying dataset, one measure may be more appropriate than the others.<br> <img alt=\"Pasted image 20250708171735.png\" src=\"https://emujakic.github.io/TechKB/resources/pasted-image-20250708171735.png\" target=\"_self\"><br>\n<a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.studyforfe.com/blog/measures-of-central-tendencies-and-dispersions\" target=\"_self\">https://www.studyforfe.com/blog/measures-of-central-tendencies-and-dispersions</a><br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, often referred to as the average, is one of the most widely used measures of central tendency. There are various types of means, with the arithmetic mean being the most common. The arithmetic mean is calculated by summing all values in a dataset and dividing by the number of values.<br>The sample <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"11\" to=\"15\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, denoted as , is defined by the formula:Where is the number of values in the dataset.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> is sensitive to <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">outliers</a>, so it may not provide an accurate representation of the center when the underlying dataset is asymmetric, or has many extreme <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"128\" to=\"136\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>. For symmetric distributions, the mean is a useful measure that provides the average value of the dataset.\nThe mean is often used in algorithms such as linear regression, where it helps minimize error in predictions.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"10\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> is the middle value of a dataset when it is ordered. If there is an even number of values, then the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"111\" to=\"115\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> (average) of the two middlemost values are taken.<br>If is even, the formula for the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"30\" to=\"36\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> is:<br>While if is odd, the formula for the <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"29\" to=\"35\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> is:\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"10\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a> is less susceptible to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"34\" to=\"42\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a> than the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"52\" to=\"56\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a>, therefore, it provides a more accurate measure of the center for skewed distributions.\n<br>In data science and machine learning, the <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"42\" to=\"46\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> is useful for categorical variables, such as determining the most common class label in classification tasks.\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> of a dataset is the value that appears most frequently. A dataset can have:\n<br>One <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> (unimodal)\nTwo modes (bimodal)\nMultiple modes (multimodal)\n<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> is useful for analyzing <a data-href=\"Nominal Data\" href=\"https://emujakic.github.io/TechKB/notes/math/nominal-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Nominal Data</a>, as it helps identify the most \"popular\" category within a given set of values.<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> can be defined as:Where is the frequency of the value in a given dataset.\n<br>Unlike the <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"11\" to=\"15\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> or <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"19\" to=\"25\" origin-text=\"median\" class=\"internal-link virtual-link-a\">median</a>, the <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"31\" to=\"35\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a> can be directly applied to <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a>, making it one of the most simple and versatile measures of central tendency. J. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Amsterdam ; Boston: Elsevier/Morgan Kaufmann, 2012.\n<br>Laerd Statistics, “Measures of central tendency,”&nbsp;Laerd Statistics, 2018. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://statistics.laerd.com/statistical-guides/measures-central-tendency-mean-mode-median.php\" target=\"_self\">https://statistics.laerd.com/statistical-guides/measures-central-tendency-mean-mode-median.php</a>\n<br>“Central tendency,”&nbsp;Wikipedia, Jul. 13, 2020. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Central_tendency\" target=\"_self\">https://en.wikipedia.org/wiki/Central_tendency</a>\n","aliases":["Measures of Central Tendency"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Measure of Central Tendency","level":1,"id":"Measure_of_Central_Tendency_0"},{"heading":"<span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Mean.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"0\" to=\"4\" origin-text=\"Mean\" class=\"internal-link virtual-link-a\">Mean</a></span>","level":2,"id":"Mean_0"},{"heading":"Properties","level":3,"id":"Properties_0"},{"heading":"<span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Median.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"0\" to=\"6\" origin-text=\"Median\" class=\"internal-link virtual-link-a\">Median</a></span>","level":2,"id":"Median_0"},{"heading":"Properties","level":3,"id":"Properties_1"},{"heading":"<span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Mode.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"0\" to=\"4\" origin-text=\"Mode\" class=\"internal-link virtual-link-a\">Mode</a></span>","level":2,"id":"Mode_0"},{"heading":"Properties","level":3,"id":"Properties_2"},{"heading":"Summary of When to Use Each Measure","level":2,"id":"Summary_of_When_to_Use_Each_Measure_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/mean.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/mean.html#_0","notes/math/outlier.html#_0","notes/math/outlier.html#_0","notes/math/median.html#_0","notes/math/median.html#_0","notes/math/mean.html#_0","notes/math/median.html#_0","notes/math/median.html#_0","notes/math/median.html#_0","notes/math/outlier.html#_0","notes/math/mean.html#_0","notes/math/mode.html#_0","notes/math/mode.html#_0","notes/math/mode.html#_0","notes/math/mode.html#_0","notes/math/mode.html#_0","notes/math/nominal-data.html#_0","notes/math/mode.html#_0","notes/math/mean.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0",".html","notes/math/nominal-data.html#_0","notes/math/mode.html#_0","notes/math/ordinal-data.html#_0","notes/math/median.html#_0","notes/math/mean.html#_0"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/HTML/resources/pasted-image-20250708171735.png","fullURL":"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html","pathToRoot":"../..","attachments":["resources/pasted-image-20250708171735.png"],"createdTime":1751847846892,"modifiedTime":1754247539565,"sourceSize":3814,"sourcePath":"NOTES/Math/Measure of Central Tendency.md","exportPath":"notes/math/measure-of-central-tendency.html","showInTree":true,"treeOrder":12,"backlinks":["notes/math/mean.html","notes/math/median.html","notes/math/mode.html","notes/math/probability.html","notes/math/quantile.html","notes/math/variance.html"],"type":"markdown"},"notes/math/mean.html":{"title":"Mean","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-04The mean is a <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a> which attempts to summarize an entire dataset with a single number. It provides an illustration of the average value within a collection of values, making it essential for data analysis tasks. The mean can only be applied to <a data-href=\"Numerical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Numerical Data</a> and not <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a>.<br>There are several types of means, each suited for different applications and fields. The most commonly used type is the arithmetic mean, which is calculated by summing all values and dividing by the number of observations. Other variations include the geometric mean, often used in financial contexts, the harmonic mean, which is beneficial in situations involving rates, and <a data-href=\"Root-Mean Square\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Root-Mean Square</a>, often used to measure the average voltage of an AC source.<br>Other common <a data-tooltip-position=\"top\" aria-label=\"Measure of Central Tendency\" data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measures of Central Tendency</a> include the <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a>, which represents the middle value when the data is ordered, the <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a>, which identifies the most frequently occurring value in a set, and the <a data-href=\"Midrange\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Midrange</a>, calculated as the average of the maximum and minimum values.<br>The arithmetic mean, commonly referred to as the average, is the sum of all values in a dataset divided by the number of values. It is the most widely used <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a>.There are two types of arithmetic means:\nSample Mean (): This represents the average value of a subset drawn from a larger population.\nGroup Mean (): This denotes the average of values within a specific category or attribute of a dataset.\nThe formula for calculating the sample mean is:Where: is the sample mean. is the number of values in the dataset. is the value of an individual object at index i.\n<br>The arithmetic mean is commonly used in statistics to summarize datasets and provide a simple <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a>. Though an arithmetic mean is susceptible to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"46\" to=\"54\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>, making it a less relevant metric for skewed datasets.<br>The trimmed mean is an arithmetic mean which discards a specified number of values from both ends of the value <a data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Range</a>. This is done to minimize the effect of <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">outliers</a> on the mean, which can skew the results. The trimmed mean generally gives a more accurate representation of the center making it particularly useful in datasets prone to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"171\" to=\"179\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a> or extreme variations.<br>The <a data-href=\"Interquartile\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Interquartile</a> Mean is a specific type of trimmed mean that excludes the first and last <a data-href=\"Quartile\" href=\"https://emujakic.github.io/TechKB/notes/math/quartile.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quartile</a> of ordered data. This results in the average of the middle 50% of values, offering a robust <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a> that is less influenced by extreme values.The formula for the trimmed mean is:The formula for the Interquartile mean is:<br>The trimmed mean is useful for analyzing skewed datasets, or datasets that have large amount of <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"96\" to=\"104\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>. The trimmed mean offers a more stable measure that is less affected by outliers, making it valuable across various disciplines.In a weighted mean, instead of each value contributing equally like in an arithmetic mean, each value is assigned a weight (or coefficient) based on its significance. This allows for a more nuanced average that reflects the importance of different contributions. The arithmetic mean is a weighted mean where all weights are equal.The formula for calculating the weighted mean is:<br>The weighted mean is used when there is a need to model the relative importance of various attributes. This is commonly seen in artificial intelligence techniques such as <a data-href=\"Ensemble Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ensemble Machine Learning</a> algorithms.The harmonic mean calculates the average of a set of numbers that are defined in relation to some unit. It is calculated by taking the reciprocal of the arithmetic mean of the reciprocals of each value in the dataset.The formula for the harmonic mean is:<br>In <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a>, the harmonic mean is commonly used to calculate the <a data-href=\"F1 Score\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">F1 Score</a> of a model. It is also commonly used when analyzing speed and rates, such as finding the average speed of multiple segments of a journey.<br>The geometric mean calculates the average of a set of values by using the product of values rather than their sum. It involves multiplying all the values in the dataset and then taking the th root of that product, where is the total number of values in the set. The geometric mean is less susceptible to <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">outliers</a> than the arithmetic mean since each value is part of a product rather than a sum.It is called the geometric mean because it's commonly used to find the side length of a square that has the same area as a rectangle with given side lengths. For example, if you have a rectangle with dimensions , the length of a square with equal volume is the geometric mean of and , which is .The formula for the geometric mean is:<br>The geometric mean is commonly used to calculate average rates of return on investments over time. The geometric mean can also be employed in <a data-href=\"Data Normalization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Data Normalization</a> to normalize features, particularly when the values span multiple orders of magnitude.The root mean square (RMS), often denoted as , is an average of the magnitude of a set of values, and is and is also known as the quadratic mean. It is particularly useful in sets with values of both positive and negative numbers. RMS is calculated by taking the square root of the arithmetic average of the squared values.For a continuous function defined over the interval , the RMS is determined by squaring the function, averaging the squared values over the interval, and then taking the square root of that average.The formula for discrete RMS is:The formula for continuous RMS is:Root-mean square is widely used in signal processing the measure the power of AC currents and voltages. In regression analysis, the RMS error is a common metric for evaluation the performance of a model. RMS is also used to evaluate the performance of control systems regarding the stability and responsiveness to input signals. RMS can also be used in optimization algorithms for neural networks, such as RMSprop.<br>The mean of a <a data-href=\"Probability Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Distribution</a> represents the average outcome of some <a data-href=\"Random Variable\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Random Variable</a>. It is a specific type of weighted mean where each outcome of some random variable is weighted by the <a data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability</a> of that outcome occurring.<br>The <a data-href=\"Expected Value\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Expected Value</a> of a random variable, denoted as , is the weighted average of its possible outcomes. This concept is crucial in various fields, including artificial intelligence, especially in the context of stochastic task environments, where uncertainty plays a significant role.<br>For discrete <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"13\" to=\"24\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distributions, the expected value is defined as:<br>Where is the <a data-href=\"Probability Mass Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Mass Function</a>.<br>For continuous <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"15\" to=\"26\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distributions, the expected value is defined as:<br>Where is the <a data-href=\"Probability Density Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Density Function</a>.<br>The expected value is a fundamental metric in decision theory for AI systems, guiding the decision-making process by allowing agents to evaluate actions based on their expected rewards. Expected value is also important in game theory for evaluating strategies based on their expected payoffs. In <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a>, the expected value is used for supervised techniques, particularly for loss functions.<br>The mean of a continuous function over a specific interval is defined as the integral of the function divided by the length of the interval. <a data-href=\"Root-Mean Square\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Root-Mean Square</a> is a type of mean of a function.The formula for the mean of a continuous function defined over the interval is:<br>The mean of a function has many applications, such as in statistics, where it provides the <a data-href=\"Measure of Central Tendency\" href=\"https://emujakic.github.io/TechKB/notes/math/measure-of-central-tendency.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Measure of Central Tendency</a> for continuous random variables. It is also commonly applied in machine learning when performing feature engineering, such as when normalizing data.\n<br>S. Glen, “Mean, <a href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"16\" to=\"22\" origin-text=\"Median\" class=\"internal-link virtual-link-a\">Median</a>, <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"24\" to=\"28\" origin-text=\"Mode\" class=\"internal-link virtual-link-a\">Mode</a>: What They Are, How to Find Them,”&nbsp;Statistics How To, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-median-mode/\" target=\"_self\">https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-median-mode/</a>\n<br>Wikipedia contributors, “Mean,” Wikipedia, Apr. 25, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Mean\" target=\"_self\">https://en.wikipedia.org/wiki/Mean</a>\n<br>J. Frost, “What is the Mean in Statistics?,”&nbsp;Statistics By Jim, Aug. 21, 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://statisticsbyjim.com/basics/mean_average/\" target=\"_self\">https://statisticsbyjim.com/basics/mean_average/</a>\nJ. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Amsterdam ; Boston: Elsevier/Morgan Kaufmann, 2012.\n<br>“Expectation | Mean | Average,”&nbsp;<a data-tooltip-position=\"top\" aria-label=\"http://www.probabilitycourse.com\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"http://www.probabilitycourse.com\" target=\"_self\">www.probabilitycourse.com</a>. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.probabilitycourse.com/chapter3/3_2_2_expectation.php\" target=\"_self\">https://www.probabilitycourse.com/chapter3/3_2_2_expectation.php</a>\n‌","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Mean","level":1,"id":"Mean_0"},{"heading":"Other <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Measure of Central Tendency.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"6\" to=\"34\" origin-text=\"Measures of Central Tendency\" class=\"internal-link virtual-link-a\">Measures of Central Tendency</a></span>","level":4,"id":"Other_Measures_of_Central_Tendency_0"},{"heading":"Types of Means","level":2,"id":"Types_of_Means_0"},{"heading":"Arithmetic Mean","level":3,"id":"Arithmetic_Mean_0"},{"heading":"Formula","level":4,"id":"Formula_0"},{"heading":"Application","level":4,"id":"Application_0"},{"heading":"Trimmed Mean / Interquartile Mean","level":3,"id":"Trimmed_Mean_/_Interquartile_Mean_0"},{"heading":"Formula","level":4,"id":"Formula_1"},{"heading":"Application","level":4,"id":"Application_1"},{"heading":"Weighted Mean","level":3,"id":"Weighted_Mean_0"},{"heading":"Formula","level":4,"id":"Formula_2"},{"heading":"Application","level":4,"id":"Application_2"},{"heading":"<a data-href=\"Harmonic Mean\" href=\"Harmonic Mean\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Harmonic Mean</a>","level":3,"id":"[[Harmonic_Mean]]_0"},{"heading":"Formula","level":4,"id":"Formula_3"},{"heading":"Application","level":4,"id":"Application_3"},{"heading":"<a data-href=\"Geometric Mean\" href=\"Geometric Mean\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Geometric Mean</a>","level":3,"id":"[[Geometric_Mean]]_0"},{"heading":"Formula","level":4,"id":"Formula_4"},{"heading":"Application","level":4,"id":"Application_4"},{"heading":"<a data-href=\"Root-Mean Square\" href=\"Root-Mean Square\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Root-Mean Square</a>","level":3,"id":"[[Root-Mean_Square]]_0"},{"heading":"Formula","level":4,"id":"Formula_5"},{"heading":"Application","level":4,"id":"Application_5"},{"heading":"<a data-href=\"Expected Value\" href=\"Expected Value\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Expected Value</a> / Mean of a <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/Probability.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"13\" to=\"24\" origin-text=\"Probability\" class=\"internal-link virtual-link-a\">Probability</a></span> Distribution","level":3,"id":"[[Expected_Value]]_/_Mean_of_a_Probability_Distribution_0"},{"heading":"Formula","level":4,"id":"Formula_6"},{"heading":"Application","level":4,"id":"Application_6"},{"heading":"Mean of a Function","level":3,"id":"Mean_of_a_Function_0"},{"heading":"Formula","level":4,"id":"Formula_7"},{"heading":"Application","level":4,"id":"Application_7"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/measure-of-central-tendency.html#_0",".html",".html",".html","notes/math/measure-of-central-tendency.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0",".html","notes/math/measure-of-central-tendency.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/outlier.html#_0","notes/math/range.html#_0","notes/math/outlier.html#_0","notes/math/outlier.html#_0",".html","notes/math/quartile.html#_0","notes/math/measure-of-central-tendency.html#_0","notes/math/outlier.html#_0",".html",".html",".html",".html",".html","notes/math/outlier.html#_0",".html",".html",".html","notes/math/probability.html#_0",".html",".html","notes/math/probability.html#_0",".html","notes/math/probability.html#_0",".html","notes/math/probability.html#_0",".html",".html",".html","notes/math/measure-of-central-tendency.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/mean.html","pathToRoot":"../..","attachments":[],"createdTime":1751668570756,"modifiedTime":1757260326000,"sourceSize":10021,"sourcePath":"NOTES/Math/Mean.md","exportPath":"notes/math/mean.html","showInTree":true,"treeOrder":11,"backlinks":["notes/math/binary-data.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/mode.html","notes/math/nominal-data.html","notes/math/outlier.html","notes/math/probability.html","notes/math/quantile.html","notes/math/range.html","notes/math/standard-deviation.html","notes/math/variance.html","textbooks/computer-organization-and-design-risc-v-edition-summary.html"],"type":"markdown"},"notes/math/manhattan-distance.html":{"title":"Manhattan Distance","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-31The Manhattan distance is a <a data-href=\"Distance Measure\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Distance Measure</a> defined as the sum of the absolute differences of the Cartesian coordinates of two points. It is the distance between two points using only grid-like movements (horizontal and vertical). The Manhattan distance is also the norm of the distance between two vectors in <a data-href=\"Lp Space\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Lp Space</a>.The Manhattan distance between two objects in -dimensional space is calculated as:\n<br>Positive: Like any other distance metric, the <a data-tooltip-position=\"top\" aria-label=\"Range\" data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">range</a> of the Manhattan distance is where a 0 distance indicates that the two points are at the same location.\nSymmetric: The Manhattan distance is symmetric, meaning <br><a data-href=\"Triangle Inequality\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Triangle Inequality</a>: The Manhattan distance obeys the triangle inequality, which states that the distance from to is always less than or equal to the distance from to plus the distance from to . Meaning that taking a detour through a third point cannot result in a shorter distance than a direct path from to . <br><a data-href=\"Clustering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Clustering</a>: Manhattan distance may be used in clustering algorithms like <a data-href=\"K-Means Clustering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">K-Means Clustering</a> to group similar data points.\n<br><a data-href=\"Classification\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Classification</a>: The Manhattan distance may be employed in distance-based classification algorithms such as <a data-href=\"K-Nearest-Neighbors\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">K-Nearest-Neighbors</a>. Measuring Pixel Differences: The Manhattan distance, or other distance measures, may be employed to compare pixel values, or features in image recognition tasks. <br>The Manhattan distance can be used for calculating the shortest path between points. It is also an <a data-href=\"Admissible\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Admissible</a> and <a data-href=\"Consistent\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Consistent</a> <a data-href=\"Heuristic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heuristic</a> in search algorithms such as <a data-href=\"A* Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">A* Search</a>.\nGrid-Navigation: The Manhattan distance is particularly useful for pathfinding in domains which only allow grid-like movements, such as a chessboard or a city network. <br><a data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outlier</a> Detection: Manhattan distance can be used for distance based <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"52\" to=\"59\" origin-text=\"outlier\" class=\"internal-link virtual-link-a\">outlier</a> detection algorithms such as <a data-href=\"DBSCAN\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">DBSCAN</a>.\n<br><a data-href=\"Multidimensional Scaling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multidimensional Scaling</a>: Manhattan distance may be employed to visualize higher-dimensional data into lower dimensions.\nOther common distance measures include:\n<br><a data-href=\"Euclidean Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Euclidean Distance</a>: The <a href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"6\" to=\"28\" origin-text=\"straight-line distance\" class=\"internal-link virtual-link-a\">straight-line distance</a> between 2 points in Euclidean space.\n<br><a data-href=\"Chebyshev Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Chebyshev Distance</a>: The maximum absolute difference between 2 vectors across all dimensions.\n<br><a data-href=\"Minkowski Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Minkowski Distance</a>: A generalized distance measure that is defined by a parameter whose common values are the Manhattan distance, Euclidean distance, and Chebyshev distance.\n<br><a data-href=\"Jaccard Index\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Jaccard Index</a>: Used to compare sets and is defined as the size of the intersection of 2 sets, over the size of their union. J. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Haryana, India ; Burlington, Ma: Elsevier, 2018.\n<br>“Taxicab geometry,”&nbsp;Wikipedia, Jan. 21, 2022. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Taxicab_geometry\" target=\"_self\">https://en.wikipedia.org/wiki/Taxicab_geometry</a>\n<br>GeeksforGeeks, “Clustering Distance Measures,”&nbsp;GeeksforGeeks, May 24, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/machine-learning/clustering-distance-measures/#common-distance-measures\" target=\"_self\">https://www.geeksforgeeks.org/machine-learning/clustering-distance-measures/#common-distance-measures</a> (accessed Jul. 31, 2025).\n","aliases":["City Block Distance"],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Manhattan Distance","level":1,"id":"Manhattan_Distance_0"},{"heading":"Properties","level":3,"id":"Properties_0"},{"heading":"Applications","level":2,"id":"Applications_0"},{"heading":"<a data-href=\"Machine Learning\" href=\"Machine Learning\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Machine Learning</a>","level":3,"id":"[[Machine_Learning]]_0"},{"heading":"<a data-href=\"Computer Vision\" href=\"Computer Vision\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Computer Vision</a>","level":3,"id":"[[Computer_Vision]]_0"},{"heading":"Pathfinding","level":3,"id":"Pathfinding_0"},{"heading":"Statistics","level":3,"id":"Statistics_0"},{"heading":"Other Distance Measures","level":2,"id":"Other_Distance_Measures_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/outlier.html#_0","notes/math/outlier.html#_0",".html",".html","notes/math/euclidean-distance.html#_0","notes/math/euclidean-distance.html#_0",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/manhattan-distance.html","pathToRoot":"../..","attachments":[],"createdTime":1753987116983,"modifiedTime":1754247526013,"sourceSize":3486,"sourcePath":"NOTES/Math/Manhattan Distance.md","exportPath":"notes/math/manhattan-distance.html","showInTree":true,"treeOrder":10,"backlinks":["notes/math/euclidean-distance.html","notes/math/outlier.html"],"type":"markdown"},"notes/math/least-squares.html":{"title":"Least Squares","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-21The least squares method is an optimization technique that attempts to find a linear function which minimizes the sum of squared distances between observed and predicted values. This method is widely used in <a data-href=\"Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Regression</a> analysis for finding the best-fit function between a matrix of features and one or more independent variables.<br><img alt=\"linearRegression.png\" src=\"https://emujakic.github.io/TechKB/resources/linearregression.png\" target=\"_self\"><br>In a <a data-href=\"Simple Linear Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Simple Linear Regression</a>, the model is defined as:Where: is the dependent variable. is the slope of the line. is the independent variable. is the y-intercept.\n<br>The objective is to minimize the sum of squared <a data-tooltip-position=\"top\" aria-label=\"Euclidean Distance\" data-href=\"Euclidean Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Euclidean distances</a>:Where: is the number of data points. are the observed data points.\nThis is equivalent to min\nCalculate Slope: Use the following formula to calculate the slope, : Calculate Y-Intercept: Use the slope calculated in the previous step and the following formula to calculate the y-intercept, : Formulate the Function: Construct the line of best fit in the form of <br>Sensitive to <a data-tooltip-position=\"top\" aria-label=\"Outlier\" data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outliers</a>:The least squares method is sensitive to <a href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"42\" to=\"50\" origin-text=\"outliers\" class=\"internal-link virtual-link-a\">outliers</a>, which could unfairly skew the resulting regression line, resulting in inaccurate predictions.\n<br>Assumes Linearity: The least squares method assumes a linear relationship between the dependent and independent variables. If the underlying relationship is non-linear, this can introduce <a data-href=\"Bias\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bias</a> in the predictions.\n<br>Assumes <a data-href=\"Homoscedasticity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Homoscedasticity</a>: The least squares method assumes that the <a data-tooltip-position=\"top\" aria-label=\"Variance\" data-href=\"Variance\" href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">variance</a> of errors is a constant (homoscedastic), rather than a function of the independent variable (<a data-href=\"Heteroscedastic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heteroscedastic</a>).\n<br><a data-href=\"Multicollinearity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multicollinearity</a>: If the independent variables are highly correlated, the least squares method has difficulty determining the effect of each attribute on the dependent variable, making the model unstable.\nThe most common form of the least squares method, commonly used in Linear Regression models. It simply minimizes the sum of squared residuals without any weights.<br>Extends ordinary least squares to handle heteroscedasticity by assigning weights to data objects based on <a data-href=\"Covariance Matrix\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Covariance Matrix</a> of the residuals.<br>A specific type of generalized least squares, used when the dataset exhibits heteroscedasticity. WLS is more robust because it weighs the influence of each data point based on its <a href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"180\" to=\"188\" origin-text=\"variance\" class=\"internal-link virtual-link-a\">variance</a>. <br>Also known as L2 regularization, ridge regression is a type of linear regression that introduces a penalty term to the OLS cost function. Ridge regression adds the squared coefficients as a penalty to the cost function, thereby, punishing large coefficient values. This helps prevent overfitting and addresses any <a data-href=\"Multicollinearity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multicollinearity</a> in the independent variables.\nThe cost function for ridge regression defined as:Where: is the actual output. is the predicted output. are the coefficients is the regularization parameter which determines the magnitude of the penalty term.\n<br>By adjusting the ridge parameter, λ, ridge regression allows for control over the bias-<a href=\"https://emujakic.github.io/TechKB/notes/math/variance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"87\" to=\"95\" origin-text=\"variance\" class=\"internal-link virtual-link-a\">variance</a> tradeoff. As increases, the bias of the model increases and the variance decreases. Optimizing this parameter can achieve the ideal balance between overfitting and underfitting model.Also known as L1 regularization, lasso regression is a type of linear regression which, like ridge regression, introduces a penalty term to the OLS cost function. Lasso regression adds the absolute coefficient values to the cost function, this allows the coefficients of irrelevant variables to be shrunk down to 0, thereby, simplifying and regularizing the model.\nThe cost function for lasso regression defined as:Where: is the actual output. is the predicted output. are the coefficients is the regularization parameter which determines the magnitude of the penalty term.\n<br>Unlike ridge regression, which shrinks coefficients but typically keeps all predictors in the model, lasso regression can set the coefficients of irrelevant variables exactly to zero. This makes it an effective technique for <a data-href=\"Feature Selection\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Feature Selection</a>, that is, identifying and retaining only the most important variables.\n<br>Prabhu Raghav, “Linear Regression Simplified - Ordinary Least Square vs Gradient Descent,”&nbsp;Medium, May 15, 2018. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://medium.com/data-science/linear-regression-simplified-ordinary-least-square-vs-gradient-descent-48145de2cf76\" target=\"_self\">https://medium.com/data-science/linear-regression-simplified-ordinary-least-square-vs-gradient-descent-48145de2cf76</a> (accessed Jul. 21, 2025).\n<br>GeeksforGeeks, “Least Square Method | Definition Graph and Formula,”&nbsp;GeeksforGeeks, Jul. 06, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/least-square-method/\" target=\"_self\">https://www.geeksforgeeks.org/maths/least-square-method/</a>\n<br>“Least squares,”&nbsp;Wikipedia, Dec. 19, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Least_squares\" target=\"_self\">https://en.wikipedia.org/wiki/Least_squares</a>\n<br>A. Menon, “Linear Regression Using Least Squares - TDS Archive - Medium,”&nbsp;Medium, Sep. 08, 2018. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://medium.com/data-science/linear-regression-using-least-squares-a4c3456e8570\" target=\"_self\">https://medium.com/data-science/linear-regression-using-least-squares-a4c3456e8570</a> (accessed Jul. 21, 2025).\n<br>The Organic Chemistry Tutor, “Linear Regression Using Least Squares Method - Line of Best Fit Equation,”&nbsp;YouTube. Jul. 13, 2020. [YouTube Video]. Available: <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.youtube.com/watch?v=P8hT5nDai6A\" target=\"_self\">https://www.youtube.com/watch?v=P8hT5nDai6A</a>\n<br>GeeksforGeeks, “Ridge Regression,”&nbsp;GeeksforGeeks, Jun. 11, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/machine-learning/what-is-ridge-regression/\" target=\"_self\">https://www.geeksforgeeks.org/machine-learning/what-is-ridge-regression/</a> (accessed Jul. 23, 2025).\n<br>GeeksforGeeks, “What is Lasso Regression?,”&nbsp;GeeksforGeeks, May 15, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/machine-learning/what-is-lasso-regression/\" target=\"_self\">https://www.geeksforgeeks.org/machine-learning/what-is-lasso-regression/</a>\n","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#statistics","#machineLearning","#regression"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Least Squares","level":1,"id":"Least_Squares_0"},{"heading":"Method","level":2,"id":"Method_0"},{"heading":"Objective","level":3,"id":"Objective_0"},{"heading":"Steps","level":3,"id":"Steps_0"},{"heading":"Limitations","level":2,"id":"Limitations_0"},{"heading":"Types of Least Squares","level":2,"id":"Types_of_Least_Squares_0"},{"heading":"<a data-href=\"Ordinary Least Squares\" href=\"Ordinary Least Squares\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Ordinary Least Squares</a>","level":3,"id":"[[Ordinary_Least_Squares]]_0"},{"heading":"<a data-href=\"Generalized Least Squares\" href=\"Generalized Least Squares\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Generalized Least Squares</a>","level":3,"id":"[[Generalized_Least_Squares]]_0"},{"heading":"<a data-href=\"Weighted Least Squares\" href=\"Weighted Least Squares\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Weighted Least Squares</a>","level":3,"id":"[[Weighted_Least_Squares]]_0"},{"heading":"Additional Techniques","level":2,"id":"Additional_Techniques_0"},{"heading":"<a data-href=\"Ridge Regression\" href=\"Ridge Regression\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Ridge Regression</a>","level":3,"id":"[[Ridge_Regression]]_0"},{"heading":"<a data-href=\"Lasso Regression\" href=\"Lasso Regression\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Lasso Regression</a>","level":3,"id":"[[Lasso_Regression]]_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html","notes/math/euclidean-distance.html#_0","notes/math/outlier.html#_0","notes/math/outlier.html#_0",".html",".html","notes/math/variance.html#_0",".html",".html",".html",".html",".html",".html","notes/math/variance.html#_0",".html",".html","notes/math/variance.html#_0",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/resources/linearregression.png","fullURL":"https://emujakic.github.io/TechKB/notes/math/least-squares.html","pathToRoot":"../..","attachments":["resources/linearregression.png"],"createdTime":1753105505921,"modifiedTime":1754247532104,"sourceSize":6451,"sourcePath":"NOTES/Math/Least Squares.md","exportPath":"notes/math/least-squares.html","showInTree":true,"treeOrder":9,"backlinks":["notes/math/euclidean-distance.html","notes/math/variance.html"],"type":"markdown"},"notes/math/associative-property.html":{"title":"Associative Property","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-19The associative property states that the sum or product of any group of values is not affected by how the values are grouped. It allows you to transform mathematical expressions into equivalent forms without altering its value.The associative property applies to addition. For any numbers , and :The associative property applies to multiplication. For any numbers , and :The associative property applies to matrix multiplication as well. For matrices , , and with compatible dimensions:Operations such as subtraction or division are not associative:\nSubtraction: Division: In <a data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositional Logic</a>, associativity is a rule of replacement that applies to some <a data-href=\"Logical Connectives\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logical Connectives</a>, allowing for the rearrangement of grouping symbols without changing the truth value of the logical expression.Associativity applies to conjunction (AND), for any variables , , and :Associativity applies to disjunction (OR), for any variables , , and :<br>In set theory, the associative property refers to how the <a data-href=\"Union\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Union</a> and <a data-href=\"Intersection\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Intersection</a> of sets can be grouped without altering the outcome of the expression.for any sets , , and :for any sets , , and :<br>The <a href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"24\" origin-text=\"commutative property\" class=\"internal-link virtual-link-a\">commutative property</a> states of values does not affect their sum or product.\nAddition: Multiplication: <br>Note that the <a href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"14\" to=\"34\" origin-text=\"commutative property\" class=\"internal-link virtual-link-a\">commutative property</a> does not apply to matrix multiplication.\n<br>GeeksforGeeks, “Associative Property,”&nbsp;GeeksforGeeks, Sep. 29, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/associative-property/\" target=\"_self\">https://www.geeksforgeeks.org/maths/associative-property/</a> (accessed Jul. 19, 2025)\n<br>“Associative property,”&nbsp;Wikipedia, Jan. 16, 2023. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Associative_property\" target=\"_self\">https://en.wikipedia.org/wiki/Associative_property</a>\n","aliases":["Associative"],"inlineTags":[],"frontmatterTags":["#math","#algebra"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Associative Property","level":1,"id":"Associative_Property_0"},{"heading":"Associative Operations","level":3,"id":"Associative_Operations_0"},{"heading":"Addition","level":4,"id":"Addition_0"},{"heading":"Multiplication","level":4,"id":"Multiplication_0"},{"heading":"<a data-href=\"Matrix Multiplication\" href=\"Matrix Multiplication\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Matrix Multiplication</a>","level":4,"id":"[[Matrix_Multiplication]]_0"},{"heading":"Non-Associative Operations","level":3,"id":"Non-Associative_Operations_0"},{"heading":"Logical Operations","level":2,"id":"Logical_Operations_0"},{"heading":"<a data-href=\"Conjunction\" href=\"Conjunction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Conjunction</a>","level":3,"id":"[[Conjunction]]_0"},{"heading":"<a data-href=\"Disjunction\" href=\"Disjunction\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Disjunction</a>","level":3,"id":"[[Disjunction]]_0"},{"heading":"<a data-href=\"Set Theory\" href=\"Set Theory\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Set Theory</a>","level":2,"id":"[[Set_Theory]]_0"},{"heading":"Union","level":3,"id":"Union_0"},{"heading":"Intersection","level":3,"id":"Intersection_0"},{"heading":"<a data-href=\"Commutative Property\" href=\"Commutative Property\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Commutative Property</a>","level":2,"id":"[[Commutative_Property]]_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/propositional-logic.html#_0",".html",".html",".html",".html",".html",".html","notes/math/commutative-property.html#_0","notes/math/commutative-property.html#_0","notes/math/commutative-property.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/associative-property.html","pathToRoot":"../..","attachments":[],"createdTime":1752965745243,"modifiedTime":1756434996484,"sourceSize":2549,"sourcePath":"NOTES/Math/Associative Property.md","exportPath":"notes/math/associative-property.html","showInTree":true,"treeOrder":4,"backlinks":["notes/math/commutative-property.html","notes/math/propositional-logic.html"],"type":"markdown"},"notes/math/euclidean-distance.html":{"title":"Euclidean Distance","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-17The Euclidean distance is the most popular <a data-href=\"Distance Measure\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Distance Measure</a> that quantifies the dissimilarity between <a data-href=\"Numerical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Numerical Data</a>. It represents the straight-line distance between two points in Euclidean space and is calculated using the <a data-href=\"Pythagorean Theorem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pythagorean Theorem</a>. Let and be two data objects described by numerical attributes. The Euclidean distance between these two objects is: This formula computes the square root of the sum of the squared differences of each corresponding attribute, providing a measure of the straight-line distance in the multidimensional space.\n<br>Positive: Like any other distance metric, the <a data-tooltip-position=\"top\" aria-label=\"Range\" data-href=\"Range\" href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">range</a> of the Euclidean distance is where a 0 distance indicates that the two points are at the same location.\nSymmetric: The Euclidean distance is symmetric, meaning <br><a data-href=\"Triangle Inequality\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Triangle Inequality</a>: The Euclidean distance obeys the triangle inequality, which states that the distance from to is always less than or equal to the distance from to plus the distance from to . Meaning that taking a detour through a third point cannot result in a shorter distance than a direct path from to .\nThe squared Euclidean distance is computed as only the sum of squared differences:<br>The squared Euclidean distance amplifies greater distances more so then the standard Euclidean distance, and is faster and easier to compute. This makes it more desirable in problems where significant distances should be penalized harsher, such as in <a data-href=\"Clustering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Clustering</a> or <a data-href=\"Outlier Detection\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outlier Detection</a>. Though, the squared Euclidean distance does not obey the triangle inequality.<br>Squared Euclidean distance is a <a data-href=\"Convex Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Convex Function</a>, which makes it more desirable in optimization theory since it permits the use of <a data-href=\"Convex Analysis\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Convex Analysis</a>.<br><a href=\"https://emujakic.github.io/TechKB/notes/math/least-squares.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"13\" origin-text=\"Least squares\" class=\"internal-link virtual-link-a\">Least squares</a> is an optimization technique that attempts to find the function which minimizes the sum of the square Euclidean distances between the observed and predicted values. This method is widely used in <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a>, particularly in <a data-href=\"Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Regression</a> analysis.<br>Divergence is a kind of distance measure that applies to <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"57\" to=\"68\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distributions. The squared Euclidean distance is the simplest divergence measure.<br>Other common divergence measures include <a data-href=\"Kullback–Leibler Divergence\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Kullback–Leibler Divergence</a> and <a data-href=\"Jensen-Shannon Divergence\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Jensen-Shannon Divergence</a>.\n<br>Clustering: Euclidean distance is used in clustering algorithms such as <a data-href=\"K-Means Clustering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">K-Means Clustering</a> to measure distance between data points.\n<br><a data-href=\"Classification\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Classification</a>: Classification algorithms like <a data-href=\"K-Nearest-Neighbors\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">K-Nearest-Neighbors</a> may utilize Euclidean distance to classify data points based on the label of their nearest neighbors. <br><a data-href=\"Outlier\" href=\"https://emujakic.github.io/TechKB/notes/math/outlier.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Outlier</a> Detection: The Euclidean or squared Euclidean distance can be used to identify data points which deviate significantly from the rest of the dataset.\n<br>Multivariate Analysis: Euclidean distance can be used in techniques like <a data-href=\"Principal Component Analysis\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Principal Component Analysis</a> or <a data-href=\"Multidimensional Scaling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multidimensional Scaling</a> to measure the distance between points with multiple dimensions.\n<br>Least Squares Method: The Euclidean distance is a key step for the method of <a href=\"https://emujakic.github.io/TechKB/notes/math/least-squares.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"57\" to=\"70\" origin-text=\"least squares\" class=\"internal-link virtual-link-a\">least squares</a>, which is commonly used to optimize regression problems.\n<br>Divergence: Squared Euclidean distance is a simple measure of divergence, allowing you to compare <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"88\" to=\"99\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distributions.\nOptimization: Squared Euclidean distance is preferred in optimization theory due to its smoothness and convexity, permitting the use of convex analysis. <br>Path Planning: Euclidean distance can be used for calculating the shortest path between points. It is also an <a data-href=\"Admissible\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Admissible</a> and <a data-href=\"Consistent\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Consistent</a> <a data-href=\"Heuristic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heuristic</a> in search algorithms such as <a data-href=\"A* Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">A* Search</a>.\n<br>Localization: in <a data-href=\"Simultaneous Localization and Mapping\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Simultaneous Localization and Mapping</a> problems, the Euclidean distance can be used to determine a robot's position relative to known landmarks. Image Recognition: Euclidean distance is used to compare feature vectors in images, aiding in object recognition.\nImage Segmentation: Euclidean distance is used to measure similarities between pixel values in clustering-based image segmentation.\nOther common distance measures include:\n<br><a data-href=\"Chebyshev Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Chebyshev Distance</a>: The maximum absolute difference between 2 vectors across all dimensions.\n<br><a data-href=\"Minkowski Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Minkowski Distance</a>: A generalized distance measure that is defined by a parameter whose common values are the <a href=\"https://emujakic.github.io/TechKB/notes/math/manhattan-distance.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"29\" to=\"47\" origin-text=\"Manhattan distance\" class=\"internal-link virtual-link-a\">Manhattan distance</a>, Euclidean distance, and Chebyshev distance.\n<br><a data-href=\"Manhattan Distance\" href=\"https://emujakic.github.io/TechKB/notes/math/manhattan-distance.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Manhattan Distance</a>: The shortest distance between 2 vectors using only 90° movements.\n<br><a data-href=\"Jaccard Index\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Jaccard Index</a>: Used to compare sets and is defined as the size of the intersection of 2 sets, over the size of their union. J. Han and M. Kamber,&nbsp;Data Mining : Concepts and Techniques, 3rd ed. Amsterdam ; Boston: Elsevier/Morgan Kaufmann, 2012.\n<br>GeeksforGeeks, “Euclidean Distance,”&nbsp;GeeksforGeeks, Mar. 13, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/maths/euclidean-distance/\" target=\"_self\">https://www.geeksforgeeks.org/maths/euclidean-distance/</a>\n<br>Wikipedia Contributors, “Euclidean distance,”&nbsp;Wikipedia, Apr. 01, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Euclidean_distance\" target=\"_self\">https://en.wikipedia.org/wiki/Euclidean_distance</a>\n<br>“<a href=\"https://emujakic.github.io/TechKB/notes/math/least-squares.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"1\" to=\"14\" origin-text=\"Least squares\" class=\"internal-link virtual-link-a\">Least squares</a>,”&nbsp;Wikipedia, Dec. 19, 2019. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Least_squares\" target=\"_self\">https://en.wikipedia.org/wiki/Least_squares</a>\n<br>Maarten Grootendorst, “9 Distance Measures in Data Science | TDS Archive,”&nbsp;Medium, Feb. 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://medium.com/data-science/9-distance-measures-in-data-science-918109d069fa\" target=\"_self\">https://medium.com/data-science/9-distance-measures-in-data-science-918109d069fa</a>\n","aliases":["Straight-Line Distance","Euclidean Distances"],"inlineTags":[],"frontmatterTags":["#math","#statistics","#machineLearning","#unfinished"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Euclidean Distance","level":1,"id":"Euclidean_Distance_0"},{"heading":"Formula","level":3,"id":"Formula_0"},{"heading":"Properties","level":3,"id":"Properties_0"},{"heading":"Squared Euclidean Distance","level":2,"id":"Squared_Euclidean_Distance_0"},{"heading":"<a data-href=\"Least Squares\" href=\"Least Squares\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Least Squares</a>","level":3,"id":"[[Least_Squares]]_0"},{"heading":"<a data-href=\"Divergence\" href=\"Divergence\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Divergence</a>","level":3,"id":"[[Divergence]]_0"},{"heading":"Applications","level":2,"id":"Applications_0"},{"heading":"Machine Learning","level":3,"id":"Machine_Learning_0"},{"heading":"Statistics","level":3,"id":"Statistics_0"},{"heading":"Robotics","level":3,"id":"Robotics_0"},{"heading":"<a data-href=\"Computer Vision\" href=\"Computer Vision\" class=\"internal-link\" target=\"_blank\" rel=\"noopener nofollow\">Computer Vision</a>","level":3,"id":"[[Computer_Vision]]_0"},{"heading":"Other Distance Measures","level":2,"id":"Other_Distance_Measures_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html","notes/math/least-squares.html#_0","notes/math/least-squares.html#_0",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html","notes/math/outlier.html#_0",".html",".html","notes/math/least-squares.html#_0","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/manhattan-distance.html#_0","notes/math/manhattan-distance.html#_0",".html","notes/math/least-squares.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/euclidean-distance.html","pathToRoot":"../..","attachments":[],"createdTime":1752772872723,"modifiedTime":1756435583317,"sourceSize":6032,"sourcePath":"NOTES/Math/Euclidean Distance.md","exportPath":"notes/math/euclidean-distance.html","showInTree":true,"treeOrder":7,"backlinks":["notes/math/least-squares.html","notes/math/manhattan-distance.html","notes/math/median.html","notes/math/outlier.html"],"type":"markdown"},"notes/math/binary-data.html":{"title":"Binary Data","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-08Binary data is a type of <a data-href=\"Categorical Data\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Categorical Data</a> with only two possible values, typically 1 and 0. Binary data is a specific type of <a data-href=\"Nominal Data\" href=\"https://emujakic.github.io/TechKB/notes/math/nominal-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Nominal Data</a>, meaning the values are non-numeric, and qualitative.\nPresence: Binary data is commonly used to represent the presence or absence of a specific attribute, 1 meaning the attribute is present, 0 meaning the attribute is absent.\nTruth: Binary data is also commonly used to represent truth, where 1 indicates truth, and 0 indicated falsehood.\nOpposing Categories: Binary data is commonly used to represent 2 opposing categories, such as male/female, or employed/unemployed.\n<br>Since <a href=\"https://emujakic.github.io/TechKB/notes/math/nominal-data.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"6\" to=\"18\" origin-text=\"nominal data\" class=\"internal-link virtual-link-a\">nominal data</a> lacks numerical significance, data operations such as <a data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mean</a> or <a data-href=\"Median\" href=\"https://emujakic.github.io/TechKB/notes/math/median.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Median</a> cannot be performed. However, the frequency of nominal data values can be analyzed, and a measure like the <a data-href=\"Mode\" href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Mode</a> can describe the most common category within a given dataset.A binary attribute is symmetric if each state 0 or 1 is equally valuable, such as a gender attribute. A binary attribute is asymmetric if the two states are not equally valuable, such as the results of a disease test.<br>Asymmetric binary attributes require careful consideration in <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a> tasks to ensure the model understands the underlying implications of the data. Common strategies include:\n<br><a data-href=\"Label Encoding\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Label Encoding</a>: Label encoding assigns numerical values to binary attributes. Each binary class can be assigned a value representative of its importance, for example, assigning the true class a value of , while the false class is assigned a value of .\nClass Weighting: In binary classification tasks, assigning different weights to each state during model training can put more emphasis on a particular class.\nCalculating the similarity and dissimilarity of binary attributes involves different methods depending on whether the attribute is symmetric or not.For symmetric binary attributes, common measures include:\n<br>\n<a data-href=\"Jaccard Coefficient\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Jaccard Coefficient</a>: The size of the intersection of two sets over their union: Where: is the number of attributes where and are 1. is the number of attributes where A is 1 and B is 0 is the number of attributes where A is 0 and B is 1 <br>\n<a data-href=\"Dice Coefficient\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dice Coefficient</a>: Twice the size of the intersection of two sets over the sum of the sets: For asymmetric binary attributes, common measures include:\nWeighted Jaccard Coefficient: The Jaccard coefficient can be modified to emphasize a particular class: Where:\n​ is 1 if the element is present in set and 0 if absent.\n​ is 1 if the element is present in set and 0 if absent.\n​ is the weight assigned to the element . <br><a data-href=\"Binary Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Binary Regression</a> estimates a function that maps one or more independent variables to a single dependent binary variable. Common techniques include:\n<br>\n<a data-href=\"Logistic Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logistic Regression</a>: A statistical method used for binary classification, predicting the <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probability</a> that a given input vector belongs to a certain binary category. It is essentially a <a data-href=\"Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Regression</a> model with a Logistic Function applied to map the output to a value between 0 and 1. <br>\n<a data-href=\"Probit Regression\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probit Regression</a>: Similar to logistic regression, though, it assumes that errors between the predicted and actual values are normally distributed. Probit regression also uses the <a data-href=\"Probit Link Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probit Link Function</a> rather than the logistic function. J. Han, M. Kamber, and J. Pei,&nbsp;Data Mining : Concepts and Techniques. Burlington, Ma: Elsevier, 2012.\n<br>GeeksforGeeks, “Jaccard Similarity,”&nbsp;GeeksforGeeks, Mar. 17, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/python/jaccard-similarity/\" target=\"_self\">https://www.geeksforgeeks.org/python/jaccard-similarity/</a> (accessed Aug. 01, 2025).\n<br>“Binary data,”&nbsp;Wikipedia, Sep. 13, 2021. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Binary_data\" target=\"_self\">https://en.wikipedia.org/wiki/Binary_data</a>\nWikipedia Contributors, “Binary regression,”&nbsp;Wikipedia, Mar. 27, 2022.\n","aliases":[],"inlineTags":[],"frontmatterTags":["#math","#statistics"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Binary Data","level":1,"id":"Binary_Data_0"},{"heading":"Representation","level":3,"id":"Representation_0"},{"heading":"No Numerical Significance","level":3,"id":"No_Numerical_Significance_0"},{"heading":"Symmetry","level":2,"id":"Symmetry_0"},{"heading":"Similarity","level":2,"id":"Similarity_0"},{"heading":"Symmetric","level":3,"id":"Symmetric_0"},{"heading":"Asymmetric","level":3,"id":"Asymmetric_0"},{"heading":"Regression","level":2,"id":"Regression_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html","notes/math/nominal-data.html#_0","notes/math/nominal-data.html#_0","notes/math/mean.html#_0","notes/math/median.html#_0","notes/math/mode.html#_0",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/math/binary-data.html","pathToRoot":"../..","attachments":[],"createdTime":1752017585071,"modifiedTime":1754445468801,"sourceSize":4392,"sourcePath":"NOTES/Math/Binary Data.md","exportPath":"notes/math/binary-data.html","showInTree":true,"treeOrder":5,"backlinks":["notes/math/nominal-data.html","notes/math/outlier.html"],"type":"markdown"},"notes/ai/turing-test.html":{"title":"Turing Test","icon":"","description":"Author: Ernad Mujakic\nDate: 2025-07-02A Turing test is a benchmark proposed by Alan Turing for evaluating a machine's ability to exhibit intelligence that is indistinguishable from that of a human. The test involves three participants, a human interrogator, a human respondent, and a machine. The interrogator communicates with both the human and machine via text, if the judge is unable to confidently identify which agent is the human and which is the machine, then the machine passes the Turing test. The result does not depend on the machine's ability to respond correctly, , only on how close the machine's language resembles human natural language. The CAPTCHA system is a famous implementation of a Turing test.To pass a Turing test a machine must have <a data-href=\"Natural Language Processing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Natural Language Processing</a> and generating abilities. The machine also needs some form of <a data-href=\"Knowledge Representation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Representation</a> to be able to keep track of conversation, as well as <a data-href=\"Reasoning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Reasoning</a>, so that the machine demonstrates some form of rationality to the interrogator.<br>There is an extension of the Turing test known as the total Turing test, where the machine has to also exhibit human sensory abilities and physical interactions. In this instance, the machine would also need robust <a data-href=\"Robotics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Robotics</a>, <a data-href=\"Computer Vision\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Computer Vision</a>, <a data-href=\"Speech Recognition\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Speech Recognition</a>, navigation, and physical manipulation capabilities as well as a physical appearance that is indistinguishable from a human.One of the strengths of the Turing test lies in its simplicity. The test is straightforward to implement and understand which encourages broader participation in the realm of AI research.The Turing test is particularly versatile, allowing it to be applied to various forms of AI models, making it relevant across sub-disciplines within artificial intelligence research. The evaluation metrics of the test are also simple to expand or contract if specific capabilities would like to be included or excluded, such as computer vision or robotics. This allows researchers to tailor their assessment based on the goals of their project, rather than trying to conform to specific parameters of the test.Due to its subjective nature, the Turing Test is susceptible to human variability, as different interrogators may perceive specific behaviors as \"human-like\" or intelligent in varying ways. This inherent subjectivity can lead to inconsistent results, which undermines the test's reliability as a benchmark for evaluating artificial intelligence systems. As a result, the effectiveness and usefulness of the Turing test as a measure for machine intelligence has been heavily scrutinized by various researchers in the field of AI.Since the Turing Test focuses primarily on actions and behaviors, it overlooks the underlying processes that lead to the formulation of those behaviors, raising questions about whether those processes truly reflect intelligence. Many computer scientists argue that analyzing actions and behaviors alone is insufficient for determining whether a machine possesses intelligence. This critique emphasizes the need for a more comprehensive evaluation that considers not only observable outputs but also the mechanisms which deliver those outputs.Some critics of the Turing Test argue that the focus of AI research should be on augmenting or improving human behavior rather than merely mimicking it. They point out that certain human behaviors are inherently unintelligent, while some intelligent behaviors may be fundamentally inhuman. For example, a machine might deliberately avoid providing a correct answer to a challenging mathematical question to avoid raising suspicion with the interrogator. Some believe that this approach represents a misguided use of research efforts, diverting attention from the potential of AI to enhance human capabilities and solve complex problems.\n<br>Wikipedia contributors, “Turing test,” Wikipedia, Jun. 24, 2025. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://en.wikipedia.org/wiki/Turing_test#Tractability_and_simplicity\" target=\"_self\">https://en.wikipedia.org/wiki/Turing_test#Tractability_and_simplicity</a>\n<br>GeeksforGeeks, “Turing Test in artificial intelligence,” GeeksforGeeks, Sep. 16, 2024. <a rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://www.geeksforgeeks.org/artificial-intelligence/turing-test-artificial-intelligence/\" target=\"_self\">https://www.geeksforgeeks.org/artificial-intelligence/turing-test-artificial-intelligence/</a>\nPeter. R. Norvig, Artificial Intelligence: A Modern Approach, Global Edition. 2021.\n","aliases":[],"inlineTags":[],"frontmatterTags":["#AI"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Turing Test","level":1,"id":"Turing_Test_0"},{"heading":"Requirements","level":2,"id":"Requirements_0"},{"heading":"Strengths","level":2,"id":"Strengths_0"},{"heading":"Simplicity","level":4,"id":"Simplicity_0"},{"heading":"Flexibility","level":4,"id":"Flexibility_0"},{"heading":"Weaknesses","level":2,"id":"Weaknesses_0"},{"heading":"Non-Deterministic","level":4,"id":"Non-Deterministic_0"},{"heading":"Behavior is not Intelligence","level":4,"id":"Behavior_is_not_Intelligence_0"},{"heading":"Augmentation over Imitation","level":4,"id":"Augmentation_over_Imitation_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html",".html",".html",".html"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/notes/ai/turing-test.html","pathToRoot":"../..","attachments":[],"createdTime":1751502135746,"modifiedTime":1756435642674,"sourceSize":4532,"sourcePath":"NOTES/AI/Turing Test.md","exportPath":"notes/ai/turing-test.html","showInTree":true,"treeOrder":2,"backlinks":["textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown"},"textbooks/artificial-intelligence-a-modern-approach-summary.html":{"title":"Artificial Intelligence A Modern Approach Summary","icon":"","description":"\nName: Stuart Russell and Peter Norvig\nEdition: 4th Edition\nAI: A Modern Approach by Norvig and Russel is a foundational text in the dynamic field of artificial intelligence. The book covers a wide <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"117\" to=\"122\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of topics, from Markov models and evolutionary algorithms, to natural language processing. This summary attempts to break down the main ideas and insights from the book. The field of AI is concerned with the understanding, engineering, and implementation of intelligent agents. Intelligence can be defined through several perspectives: <br>Acting Humanly- The ability to pass a <a data-href=\"Turing Test\" href=\"https://emujakic.github.io/TechKB/notes/ai/turing-test.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Turing Test</a>.\nThinking Humanly- Thinking like a human.\nThinking Rationally- Acting in such a way as to achieve the 'best' possible outcome.\nBeneficial Machines- Acting in a way beneficial to humans. <br>\n<a data-href=\"Utility\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Utility</a> is the subjective value of an outcome. <br>\n<a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a> is a branch of logic made up of predicates that return either true or false, universal/existential quantifiers, terms, and logical connectives such as 'and' 'or' 'not'. <br>\n<a data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability</a> extends logic to scenarios involving uncertainty, allowing for the modeling of real-world conditions where information is incomplete or ambiguous. <br>\n<a data-href=\"Decision Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Theory</a> deals with the principles and methods for making rational decisions under uncertainty. <br>\n<a data-href=\"Game Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Game Theory</a> is a framework for analyzing interdependent multi-agent environments. <br>\n<a data-href=\"Control Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Control Theory</a> is the design of systems that can automatically adjust their behavior to achieve desired outcomes. A cost function quantifies the cost of a particular action or sequence of actions. Something is 'stochastic' if it exhibits uncertainty. <br>\nA <a data-href=\"Markov Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Model</a> is a system where the following state depends only on the current state. A Markov Process is a stochastic process that satisfies the Markov Model. A <a data-href=\"Hidden Markov Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hidden Markov Model</a> is a statistical model that represents systems that transition between different hidden states, while perceiving observable outputs. <br>\nA <a data-href=\"Bayesian Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bayesian Network</a> is a probabilistic model implemented as a directed acyclic graph that represents a set of <a data-tooltip-position=\"top\" aria-label=\"Random Variable\" data-href=\"Random Variable\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Random Variables</a> and their conditional dependencies, as well as a set of conditional <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"69\" to=\"80\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distribution tables. <br>\n<a data-href=\"Agent\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Agent</a> - Anything that can perceive its environment with sensors and act upon it with actuators. <br>\n<a data-href=\"Percept Sequence\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Percept Sequence</a> - Everything an agent has perceived. <br>\n<a data-href=\"Agent Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Agent Function</a> - An abstract mathematical function that maps percept sequences to actions. Agent Program - A concrete implementation of some abstract agent function. Performance Measure - Evaluates the desirability of an outcome. Information Gathering - Performing potentially sub-optimal actions in order to perceive new information about the environment. Rationality maximizes expected performance based on the knowledge available. What is rational at a given time-step is based on the agent's performance measure, its available actions, its prior knowledge of the environment, as well as its percept sequence up until that time-step. <br>\n<a data-href=\"Task Environment\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Task Environment</a> - The factors that determine how an agent operates. The task environment consists of the performance measure, sensors, actuators, and external environment. A task environment can be fully observable, meaning the agent's sensors give it complete knowledge about all relevant variables of the environment at all times. A Task environment is partially observable if the sensors provide a noisy or incomplete description of the actual state at any time step. A task environment is single agent if there is only one actor that influences the environment, else, it is a multi-agent environment. <br>\nA task environment is deterministic if the next state is completely determined by the current state and the action taken. Otherwise, the environment is nondeterministic or stochastic. An environment is uncertain if there is uncertainty in either the <a data-href=\"Sensor Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Sensor Model</a> - which returns the perceived output of the current state, or if there is uncertainty in the <a data-href=\"Transition Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transition Model</a> - which returns the next state based on the current state and the action taken. Together the transition and sensor model allow the agent to keep track of the state of the world . A task environment is episodic if the sequence of states are divided into atomic episodes, that is, the next state (episode) does not depend on the actions from previous states. A task environment is sequential if actions at any given state can impact the actions taken in future states. A task environment is dynamic if it can change while the agent is deliberating, otherwise, the environment is static. If the environment itself doesn't change but the passage of time impacts the agent's performance measure, the environment is considered semi-dynamic. <br>\nAn environment is known if the outcomes (or <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probabilities</a> of outcomes) of actions are given. Otherwise, the environment is unknown and the agent will have to learn the result of its actions. Discrete variables can take on distinct, separate values. <br>\nContinuous variables can take on any value in a <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"28\" to=\"33\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a>. Simple Reflex Agent - An agent that selects an action that selects based only on the current percept. Is susceptible to infinite loops in partially-observable environments which can be avoided if the agent selects actions with an element of randomization. Model-Based Reflex Agent - An agent which maintains an internal state which is constructed based on the percept history. The agent's internal state keeps track of the result of actions, as well as how the world evolves independent of itself. Goal-Based Agent - An agent that maintains a current state description as well as goal information which determines the desirability of a state or action. Though, goals treat all non-goal states with equal desirability which leads to poor performance. <br>\nUtility-Based Agent - Instead of a goal, the agent has a <a data-href=\"Utility Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Utility Function</a> which assigns a continuous value to a state or action, allowing the agent to act in such a way that maximizes its utility function. The utility function is simply and internalization of the agent's performance measure, in the case where all an agent's current actions lead to non-goal states, a utility-based agent will choose the action that leads to the \"best\" state, rather than treating each action as equal like a goal-based agent would. Utility also allows an agent to rationally deal with multiple goals by selecting the goal with the maximum utility. <br>\n<a data-href=\"Learning Agent\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Learning Agent</a> - An agent that can learn and improve from experience or training. A learning agent can be any of the mentioned types. Learning agents typically consist of four main components: Learning Element - The element responsible for making improvements.\nPerformance Element - The element responsible for selecting external actions. The performance element is what we previously considered as the entire agent.\nCritic - The element which provides feedback to the learning element on how well the agent is performing. Problem-solving agent: an agent that needs to plan, and consider a sequence of actions to reach a goal. Search: the computational process a problem-solving agent undertakes. <br>\nAn algorithm is informed if the agent can estimate its proximity to the goal using a <a data-href=\"Heuristic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heuristic</a>. Otherwise, the algorithm is uninformed. A problem-solving agent: Formulates its goal\nDevises a description of the states and actions needed to reach its goal.\nSimulates a sequence of actions until it finds a solution.\nExecutes the solution, if one is found. An system is considered open-loop if it ignores its percepts while executing its solution. This is done so if the environment is known and deterministic, meaning the agent needs not to keep track of its percepts. <br>A system is closed-loop if it keeps track of its percepts during execution. The term closed loop is used to <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"85\" to=\"89\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> that the loop between the agent and its environment is not broken. A search problem is defined by the following five components: <br>The set of possible states (<a data-href=\"State Space\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">State Space</a>).\nThe initial state.\nA set of one or more goals states.\nThe set of actions available to the agent.\n<br>The <a data-href=\"Transition Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transition Model</a>, which describes the result of the agent taking a action in its current state. A sequence of actions forms a path within the state space, and a path is considered a solution if it reaches a goal state from the initial state. A solution is considered optimal if it has the lowest cost among all possible solutions. <br>\nThe state space can be represented as a <a data-href=\"Graph\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Graph</a> where the vertices represent states, and edges represent actions which lead to other states. The diameter of a graph is the greatest distance between any 2 nodes. A state can be abstracted by removing as much detail as possible, while still retaining validity. <br>\n<a data-href=\"Search Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Search Algorithm</a>: Takes a search problem and returns a solution or failure. There are four ways to evaluate the performance of a search algorithm: Completeness: Does the algorithm always find a solution if one exists?\nOptimality: Does the algorithm find the optimal solution?\n<br><a data-href=\"Time Complexity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Time Complexity</a>: How does the search time scale as the size of the problem scales?\n<br><a data-href=\"Space Complexity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Space Complexity</a>: How does the memory usage scale as the size of the problem scales? In bounded suboptimal search we look for a solution within some constant factor of the optimal solution. In bounded-cost search we look for a solution whose cost is less than some constant. In unbounded-cost search we accept any solution and prioritize the speed of the algorithm. For a search algorithm to be complete in an infinite state space, it needs to systematically explore the space. <br>\n<a data-href=\"Search Tree\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Search Tree</a>: Describes the path between states. The root node represents the initial state, and the current node can be expanded by considering the actions available, then generating a new child node for each resulting state. <br>\nFrontier: The collection of nodes that have been generated but not yet explored and is typically implemented as a <a data-href=\"Queue\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Queue</a> or a <a data-href=\"Stack\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Stack</a>. The functions available on the frontier are: is-Empty, which checks if the frontier is empty.\npop, which returns and removes the first element.\ntop, which returns the first element but does not remove it.\nadd, which adds a new element to the end of the queue. A best-first search, also known as a greedy search, chooses the node with the lowest cost in the frontier. A node is made up of the following four components: The state that it represents.\nIts parent node, which allows us to backtrack from a goal state back to the initial state.\nThe action which generated it.\nIts total path cost from the root. An uninformed search algorithm is completely unaware of how far any state is from the goal. Uninformed algorithms are differ in the way that they expand nodes in the frontier. Some common uninformed search algorithms include: <br><a data-href=\"Breadth-First Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Breadth-First Search</a>: Expands all the nodes in the current depth, starting at the root, before moving deeper into the tree. This search in implemented using a queue, which is a FIFO data structure. BFS is a systematic search, meaning, it is complete even in infinite state spaces.\nBFS is cost optimal if the edges are unweighted or have a global constant weight.\nThe goal test may be early, meaning each node is checked to be a goal when it is first generated; or the goal test may be late, meaning each node is checked when it is popped from the queue.\nThe time and space complexity of BFS is where is the number of children and is the depth of the tree. <br><a data-href=\"Dijkstra's Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dijkstra's Algorithm</a>: is a greedy search algorithm that uses a late goal test to ensure optimality. It maintains a list of the shortest distances to each node from the root where, initially, the distance to the root is 0 and the distance to all other nodes is . The frontier is implemented as a priority queue, where the node with the smallest distance is expanded first. Then all the current node's neighbors are examined and if a shorter distance is found, the distance to the corresponding node is updated. This process is iterated until the optimal path is found. Dijkstra's is complete and optimal for weighted graphs with non-negative weights.\nThe time complexity of Dijkstra's is where is the number of vertices, and is the number of edges. The space complexity of Dijkstra's is . <br><a data-href=\"Depth-First Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Depth-First Search</a>: Expands the deepest node in the frontier. DFS uses a stack as opposed to a queue, which is a LIFO data structure. This algorithm is commonly implemented as a tree search, meaning, it doesn't keep track of the states that it has reached. DFS continues down a path until either a goal is found, or a leaf node is found. In the latter case, the algorithm backtracks to the next deepest node and expands its children if any. DFS is not cost-optimal. DFS is complete in finite state spaces though not in infinite state spaces.\nThe time complexity of DFS is and the space complexity is .\n<br><a data-href=\"Backtracking Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Backtracking Search</a> is a variation of DFS where only one successor is generated at a time, and the current state description is updated in place, rather than allocating memory for a new state. <br><a data-href=\"Depth-Limited Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Depth-Limited Search</a>: Treats nodes at depth as if they are leaf nodes. This prevents the node from traveling down an infinite path. <br>The time complexity of depth-limited search is where is the <a data-href=\"Branching Factor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Branching Factor</a> and is the depth limit.\nThe diameter of the state space is a good limit value, though, it is rarely known beforehand. <br><a data-href=\"Iterative Deepening DFS\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Iterative Deepening DFS</a>: A depth limited search which iteratively increments the depth limit until a solution is found or a failure is returned. This combines the benefits of depth first and breadth first search. Optimal for unweighted paths.\nComplete for finite, acyclic state spaces.\nTime complexity of <br><a data-href=\"Bidirectional Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bidirectional Search</a>: Searches forward from the initial state and backward from the goal state until the 2 meet. The goal test returns true when the two paths meet. Since 2 frontiers need to be tracked, the space requirements are higher than most of the previously discussed algorithms. An informed (heuristic) search algorithm uses a heuristic function to estimate the distance of any given node from the goal. A search is considered greedy if it expands the node with the lowest always. Greedy searches are complete on finite spaces, but not on infinite spaces.\n<br><a data-href=\"A* Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">A* Search</a>: The evaluation function, , is the path cost from the current state to node plus . A* is complete and optimal if the heuristic is admissible or optimistic - meaning it never overestimates the cost to the goal.\nA* prunes nodes that are unnecessary for finding a solution.\nIf we allow A* to use an inadmissible heuristic, there is a risk of finding a suboptimal solution, but the heuristic may be more accurate, thus, reducing the number of expanded nodes.\nA variant of A, called **weighted A search** emphasizes the heuristic by multiplying by some constant . Weighted A finds a solution somewhere between and . A heuristic is consistent if for every node , its successor : , where represents the cost from to .\n<br>This means that the cost of reaching the goal from node is never greater than the cost of getting to from , plus the estimated cost of reaching the goal from . This is a version of the <a data-href=\"Triangle Inequality\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Triangle Inequality</a>.\nEvery consistent heuristic is admissible, but not every admissible heuristic is consistent.\nA composite heuristic combines multiple heuristics, and for certain complex problems, can be more effective than a single heuristic. A node is surely expanded if it can be reached from the initial state on a path where every node has , where is the optimal cost.\n<br><a data-href=\"Beam Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Beam Search</a>: Keeps track of only the nodes with the best f-scores. Is incomplete and suboptimal, but very fast and memory efficient. <br><a data-href=\"Iterative Deepening A*\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Iterative Deepening A*</a>: Combines the advantages of A* and iterative deepening DFS, where, at each iteration, the cutoff values is the smallest f-score of any node that exceeds the cutoff of the previous iteration. The initial cutoff is the heuristic value of the root node. <br>Can be visualized using <a data-href=\"Search Contours\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Search Contours</a>. <br><a data-href=\"Recursive Best-First Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Recursive Best-First Search</a>: Uses a f-limit variable to keep track of the f-value of the best alternative path from any ancestor of the current node. If the current node exceeds that f-limit, the recursion unwinds to the alternative path. Is optimal if the heuristic is admissible. Both RBFS and IDA use too little* memory, meaning they forget most of what they've done.\n<br><a data-href=\"Memory-Bounded A*\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Memory-Bounded A*</a>: And <a data-href=\"Simplified Memory-Bounded A*\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Simplified Memory-Bounded A*</a> uses all the memory that is allocated to it. SMA proceeds like A, expanding the node with the best f-score until memory is full. In that case, it drops the node with the highest f-score and passes its value to the parent, similar to RBFS. If all nodes have the same f-score, the oldest node is deleted and the newest is expanded.\nIs complete and optimal if the optimal solution can fit in memory. <br>\nOne way to analyze the quality of a heuristic is the <a data-href=\"Effective Branching Factor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Effective Branching Factor</a> . <br>If is the total number of nodes generated by A and the solution depth is , $b^$ is the branching factor a <a data-href=\"Uniform Tree\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Uniform Tree</a> of depth must have to contain nodes. A well-designed heuristic should have a branching factor close to 1. <br>\n<a data-href=\"Relaxed Problems\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Relaxed Problems</a>: problems with fewer restrictions on available actions. For example, allowing illegal moves in the <a data-href=\"N-Queens Problem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">N-Queens Problem</a>. The cost of an optimal solution in a relaxed problem is an admissible and consistent heuristic for the original problem.\nAdmissible heuristics can also be derived from subproblems of the original problem where the optimal cost in the subproblem is a lower bound on the cost of the complete problem. <br>\n<a data-href=\"Pattern Database\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pattern Database</a>: Stores the exact solution costs for possible subproblem instances. Commonly used to store <a data-href=\"Endgame Tablebase\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Endgame Tablebase</a>s for an AI <a href=\"https://emujakic.github.io/TechKB/projects/ai-chess-robot/chess-engine.html\" target=\"_self\" rel=\"noopener noreferrer\" from=\"12\" to=\"24\" origin-text=\"chess engine\" class=\"internal-link virtual-link-a\">chess engine</a>, for example. When searching for a solution, the agent can use the pattern database to quickly estimate the cost for a given state.\nDisjoint pattern databases ignore rather than abstract the rest of the problem. Pre-computation stores the optimal path between pairs of vertices. Landmark points can be precomputed and used as an efficient but inadmissible heuristic. <br>\n<a data-href=\"Metalevel State Space\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Metalevel State Space</a>: Allows an agent to reason about its own reasoning process by evaluating potential strategies and their outcomes. Metalevel state spaces allow an agent to learn from experience and dynamically adjust their strategy based on observed output. Local search algorithms search the state space without keeping track of a path or previously reached states. These algorithms are not systematic, though they use very little memory, and usually have constant space complexity.\nLocal search is good for problems where only the final state is desired and not so much the path to get there. The most common application of local search is solving optimization problems, where the goal is to find the best state according to some objective function. Consider the states of a problem laid out in a state-space landscape—a line chart where each state has an elevation defined by the objective function. <br>If the goal is to find the highest peak, then the problem is called <a data-href=\"Hill Climbing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hill Climbing</a>.\n<br>If the goal is to find the lowest valley, the problem is called <a data-href=\"Gradient Descent\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gradient Descent</a>. Hill Climbing: An optimization algorithm which keeps track of the current state, and on each iteration, moves to the neighboring state which provides the steepest ascent, that is, it moves uphill. Hill climbing terminates when it reaches a peak, or local maximum, a point where no neighboring state has a higher value.\nSince it doesn't look ahead past it's immediate neighbors, nor does it consider more than the next move, hill climbing is considered a greedy local search.\nHill climbing is also susceptible to plateaus, a flat region of the state space landscape. A plateau is a shoulder if it immediately neighbors a better state. <br>\n<a data-href=\"Stochastic Hill Climbing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Stochastic Hill Climbing</a>: Chooses randomly from the set of available uphill moves. Typically, the <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probability</a> of a move being selected is linear to the steepness of the move. <br>\n<a data-href=\"First-Choice Hill Climbing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Choice Hill Climbing</a>: Randomly generates successors until a state better than the current one is generated. <br>\n<a data-href=\"Random-Restart Hill Climbing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Random-Restart Hill Climbing</a>: Conducts a series of searches from random initial states, until a goal is found. Random-restart is complete, since it will eventually generate a goal as the initial state.\nIf each search has a probability of success, the expected number of restarts is . <br>\n<a data-href=\"Simulated Annealing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Simulated Annealing</a>: A local search algorithm with a temperature which determines the <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"22\" to=\"33\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> of the algorithm accepting a downhill move. The algorithms starts with a high temperature, which decreases over iterations. The probability of a move being selected decreases with the \"badness\" of the move.\nSince simulated annealing can make downhill moves, this allows it to escape local maxima that other algorithms can't. <br>\n<a data-href=\"Local Beam Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Local Beam Search</a>: A local search algorithm which keeps track of states rather than just one. It begins with randomly generated states, and at each iteration, generates all the neighbors of all states. If one of the successors is a goal state, then the algorithm halts; else, the algorithm selects the best successors and repeats. A variant of local beam search, called stochastic beam search, chooses successors with probabilities proportional to their values. <br>\n<a data-href=\"Genetic Algorithms\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Genetic Algorithms</a>: A variant of local beam search inspired by the principles of natural selection and genetics. Successor states are generated by a process called recombination, where two parent states are combined to make a new state. One approach to recombination is to randomly select a crossover point, which splits each of the parent strings and recombines them to form a child. Genetic algorithms starts with a \"population\" of states, where each state is evaluated based on its fitness level, which determines the likelihood of that state being selected for reproduction. The mutation rate determines the probability that each bit in the offspring string is flipped. This ensures diversity in the population. Elitism is where a number of high-scoring individuals from the previous generation are propagated forward into the current generation without modification. This ensures that high-quality solutions are preserved while still maintaining diversity. Culling is where individuals performing under a certain threshold are removed from the population. Schema: A substring where some positions are left unspecified. Schemas can be thought of as templates or patterns for a full solution. Genetic algorithms work best when schemas correspond to meaningful components of a solution. Continuous Space: A state space with an infinite branching factor. Most real-world environments are continuous. You can discretize a continuous space be limiting values to fixed intervals.\nAlternatively, you can make the branching factor finite by sampling successor states randomly, in a random direction by some small amount . <br>\n<a data-href=\"Gradient\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gradient</a>: A <a data-href=\"Vector\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Vector</a> that contains all the <a data-tooltip-position=\"top\" aria-label=\"Partial Derivative\" data-href=\"Partial Derivative\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">partial derivatives</a> of a function. Empirical Gradient: The gradient of a function based on observed data rather than analytical calculation. <br>\n<a data-href=\"Line Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Line Search</a>: An optimization technique that is used to find a satisfactory step size along a specific direction to minimize a function. <br>\n<a data-href=\"Newton-Raphson Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Newton-Raphson Algorithm</a>: A general method for finding roots of functions, that is, solutions to equations of the form . Constrained Optimization Problem: An optimization problem where solutions must satisfy some constraints on the value of variables. <br>The most well-known category of constrained optimization problems are <a data-href=\"Linear Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Linear Programming</a> problems.\n<br>Linear programming is a case of the more general problem of <a data-href=\"Convex Optimization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Convex Optimization</a>. Search with Nondeterministic Actions: When the environment is partially-observable or is nondeterministic, the agent either doesn't exactly know it's current state (sensor model), or the next state (transition model) respectively. <br>\n<a data-href=\"Belief State\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Belief State</a>: The set of states that the agent believes it could be in. In nondeterministic or partially-observable environments, the solution to a problem is a conditional plan rather than a sequence of actions. The action to take is conditionally dependent on the percepts received. In a nondeterministic environment, the transition model returns a set of possible states, rather than a single state. The conditional plan can contain if-else statements, which allows solutions to be represented as trees rather than sequences. In a deterministic environment, the only branching is introduced by the agent's actions. These are called 'or' nodes. In a non-deterministic environment, branching is also introduced by the environments choice of outcome for each action. These are called 'and' nodes. <br>\nThese two nodes alternate to create an <a data-href=\"And-Or Tree\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">And-Or Tree</a>. A solution for an and-or search problem is a subtree where: Every leaf is a goal node.\nSpecifies an action at each OR node.\nIncludes each outcome of each AND node. And-or graphs can be explored using breadth-first or depth-first search. Cycles can arise in nondeterministic problems, one case is where an action has no effect on the current state. If an agent is in an environment where actions can fail, there are no acyclic solutions.\nOne workaround is to use a while construct, where an action is repeated until it succeeds. This is only useful if repeating the action increases the probability that it succeeds. Sensorless Problems: A problem where an agent's percepts provide no information on the state of the environment. The solution to sensorless problems is a sequence of actions, not a conditional plan, since there are no possible percepts to condition on.\nIf problem has states, the belief-state problem has states.\nThe initial state is typically all the states of .\nIf the agent is unsure about what state it is in, and if some actions are only legal in particular states, then the agent is unsure about what actions it can legally perform. If illegal actions have no consequence on the environment, then the agent can take the union of all actions. Though, if performing illegal actions can be detrimental, then it is safer to take the intersection of available actions.\nThe transition model for belief states results in a new belief state with all the possible results of the action for each state in the current belief state.\nThe agent is possibly in a goal state if the current belief state contains a goal state. The agent is necessarily in a goal state if every state in the current belief state is a goal state.\nThe path cost could be one of several values if the same action has different costs in different states.\nIn ordinary graph search, newly reached states are tested to see if they've been visited previously, this can be done for belief states as well. If the current belief state is a superset of a previous belief state, we can discard the superset belief state since a solution to the superset must be a solution for each state in the corresponding subset.\nAdditionally, if the superset has been proven to be solvable, then any of its subsets are guaranteed to be solvable. This extra level of pruning can dramatically increase the efficiency of sensorless solutions. Though, even with this pruning, sensorless problems are still too vast to be solved efficiently.\nOne alternative is to avoid standard search algorithms, and use algorithms that look within belief states and develop incremental belief-state search algorithms. Partially Observable Problems: Problems where the agent has a PERCEPTS function which returns the percept received by the agent's sensors in a given state. If sensing is nondeterministic, the PERCEPTS function can return a set of possible percepts.\nWith partial observability, many states can produce the same percepts.\nThe two main differences between agents in partially observable environments and fully observable deterministic environments is: The solution is a conditional plan rather than a sequence.\nThe agent needs to maintain a belief state. Online Search: A search algorithm which interleaves action and planning. This is useful in dynamic or semi-dynamic environments, where the environment can change while the agent is deliberating. Online search is also useful in nondeterministic environments by focusing on contingencies which actually occur, rather than the set of all possible contingencies.\nThe competitive ratio is the discovered solution cost to the optimal cost if the environment was known.\nOnline agents can get stuck in dead-ends, states from which no goal is reachable.\n<br>One common example of online search are <a data-href=\"Simultaneous Localization and Mapping\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Simultaneous Localization and Mapping</a> or SLAM problems, where an agent must build a map of an unknown environment while simultaneously keeping track of its position within that environment.\nAn offline algorithm explores a model of the state space, while an online algorithm explores the real world. Therefore, an online algorithm can only discover successors for the state it is currently in, while offline algorithms can jump around the state space.\nIn an online DFS, when an agent has tried all the actions in a given state, it must backtrack in the physical world. This can be done by keeping track of the predecessor states of the current state. Though this only works if the actions in the state-space are reversible. Online Local Search: Algorithms like hill climbing or gradient descent are already considered online algorithms. Though, these algorithms are not as good for exploration due to getting stuck at local maxima/minima. A random walk simply selects one of the actions available at random. Preference can be given to actions that have yet to be tried.\nHill climbing can be augmented with memory, where a heuristic value is stored for each visited state.\nOptimism under uncertainty encourages the agent to explore new paths, rather than go down already explored paths.\n<br><a data-href=\"Learning Real-Time A*\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Learning Real-Time A*</a>* updates the cost element for the state it just left, then chooses the best move according to it's current cost element. Factored Representation: A way of representing states as a set of variables that each have a value. <br>\n<a data-href=\"Constraint Satisfaction Problem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Constraint Satisfaction Problem</a>: Specifies constraints on the values of variables of a state. The solutions is the set of states where each variable satisfies every constraint on it. A CSP has three components: : The set of variables.\n: The set of domains, one for each variable. A domain can be discrete, continuous, finite, or infinite.\n: The set of constraints. Each constraint is a pair , where is a tuple of variables and is a relationship defining the values that each in-scope variable can take on. A relationship may be written as an explicit set of tuples, or as a function.\nA unary constraint deals with one variable, a binary constraint deals with two. A constraint that deals with more than two variables is called a global constraint, even if it doesn't involve all variables.\nPrecedence constraints assert that one task must be complete before another.\nDisjunctive constraints allow a disjunction of conditions to satisfy the constraint.\n<br>Preference constraints are encoded as costs on variable assignments. CSPs with preferences can be solved using path-based or local optimization search algorithms. Such a problem is called a <a data-href=\"Constraint Optimization Problem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Constraint Optimization Problem</a>.\nWith infinite domains, you must use implicit constraints.\n<br><a data-href=\"Linear Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Linear Programming</a> problems are an example of CSPs in continuous domains, since each constraint is a linear equality/inequality. An assignment which satisfies all constraints is consistent or legal. An assignment is complete if it assigns a value to each variable.\nA solution is a legal and complete assignment. <br>\n<a data-href=\"Constraint Graph\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Constraint Graph</a>: A data structure in which nodes correspond to state variables, and edges correspond to binary constraints between variables. Constraint Hypergraph: Consists of nodes (circles) and square nodes—hypernodes that represent -ary constraints involving variables. Auxiliary Variables: A temporary variable used to simplify problems or represent certain constraints. Constraint Propagation: Uses the constraints on variables to reduce the legal values for variables, which could reduce the domains of other variables, and so on. Enforcing local consistency on nodes in a constraint graph causes inconsistent values to be eliminated throughout the graph. Node Consistency: A variable is node-consistent if all the values in its domain satisfies all the unary constraints on out.\nArc Consistency: A variable is arc-consistent if every value in its domain satisfies all binary constraints it's a part of. <br>\n<a data-href=\"AC-3\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">AC-3</a>: The most popular arc-consistency algorithm which maintains a queue of arcs to consider. AC-3 pops an arc from the queue, (), and makes arc-consistent with respect to .\nIf the domain of , remains the same, it moves on to the next arc.\nIf the domain of changes, then all arcs are enqueued, where is a neighbor of .\nThe complexity is where is the number of arcs and is the maximum size of the domain. Path Consistency: A set of variables are path consistent if, for every assignment to and consistent with their constraints, there is an assignment to that satisfies constraints on () and (). This refers to the overall consistency of the path from to through a third variable . -Consistency: A CSP is -consistent if, for any set of variables, and for any consistent assignment to those variables, a consistent value can be assigned to any th variable. Arc-consistency is considered 2-consistent.\nA CSP is strongly -consistent if it is -consistent, -consistent, all the way to 1-consistent. The alldiff constraint says that all in-scope variables must have distinct values. The resource constraint, also called the at-most constraint, is a limitation on the availability of a particular resource. <br>\nFor large problems, it is common to represent domains using upper and lower bounds. These domains are managed by <a data-href=\"Bounds Propagation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bounds Propagation</a>. A CSP is bounds-consistent if, for every variable , the lower and upper bounds of have corresponding values in the domain of every variable such that the constraints on and are satisfied. This means that for each value within the bounds of , there exists at least one compatible value in the domain of that meets the constraints. <br>\nFor a CSP with variables, the tree representing the CSP has leaves even though there are only possible complete assignments. We can reduce this by a factor of if we recognize that CSPs are <a data-tooltip-position=\"top\" aria-label=\"Commutative Property\" data-href=\"Commutative Property\" href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">commutative</a>. Commutativity means that the order of application of a set of actions does not matter. With this restriction, the number of leaves is . <br>\n<a data-href=\"Backtracking Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Backtracking Search</a>: A depth-first search for CSPs is used when after performing constraint propagation, there are still multiple possible values for variables. A recursive backtracking search chooses an unassigned variable, then chooses a value for that variable which satisfies all the constraints on the variable. If the call assigns a value to all variables successfully, then a solution is returned. If a variable's domain becomes empty, then the call backtracks by undoing the last assignment and tries another legal value.\nThe simplest strategy for selecting an unassigned variable is called static ordering. This strategy simply chooses the variables in the order that they appear in. The next simplest strategy is choosing randomly. Neither of these are optimal.\nMinimum-Remaining-Values Heuristic: Chooses the variable with the least amount of values in its domain. If some variable has no legal values left, the MRV heuristic will recognize this immediately and start backtracking.\nDegree Heuristic: Chooses the variable that is involved in the largest number of constraints with other unassigned variables. This is typically used as a tiebreaker for the MRV heuristic.\nLeast-Constraining-Value Heuristic: Chooses the value in the current variables domain which rules out the fewest choices for neighboring values in the constraint graph. Forward Checking: A form of inference where whenever a variable is assigned a value, the forward-checking process establishes arc-consistency for it. For each unassigned neighbor of , delete any values from its domain that is inconsistent with the value chosen for .\nFor many problems, the search is more efficient if the MRV heuristic and forward-checking are combined.\nForward-checking is not a complete method for discovering inconsistencies. <br>\n<a data-href=\"Maintaining Arc-Consistency\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Maintaining Arc-Consistency</a>: An algorithm that can detect more inconsistencies than forward checking. It creates a queue of all arcs in the CSP, then pops one ().\nFor each value in 's domain, check if there exists a value in that satisfies the constraint. If not, remove the value from 's domain.\nIf the domain of changes, add all arcs that are connected to back in the queue. Chronological Backtracking: A backtracking method which backtracks to the previous assigned variable and tries a new value for it. This is not an intelligent way to backtrack. A better way is to backtrack to variables that are more likely to fix the problem. One way to do so is to keep a conflict set—a set of assignments that are in conflict with some value of the current variable.\n<br>The <a data-href=\"Backjumping Method\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Backjumping Method</a> moves back to the most recent assignment in the conflict set. Forward checking can be modified to supply a conflict set.\n<br><a data-href=\"Conflict-Directed Backjumping\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Conflict-Directed Backjumping</a>: The conflict set for a variable is the set of preceding variables that cause to current variable to fail, together with any subsequent failed variables. <br>\n<a data-href=\"Constraint Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Constraint Learning</a>: The process of learning and adding new constraints whenever an inconsistency is detected. It involve finding the minimum set of variables from the conflict set which causes the inconsistency. Local Search For CSPs: Local search algorithms can be effective for solving CSPs. A complete state formulation is used, meaning each state assigns a value to every variable and the search changes the value of one variable at a time. The landscape of a CSP using the min-conflicts heuristic usually has a series of plateaus. Plateau search allows sideways movements across plateaus which helps avoid getting stuck at local maxima.\nTabu search can avoid wandering back and forth on a plateau by keeping a list of recently visited states and forbidding the algorithm to return to such states. Constraint Weighing: Assigns weights to constraints based on their importance. All constraints are initiated with a weight of 1, and each time a constraint is violated, its weight is incremented. This adds topography to plateaus, and it adds a form of machine learning. Independent Subproblem: A subset of variables and constraints in a CSP which can be solved without considering the rest of the problem. Independence can be discovered by finding independent components in the constraint graph. Though, comp\nIndependent subproblems can be solved in time linear in , the number of variables. Without this decomposition into subproblems, the work required is exponential in . Though, fully independent subproblems are rare in practice. There are constraint graph structures other than independent subproblems which are easy to solve. A constraint graph is a tree when any two variables are connected by only one path. Tree-structured CSPs can also be solved in linear time using directional arc-consistency. A CSP is DAC if under an ordering of variables , every is arc-consistent with every where .\nTo solve a tree-structured CSP, pick any variable as the root of the tree, then choose an ordering such that each variable appears after its parent in the tree. This is called a topological sort. Once you have a DAC graph, you can simply go down the list of variables and choose any remaining values. A constraint graph can be reduced to a tree by fixing the values of some variables, such that the remaining unassigned variables form a tree. A cycle cutset is a set of edges whose removal would disconnect the graph or eliminate cycles. There are approximation algorithms for finding the smallest cycle cutset. Tree Decomposition: Another technique for reducing a constraint graph to a tree. It is a transformation in which each node of the resulting tree consists of a set of variables from the original graph. A tree decomposition must satisfy three requirements: Every variable appears in at least one tree node.\nIf two variables have an edge between them, both variables and their constraint must appear in at least one tree node.\nIf a variable appears in two nodes, it must appear in each node along the path connecting those nodes. Value Symmetry: The situation where distinct values of a variable's domain lead to the same solution. You can reduce the search space by a factor of by breaking up symmetry in the assignments. This is achieved using symmetry breaking constraints. For example, you can enforce the values of three variables to be in alphabetical order, allowing only one solution. <br>\nCompetitive Environment: A multi-agent environment in which agents have conflicting goals. This results in <a data-href=\"Adversarial Search Problems\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Adversarial Search Problems</a>. In the case where there is a large number of agents, we can consider them in the aggregate as an economy, allowing us to make predictions without considering the actions of each individual agent.\nWe can also model adversaries as a stochastic part of the environment itself.\n<br>A third option is to model the adversarial agents explicitly with the techniques of <a data-href=\"Adversarial Game Search Tree\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Adversarial Game Search Tree</a>. Pruning is the process of ignoring certain parts of the search tree that don't impact the optimal move.\nA heuristic evaluation function estimates who is winning in each state based on the features of the state. An agent has imperfect information if it doesn't have complete knowledge about the environment. Imperfect information is also called partial observability, where perfect information is called full observability. <br>\nChess is a two-player, deterministic, turn-taking, perfect-information, <a data-href=\"Zero-Sum\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Zero-Sum</a> game. In multi-agent environments, actions are called moves and states are called positions.\nA zero-sum game is a game where the sum of the payoffs to all players equals 0. Meaning whatever one player gains is directly cancelled out by the loss of another player. A game can be formally defined with the following components: : The initial state of the game.\nTO-MOVE(s): A function that returns the player whose turn it is in state .\nACTION(s): Returns the set of legal actions in state .\nRESULT(s, a): The transition model defining the result of action in state .\nIS-TERMINAL(s): Returns true if state is a terminal state, meaning the game is over.\nUTILITY(s,p): A utility function defining the utility value to player when the game ends in terminal state . <br>\n<a data-href=\"State-Space Graph\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">State-Space Graph</a>: Defined by the initial state, actions, and result function. Nodes represents positions (states), and edges represent moves. <br>\n<a data-href=\"Game-Tree\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Game-Tree</a>: A specialized form of a state-space graph, it assumes a two-player turn-taking game. One player is designated the MAX player, who is trying to maximize the objective function; the other player is the MIN player, who is trying to minimize the objective function.\nA ply refers to a single move made by a single agent. <br>\nFor an agent to act rationally, its <a data-href=\"Strategy\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Strategy</a> must be conditioned upon the actions of the other player. <br>\n<a data-href=\"Minimax Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Minimax Algorithm</a>: Given a game tree, the optimal move can be determined by working out the minimax value of each state, denoted as MINIMAX(s). MAX prefers a higher value, while MIN prefers a lower value.\n<br>The algorithm performs a complete <a data-href=\"Recursive\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Recursive</a> <a data-href=\"Depth-First Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Depth-First Search</a> exploration. It proceeds down to a leaf node, and backs up the minimax value through the tree as the recursion unwinds.\nThe complexity of minimax by itself is where is the branching factor of the tree and is the max depth of the tree. <br>\n<a data-href=\"Alpha-Beta Pruning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Alpha-Beta Pruning</a>: An optimization technique used in the minimax algorithm which prunes suboptimal branches. It keeps track of two values: Alpha: The highest-value choice found so-far along the path for the MAX player.\nBeta: The lowest-value choice found so-far along the path for the MIN player.\nIf MAX's score exceeds MIN's beta value, the branch is beta-pruned.\nIf MIN's score is less than MAX's alpha value, the branch is alpha-pruned. The effectiveness of alpha-beta pruning is dependent on the order in which states are examined. If we could first examine the best states, minimax with pruning would reduce to . This is in the case of perfect move ordering. If the best moves are evaluated first, the alpha and beta values can be updated more quickly. This allows for more effective pruning of suboptimal branches. Using heuristics can lead to better move orderings. For example, moves that capture pieces or attack the king can be examined first, in the case of a chess game.\nKiller moves are moves that have caused pruning in previous searches. Prioritizing these moves is called the killer moves heuristic. Repeated states may occur in a game tree due to transpositions, which are different permutations of the same move sequence leading to the same position. <br>Transpositions are addressed using <a data-href=\"Transposition Tables\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transposition Tables</a>. Say two move sequences, and both lead to the same state . We can find the value of state when exploring sequence and store it in the transposition table. Then, when we reach state from sequence , we can simply look up its value in the table. <br>\n<a data-href=\"Type A Strategy\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Type A Strategy</a>: Evaluates all possible moves to a certain depth in the game tree and uses a heuristic function to estimate the utility of states at that depth. This cuts the search off early and applies a heuristic function to states, effectively treating non-terminal states as terminal.\nIn this case, you replace the utility function with an EVAL function, and the terminal test function is replaced with a cutoff test, which returns true for terminal nodes, but is otherwise free to decide when to cut off a search. <br>\n<a data-href=\"Type B Strategy\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Type B Strategy</a>: Ignores moves that look bad, and follows promising lines as far as possible. <br>\n<a data-href=\"Heuristic Evaluation Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heuristic Evaluation Function</a>: Returns an estimate of the expected utility of a state to player . For terminal states, EVAL(s,p) must equal UTILITY(s,p). For non-terminal states, the evaluation must be between a loss and a win.\nMost evaluations work by calculating various features of states. The features taken together define various categories or equivalence classes of states. This enables the evaluation function to return a single variable which estimated the proportion of states with each outcome in that equivalence class.\n<br>A weighted linear function computes separate contributions from each feature, and combines them for the total value. It's defined as: . The weights should be normalized so that the sum is always within the <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"59\" to=\"64\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> . <br>\nCutting-Off: The most straightforward approach to cutting the search early. This method sets a fixed depth limit as the cutoff point. This is called a <a data-href=\"Depth-Limited Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Depth-Limited Search</a>. <br>\n<a data-href=\"Iterative Deepening\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Iterative Deepening</a>: Iteratively performs depth-limited searches, incrementing the depth limit on each iteration. The evaluation function should only apply to positions that are quiescent or stable, meaning there is no pending move that would drastically change the evaluation. <br>The IS-CUTOFF function should return false for non-quiescent states. This is called a <a data-href=\"Quiescent Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Quiescent Search</a>. Horizon Effect: Occurs when the agent is facing a devastating move from the opponent, but can delay it beyond its horizon by performing other moves. <br>One way to address this is to allow <a data-href=\"Singular Extensions\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Singular Extensions</a>, which are moves that are clearly better than all other available moves in a given position. <br>\n<a data-href=\"Forward Pruning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Forward Pruning</a>: Prunes moves that appear to be poor moves, but might in fact be good. This saves computation time by incurring the risk of pruning good moves and is considered a type B strategy.\n<br>One approach, called <a data-href=\"Beam Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Beam Search</a>, on each ply, considers only the beam of the best moves according to the evaluation function.\nProbabilistic Cut Algorithm: A forward-pruning approach to alpha-beta search that uses statistics derived from previous experience to lessen the chance that the optimal move gets pruned. <br>\n<a data-href=\"Late Move Reduction\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Late Move Reduction</a> assumes that move ordering has been done well, therefore, moves that are later in the sequence are less likely to be good moves. Rather than pruning the late moves, we just reduce the depth at which they are searched. If the shallow search returns a value above the current alpha, the search is re-run at full depth. Table Lookup: Rather than search, table lookup stores and retrieves the best move from a data structure. A program can then produce a policy, which is a mapping from every possible state to the optimal move in that state. <br>This is commonly used in chess engines to save <a data-tooltip-position=\"top\" aria-label=\"Endgame Tablebase\" data-href=\"Endgame Tablebase\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Endgame Tablebases</a>, which allows the engine to play endgames perfectly. This table is constructed with a <a data-href=\"Retrograde Minimax Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Retrograde Minimax Search</a>, which involves evaluating the end of the game backward to the beginning. <br>\n<a data-href=\"Monte-Carlo Tree Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Monte-Carlo Tree Search</a>: A search algorithm that doesn't use a heuristic evaluation function, instead it calculates the average utility over a number of complete games starting from a given state. This is the same as the win percentage for games with binary win/lose outcomes MCTS is considered a kind of <a data-href=\"Reinforcement Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Reinforcement Learning</a>. Playout Policy: chooses which moves to make during a play-out simulation. These policies can be learned by self-play using neural networks.\nEarly playout termination is when a playout is stopped early because it is taking too many moves. The playout is either evaluated with a heuristic or is declared a draw.\n<br>A pure MCTS does simulations starting from the current state and tracks which possible moves have the highest win percentage. For some stochastic games, this converges to optimal play as increases, though it isn't sufficient for most games. We instead need a selection policy which balances the <a data-href=\"Exploration-Exploitation Tradeoff\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Exploration-Exploitation Tradeoff</a>.\nMCTS does this by maintaining a search tree and growing it at each iteration of the following four steps: Selection: Starting at the root, we choose a move (according to the selection policy), leading to a successor state, and repeat this process to a leaf node.\nExpansion: We grow the tree by generating a new child of the selected node.\nSimulation: We perform a playout from the newly generated node, choosing moves according to the playout policy.\nBack-Propagation: We use the result of the simulation to update all nodes going up to the root. <br>\n<a data-href=\"Upper Confidence Bound\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Upper Confidence Bound</a>: A selection policy which ranks possible moves according to the UCB formula: Where is the average reward obtained from action , is the total number of trials, is the total number of trials where action was selected, and is a constant which controls the degree of exploration. Stochastic Games: A class of games which are in an environment that exhibit randomness. A standard game tree cannot be used to model stochastic game because of their inherit uncertainty. <br>Chance nodes are included which denote the possible outcomes of some random variable and their <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probabilities</a>.\n<br>Positions do not have definite MINIMAX values, an <a data-href=\"Expected Value\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Expected Value</a> is calculated instead. This leads to the expectminimax values for games with chance nodes. Knowledge-Based Agent: Uses reasoning processes over an internal knowledge representation. The central component of a knowledge-based agent is its knowledge base (KB). <br>\n<a data-href=\"Knowledge Base\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Base</a>: A set of sentences, each expressed in a knowledge representation language and represents some assertion about the world. When the sentence isn't derived from other sentences, it is called an axiom.\nA KB may initially contain some background knowledge. TELL and ASK are the names for adding to or querying the KB, respectively. Each of these operations may include inference: deriving new sentences from existing ones. Each time a knowledge-based agent is called it: TELLs the KB what it saw (its percepts).\nASKs the KB what action to perform. This usually requires extensive reasoning.\nTELLs the KB what action was chosen and returns that action. Declarative Approach: Starts with an empty KB, and the agent designer TELLs sentences one by one until the agent can operate in its environment. Procedural Approach: Encodes desired behavior directly as program code. <br>\n<a data-href=\"Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic</a>: A formal system that uses symbols and syntax to represent logical expressions and arguments. A logic must also define the semantics, or meaning, of sentences. The semantics defines the truth of each sentence with respect to each possible world.\nThe term model is commonly used in place of possible world. When possible worlds represent potentially real environments, a model is a mathematical abstraction, which has a fixed truth value for every relevant sentence. Logical entailment between two sentences means that a sentence follows logically from another sentence. Entailment is represented symbolically as . This means entails if and only if, in every model where is true, is also true. <br>\n<a data-href=\"Logical Inference\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logical Inference</a>: The process of deriving new conclusions from existing premises. Model Checking: Enumerating all possible models to check if is true in all models where the KB is true. <br>\n<a data-href=\"Inference Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Inference Algorithm</a>: A computational method which derives entailed sentences based on a KB. IF a inference algorithm derives only entailed sentences, it is sound or truth preserving. If it derives all entailed sentences, it is complete. If some inference algorithm can derive from KB, it is said that \" is derived from KB by \". This sentence is represented symbolically as: Grounding: The connection between logical reasoning processes and the real environment. The agent's sensors create this connection and the general rules of this environment are produced by a sentence construction process called learning. <br>\n<a data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositional Logic</a>: A branch of <a data-href=\"Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic</a> that deals with propositions, which are statements that are either true or false. <a href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"2\" to=\"21\" origin-text=\"Propositional logic\" class=\"internal-link virtual-link-a\">Propositional logic</a> is made up of: Propositional Symbols: Symbols that start with an uppercase letter and refer to a proposition. For example, , , and are examples of propositional symbols. Each symbol represents a distinct statement that can be true or false. Individual symbols are commonly referred to as literals. A literal is negative if there is a negation applied to it (e.g. ), else, it's a positive literal. Logical Connectives: Operators which combine propositional symbols to create complex sentences. The common connectives include: Negation (NOT, ¬)\nConjunction (AND, ∧)\nDisjunction (OR, ∨)\nImplication (IMPLIES, →)\nBiconditional (IF AND ONLY IF, ↔)\nXOR (EXCLUSIVE OR, ) Atomic Sentence: An atomic sentence consists of a single propositional symbol and represents a basic assertion. Complex Sentence: A complex sentence is made up of propositional symbols connected by parenthesis and logical connectives. They are also called formulas. In propositional logic, a model is simply a setting of truth values for each propositional symbol. There are possible models, where is the number of propositional symbols. <br>\n<a data-href=\"Truth Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Truth Table</a>: species the truth value of sentences for each possible assignment of truth values for symbols. <br>\nPropositional logic is <a data-tooltip-position=\"top\" aria-label=\"Monotonicity\" data-href=\"Monotonicity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Monotonic</a>, meaning that when you add knowledge to a propositional <a data-href=\"Knowledge Base\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Base</a>, it cannot lead to the loss of previously established truths. <br>\n<a data-href=\"Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Theorem Proving</a>: Applying rules of inference to sentences in a KB to construct a proof of a sentence without checking models. <br>\n<a data-href=\"Rules of Inference\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Rules of Inference</a>: Logical rules which provide the structure for how new statements can be derived from existing ones. Proofs: In propositional logic, proofs are essential for establishing the truth of a statement or the validity of an argument. A proof is a demonstration that a conclusion follows from a set of premises. Any of the ch.3 search algorithms can be used to find a sequence of steps to constitute a proof. We define a proof as the following components: Initial State: The initial KB.\n<br>Actions: The set of all the inference rules applied to all the sentences that match the top half of the inference rule. The top half refers to the numerator of the inference rule in <a data-href=\"Gentzen Notation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gentzen Notation</a>.\nResult: The bottom half of the inference rule, or the denominator of the inference rule in Gentzen notation.\nGoal: A state that contains the sentence which we are trying to prove. <br>\n<a data-href=\"Modus Ponens\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Modus Ponens</a>: Modus Ponens is a syllogistic argument form and rule of inference. It has the following structure: If then .\n.\nTherefore, . <br>\nLogical Equivalence: Two sentences are said to be logically equivalent if they have the same truth table. This is denoted using the symbol. A <a data-href=\"Rule of Replacement\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Rule of Replacement</a> is a logical principle that allows for the substitution of one logical expression, for another, logically equivalent expression. Rules of replacement are used to construct proofs, simply logical expressions, and verify the correctness of logical statements. <br>\nValidity: A sentence is valid if it is true in all models. This is called a <a data-href=\"Tautology\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Tautology</a>, meaning that the sentence is necessarily true. Satisfiability: A formula is satisfiable if there is at least one assignment of truth values which makes the formula true. If there is no assignment of truth values to make the formula true, then it is unsatisfiable, also called a contradiction. <br>\n<a data-href=\"Proof by Contradiction\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Proof by Contradiction</a>: An indirect proof that assumes the conclusion is false, then proves that this assumption leads to a contradiction. If assuming the conclusion is false does lead to a contradiction, then the conclusion must be true. A clause is a disjunction/conjunction of literals. When talking about clauses, usually it refers to a disjunctive clause, which is a logical expression formed by connecting literals with the OR operator. The empty clause is a clause with no literals, commonly denoted as , , or . An empty disjunctive clause is always false, making it analogous to a contradiction. This is an important concept in proof by contradiction, as reaching an empty clause indicates that a contradiction has been proven. <br>\n<a data-href=\"Horn Clause\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Horn Clause</a>: A disjunctive clause with at most one positive literal. Definite Clause: If a Horn clause has exactly one positive literal, it is a definite clause. For example, .\nGoal Clause: If it has no positive literals, it is a goal clause. For example, .\n<br>Horn clauses are computationally efficient for algorithms such as <a data-href=\"Resolution Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Resolution Theorem Proving</a>, or for <a data-href=\"Forward/Backward Chaining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Forward/Backward Chaining</a>. This makes them the basis of many <a data-href=\"Logic Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logic Programming</a> languages, as well as for automated theorem proving or database querying. <br>\nProof by <a data-href=\"Resolution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Resolution</a>: Resolution resolves two clauses which contain complementary literals. Two literals are complements of one another if one is the negation of the other (e.g. and ). Resolution is defined: The above example resolves and resulting in a new clause called the resolvent. Only one pair of complementary literals can be resolved at a time.\n<br>In the context of <a data-href=\"Automated Theorem Proving\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Automated Theorem Proving</a>, resolution is applied repeatedly to derive a contradiction, thereby proving that the negation of the statement that's being proven, is unsatisfiable. Resolution closure of a set of clauses is the set of all clauses derivable by repeated application of the resolution rule to clauses in or their derivatives.\n<br>The completeness theorem for resolution in <a data-tooltip-position=\"top\" aria-label=\"Propositional Logic\" data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">propositional logic</a> is called the ground resolution theorem. <br>\n<a data-href=\"Conjunctive Normal Form\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Conjunctive Normal Form</a>: A sentence is considered to be in conjunctive normal form (CNF) if it's a conjunction (AND) of one or more clauses. A -CNF sentence is a CNF sentence where each clause has at most literals. If a KB contains only definite clauses: Every definite clause can be written as an implication whose premise is a conjunction of positive literals and whose conclusion is a single positive literal. Ex: .\nIn Horn form, the premise is called the body and the conclusion is called the head. <br>\n<a data-href=\"Forward Chaining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Forward Chaining</a>: An algorithm which determines if a single propositional symbol (the query), is entailed by a knowledge base of definite clauses. It starts with known facts (single, positive literals), if all the premises of an implication are known, then its conclusion is added to the set of known facts.\nThis process continues until the query is added, or until no further inferences is made.\nForward chaining runs in linear time, is sound, and complete. <br>\n<a data-href=\"Backward Chaining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Backward Chaining</a>: Works backwards from the query. If is known to be true then no work is needed. Else, the implications in the KB whose conclusion is are found.\nIf all the premises of one of those implications is known to be true, then is true.\nOften runs in sublinear time. Model checking is used to check the satisfiability of a query. <br><a data-href=\"Davis-Putnam Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Davis-Putnam Algorithm</a>: A model checking algorithm which takes as input a formula in CNF. Like <a data-href=\"Backtracking Search\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Backtracking Search</a>, it is essentially a depth-first enumeration of possible models. Early termination occurs if the algorithm detects that the sentence must be true or false, even with a partially completed model. For example, a clause is true if any literal is true.\nPure Symbol Heuristic: A pure symbol is a symbol that always appears with the same sign in all clauses. If a sentence has a model, then it has a model with the pure symbols assigned so as to make their literals true, because doing so never makes a clause false.\nUnit Clause Heuristic: In the context of DPLL, a unit clause also means a clause in which all but one literal are already assigned false by the model. Unit propagation occurs when a unit's truth value leads to the simplification of other clauses by removing the occurrence of the literal. Hill-Climbing can be assigned to satisfiability (SAT) problems, provided a correct evaluation function is selected. Since the goal is to find an assignment that satisfies every clause, an evaluation function that counts the number of unsatisfied clauses works well. <br>\n<a data-href=\"WalkSAT Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">WalkSAT Algorithm</a>: A local search algorithm which, on every iteration, picks an unsatisfied clause and picks a symbol to flip. The symbol that is picked is the one that minimizes the number of unsatisfied clauses in the new state. A fluent variable is an aspect of the world that changes. An atemporal variable is static. Hybrid Agent maintains and updates a KB as well as a current plan. The initial KB contains the atemporal variables. At each time step , the new percept sequence is added, along with all the fluent axioms, such as the successor state axioms.\nThe agent then uses logical inference to to derive new knowledge and update its knowledge base (KB).\nThough, with this program, as increases, the computational expense to logically infer increases due to inferences having to go further back and involve more propositional symbols. <br>One solution is to save or cache the results of inference. This is a form of <a data-href=\"Dynamic Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Programming</a>. <br>\nThe percept history and all their ramifications can be replaced with the <a data-href=\"Belief State\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Belief State</a>, which is the set of all possible states of the world currently. The process of updating the belief state as new percepts arrive is called state estimation.\n<br>The set of belief states is the <a data-href=\"Powerset\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Powerset</a> of the set of physical states, hence the size of the belief state set is . Programming languages are the largest class of formal languages in common use. The main drawback of programming languages is that they lack a general mechanism for deriving facts from other facts. In a compositional language, the meaning of a sentence is a function of its parts. <br>\n<a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a>: Extends <a href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"10\" to=\"29\" origin-text=\"propositional logic\" class=\"internal-link virtual-link-a\">propositional logic</a> by introducing quantifiers and predicates, allowing for the representation of the relationships between objects. Predicates are symbols that represent properties or relations among objects. For example, might denote a certain property of , while could represent a relationship between objects and . <br>\nThe primary difference between propositional and <a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a> (<a href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"2\" to=\"5\" origin-text=\"FOL\" class=\"internal-link virtual-link-a\">FOL</a>) is their ontological commitments, that is, what they assume about the nature of reality. Propositional logic assumes that facts are either true or false in the world. First-order logic assumes that the world consists of objects with relations that are either true or false.\nIn fuzzy logic, the ontological commitment allows degrees of truth between 0 and 1.\n<br><a data-href=\"Temporal Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Temporal Logic</a> assumes that facts hold at particular times, and that those times are ordered.\nHigher-order logics view the relations and functions of first-order logic as objects themselves. A logic can also be characterized by its epistemological commitments, that is, the possible states of knowledge that it allows with respect to each fact. Both first-order and propositional logic sentences are either true, false, or unknown.\n<br>Systems using <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"14\" to=\"25\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> theory can have any degree of belief ranging from 0 to 1. The domain of a model in FOL is the set of objects it contains. The domain is required to be non-empty. Relation: The set of tuples of objects that are related. Function: maps a tuple to a single output. Models require total functions, functions that have an output for every input tuple. Constant symbols stand for objects (e.g. ), predicate symbols stand for relations (i.e. or ), and function symbols stand for functions (e.g. ). Each predicate and function symbol has an arity, fixing the number of arguments it takes. Model checking cannot be used to determine entailment in FOL because the number of first-order models is unbounded. Term: A logical expression that refers to an object. Complex Term: Formed by a function symbol followed by a parenthetical list of arguments. Atomic Sentence: Formed from a predicate symbol optionally followed by a parenthetical list of terms (i.e. ). Atomic sentences can have complex terms as arguments. Complex Sentences: One or more atomic sentences combined using logical connectives or quantifiers. Quantifiers: Allows for statements about some or all objects in a domain. Universal Quantifier (): Asserts that a certain statement is true for all objects. For example, means \"for all , is true\". Implication is the natural connective for . Existential Quantifier (): Asserts that there is at least one object for which the statement is true. For example, means \"there exists an , such that is true\". Conjunction (AND) is the natural connective for . Uniqueness Quantifier (): Asserts that exactly one objects makes the statement true. For example, means \"there is exactly one , such that is true.\"\nConsecutive quantifiers of the same type can be written as one quantifier with multiple variables: If two quantifiers use the same variable name, the variable belongs to the innermost quantifier that mentions it.\n<br> is a conjunction and is a disjunction over the universe of objects, therefore, they obey <a data-href=\"De Morgan's Laws\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">De Morgan's Laws</a>: We can use the equality symbol to say that two terms refer to the same object. For example, . <br>\n<a data-href=\"Database Semantics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Database Semantics</a>: Consists of the closed-world, unique names, and domain-closure assumptions. Unique Names Assumption: Assumes that every constant symbol refers to a distinct object.\nClosed-World Assumption: Assumes that atomics sentences not known to be true are false.\nDomain Closure: Assumes that each model contains no more domain elements than those named by the constant symbols. Domain: Some part of the universe about which we wish to express definite knowledge of what the world contains. Assertions: Sentences that are added to a knowledge base. Questions: Queries or goals which receive information from a knowledge base. Axioms: Provide the basic factual knowledge from which conclusions can be derived. Theorems: Logical sentences that are entailed by axioms. Theorems add no new information, though they are essential for reducing the computational cost of inference. <br>\n<a data-href=\"Knowledge Engineering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Knowledge Engineering</a>: The general process of constructing a knowledge base (KB). The knowledge engineering process is as follows: Identify the questions that the KB will support ant the kinds of facts that will be available.\nAssemble the relevant knowledge.\n<br>Decide on a vocabulary of predicates, functions, and constants. Translate domain-level concepts into logic-level names. The result is a vocabulary, known as the <a data-href=\"Ontology\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ontology</a> of the domain.\nEncode general knowledge about the domain. Write the axioms for all vocabulary terms.\nEncode a description of the problem instance. Write simple atomic sentences about concepts that are already a part of the ontology.\nPose queries to the inference procedure.\nDebug and evaluate the knowledge base. <br>\n<a data-href=\"First-Order Inference\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Inference</a>: The process of deriving new conclusions from existing statements in <a href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"70\" to=\"87\" origin-text=\"first-order logic\" class=\"internal-link virtual-link-a\">first-order logic</a>. <br>One way to do first order inference is to convert a first-order KB into propositional logic and use <a data-href=\"Propositional Inference\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositional Inference</a>. This is called <a data-href=\"Propositionalization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositionalization</a>. The first step is to eliminate universal quantifiers using the rule of universal instantiation, which says that we can infer any sentence obtained by substituting a ground term for a universally quantified variable.\n<br>Existential instantiation replaces an existentially quantified variable with a single new constant symbol. A <a data-href=\"Skolem Constant\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Skolem Constant</a> is used to eliminate existential quantifiers. For example, in the formula , the existentially quantified variable can be replaced by a Skolem constant , as long as does not exist elsewhere in the KB. This process is called <a data-href=\"Skolemization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Skolemization</a>.\nNext, replace ground atomic sentences, such as , with propositional symbols, such as .\nThen, apply any of the complete propositional inference algorithms to obtain conclusions.\nOne problem is that if the KB contains a function symbol, the set of possible ground-term substitutions is infinite. This can be addressed by generating all instantiations with constant symbols, then all terms at depth 1, and so on until a proof of the entailed sentence can be constructed. <br>\n<a data-href=\"Generalized Modus Ponens\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Generalized Modus Ponens</a>: A lifted version of Modus Ponens, meaning it raises traditional Modus Ponens from variable-free <a href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"88\" to=\"107\" origin-text=\"propositional logic\" class=\"internal-link virtual-link-a\">propositional logic</a> to FOL. Generalized Modus Ponens allows for the involvement of predicates and variables. For example: Substitution: A mapping of variables to terms. To apply a substitution, you replace all occurrences of a variable with the mapping defined by that substitution. Substitutions are denoted as , meaning substitute for the variable . <br>\n<a data-href=\"Unification\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Unification</a>: The process of finding substitutions which make different logical expressions look identical. This process is a key part of all first-order inference algorithms. For example, to unify the two sentences and , you can simply substitute for , . The substitution is known as the unifier.\nIf you try to unify the sentences , meaning \"John knows everyone\", and , meaning \"Everyone knows Elizabeth\", you will not be able to. This is because cannot be equal to and at the same time. This can be avoided by standardizing apart the variables. Standardizing apart a sentence involves renaming its variables to avoid name clashes. For example, you can rename the variable in to . Now the two sentences can be unified with the unifier . If there are multiple possible unifiers, it is best to choose the most general unifier. The most general unifier (MGU) is the unifier which places the fewest restrictions on variables. For example, on the sentence , the unifier is more general than . stores a sentence in the first-order KB, and returns all unifiers such that the query unifies with some sentence in the KB. can be made more efficient by not attempting to unify sentences that clearly have no chance of unifying. This can be done by implementing indexing. Predicate indexing buckets facts by their predicate and stores them in a hash table. For example, the facts may be stored in one bucket, and the facts in another.\n<br>Given a sentence to be stored, it's possible to construct indices for all possible queries that unify with it. These queries form a <a data-href=\"Subsumption Lattice\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Subsumption Lattice</a>, where the child of any node is obtained from its parent by a single substitution, and the highest common descendant of any two nodes is the result of applying the most general unifier. <br>\nThe forward-chaining algorithm discussed earlier works for KBs of propositional definite clauses. Though, not all first-order sentences can be expressed as a <a data-href=\"Definite Clause\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Definite Clause</a>—a clause with exactly one positive literal. Existential quantifiers aren't allowed, and universal quantifiers are left implicit. An example of a first-order definite clause is: Since the universal quantifier is implicit, the sentence means that all which is greedy and a king, is evil. A first-order forward-chaining algorithm starts from the known facts, and triggers all the rules whose premises are satisfied, adding their conclusions to the knowledge base. This is repeated until the query is answered, or no new facts can be derived. A fact is not new if it is just a renaming of an existing fact. A sentence is a renaming of another if they're identical except for the names of their variables.\nIf no new inferences are possible on a KB, then the KB is called a fixed point of the inference process. Forward-chaining can be made more efficient by considering the conjunct ordering problem—finding an ordering of the conjuncts in the premise so that the total cost of inference is minimized. <br>The minimum-remaining-values (MRV) heuristic would suggest an ordering where the next variable to be assigned a value is the variable with the least amount of valid values available. This is an example of <a data-href=\"Pattern Matching\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pattern Matching</a>, and is very similar to the previously discussed constraint satisfaction problems. We can view each conjunct as a constraint on the variables that it contains.\n<br><a data-href=\"Rete Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Rete Algorithm</a>: A pattern matching algorithm which preprocesses the set of rules in the KB to construct a <a data-href=\"Rete Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Rete Network</a>—A graph data structure where each node is a literal from a rule premise. Variable bindings flow through the network and are filtered out when they fail to match a literal. If two literals in a rule share a variable, then the bindings from each literal are filtered through an equality node.\nRete networks are a key component to production systems and in cognitive architecture. Backward chaining over definite clauses works backwards from the goal, chaining through rules to find known facts that support the proof. Logic Programming: Programming paradigms based on formal logic systems. In logic programming, program statements express facts and rules about some problem domain, and computation is performed via logical inference. <br><a data-href=\"Prolog\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Prolog</a> and <a data-href=\"Datalog\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Datalog</a> are two common logic programming languages. <br>\n<a data-href=\"Resolution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Resolution</a>: Here, we extend resolution to FOL. The first step to perform resolution is to convert the sentences in the KB into <a data-href=\"Conjunctive Normal Form\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Conjunctive Normal Form</a> (CNF). That is, a conjunction (AND) of clauses, where a clause is a disjunction (OR) of literals. In CNF, literals can contain variables, which are considered to be universally quantified. Every FOL sentence can be converted into an equivalent CNF sentence. To convert a sentence to CNF, you may have standardize variable names, that is, for sentences that use the same variable name twice, you must change one of them.\n<br>You also may have to Skolemize a sentence. That is, eliminating existentially quantified variables with a <a data-href=\"Skolem Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Skolem Function</a>. These are functions which take as arguments all the universally quantified variables in scope of the existential quantifier. For example: Where is a Skolem function. The resolution rule for first-order clauses is a lifted version of the propositional rule discussed earlier. Two clauses, which are assumed to be standardized apart, can be resolved if they contain complementary literals. This is called the binary resolution rule, because it resolves two literals, and it isn't a complete inference procedure by itself. The full resolution rule resolves subsets of literals in each unifiable clause.\nAnother approach is first-order factoring, which reduces two literals to one if they are unifiable. The unifier must be applied to the entire clause. This combined with binary resolution is complete. Resolution is refutation-complete, meaning, that if a set of sentences is unsatisfiable, then resolution will always be able to derive a contradiction. Ground Resolution Theorem: States that propositional resolution is complete for ground sentences. <br>\n<a data-href=\"Herbrand Universe\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Herbrand Universe</a>: If is a set of clauses, then the Herbrand universe of , denoted , is the set of all ground terms constructible from the function symbols in , and the constant symbols in ; if none, then a default constant symbol, . Saturation: If is a set of clauses and is a set of ground terms, then , the saturation of with respect to , is the set of all ground clauses obtained by applying all possible consistent substitutions of ground terms in for variables in .\nHerbrand Base: The saturation of a set of clauses with respect to it's Herbrand universe is called the Herbrand base of , denoted <br><a data-href=\"Herbrand's Theorem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Herbrand's Theorem</a>: If a set of clauses is unsatisfiable, then there exists a finite subset of that is also unsatisfiable. <br>\n<a data-href=\"Equational Unification\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Equational Unification</a>: The process of finding a substitution for variables in a set of equations that makes the equations become identical. Strategies for finding proofs by resolution efficiently include: <br>Unit Preference: Preferring resolutions where one of the sentences is a single literal, called a unit clause. This is complete for <a data-tooltip-position=\"top\" aria-label=\"Horn Clause\" data-href=\"Horn Clause\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Horn Clauses</a>.\nSet of Support: Insisting that every resolution step involves at least one element from the set of clauses called the set of support.\nInput Resolution: Every resolution combines one of the input sentences with some other sentence.\nSubsumption: Eliminates all sentences that are subsumed (more specific than) an existing sentence in the KB.\n<br>Learning: Training a <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a> model to learn from experience. <br>\nOntological Engineering: The process of developing, analyzing, and managing <a data-tooltip-position=\"top\" aria-label=\"Ontology\" data-href=\"Ontology\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">ontologies</a>. <br>Ontology: A framework which defines concepts, classes, and relationships within a specific domain. Classes and objects can be thought of in the same way of <a data-href=\"Object-Oriented Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Object-Oriented Programming</a>, where a class is a type of entity that is described by properties, an object is an instantiation of a class, and classes can have relationships via mechanisms like inheritance. Subcategories inherit properties from their superclass. Subclass relations organize categories into taxonomic hierarchies.\nTaxonomy: A hierarchical classification of entities into categories.\nInteraction with the world takes place with objects, while most reasoning happens at the level of categories. Categories also serve to make predictions about objects. The general framework of concepts is called an upper ontology.\nGeneral-Purpose Ontology: An ontology that should be applicable in any special-purpose domain, with the addition of domain-specific knowledge.\nSpecial-Purpose Ontology: An ontology engineered for a particular domain. <br>\nWe will use <a href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"12\" to=\"29\" origin-text=\"first-order logic\" class=\"internal-link virtual-link-a\">first-order logic</a> (FOL) to represent knowledge in this chapter, although FOL has some representational limitations. The main difficulty being that in the real-world, most generalizations have exceptions or only hold to a degree. We can represent categories in FOL as predicates or objects. For example, can say that object belongs to the class.\nWe can also define an object called , and use to say the same thing.\nWe can define properties of a class by saying . Exhaustive Decomposition: The process of breaking sets into subsets, such that all elements belong to a subset. If an exhaustive decomposition is made up of disjoint sets, it is called a partition. Categories are disjoint if they have no members in common. We'll use the relation to say that one thing is a part of another. This allows us to group objects into hierarchies. <br>The relation is <a data-tooltip-position=\"top\" aria-label=\"Transitive Property\" data-href=\"Transitive Property\" href=\"https://emujakic.github.io/TechKB/notes/math/transitive-property.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">transitive</a> and <a data-tooltip-position=\"top\" aria-label=\"Reflective Property\" data-href=\"Reflective Property\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">reflective</a>. The world can be seen as composed of primitive objects, of which, composite objects are made of. Categories of composite objects are often characterized by structural relations among parts.\nA bunch is a collection of objects that are grouped together based on certain criteria and can be considered as a composite object. Logical Minimization: Defining an object in its most efficient form, while preserving its original definition. Measures are the values assigned to properties like height or mass. Quantitative measures are represented by numerical values, and thus, are easy to represent.\n<br><a data-tooltip-position=\"top\" aria-label=\"Ordinal Data\" data-href=\"Ordinal Data\" href=\"https://emujakic.github.io/TechKB/notes/math/ordinal-data.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ordinal</a> measures are measures that have a meaningful order among values, though may not have a consistent magnitude between values. For example, the <a href=\"https://emujakic.github.io/TechKB/notes/math/ordinal-data.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"133\" to=\"140\" origin-text=\"ordinal\" class=\"internal-link virtual-link-a\">ordinal</a> measure may have values . These values have a clear order among them, though the difference between and may not be the same as the difference between and . <br>These sorts of <a data-tooltip-position=\"top\" aria-label=\"Monotonicity\" data-href=\"Monotonicity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">monotonic</a> relationships among measures form the basis of a subfield of AI known as qualitative physics. Some categories have strict definitions, like that of a square or a circle. Most categories in the real-world are natural kind categories, which have no clear-cut definition. This presents a challenge for logical agents, as they must identify atypical objects as still belonging to the same category. For instance, an agent should categorize a three-wheeled car as a car, even though most cars have four wheels. Intrinsic properties belong to the substance of the object itself and is independent of external conditions or quantity. For example, the boiling point of an object is intrinsic. Extrinsic properties are properties which depend on external factors or quantity. For example, weight or volume is an extrinsic property, since it changes with quantity. Count nouns are nouns whose quantities are described by a discrete number of individual entities. For example, books are a count noun. Categories described only by intrinsic properties are count nouns. Mass nouns are objects whose quantity is described by continuous measures. For example, water is a mass noun typically quantified using measures like fluid mass. Categories described by any extrinsic properties is a mass noun. Event: Actions or occurrences that can change the state of the world. Fluents are properties or conditions that are subject to change as a result of events. <br>\n<a data-href=\"Temporal Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Temporal Logic</a>: A formalism used to reason about propositions and how they change over time. Temporal representation uses time points to describe when events happen and how they relate to each other. We assume a first time point , which describe the initial state and what fluents are true at start time. Event calculus is a mathematical formalism used to reason about events and their effects. The set of predicates of event calculus are: : Fluent is true at all time between and .\n: Event starts at time and ends at time .\n: Event causes fluent to become true at time .\n: Event causes fluent to become false at time .\n: Fluent becomes true at some time between and .\n: Time comes before time . We'll consider two types of time intervals: Moments, which have zero duration; and extended intervals, which have a duration greater than zero.\nTo establish a time scale, we first select an arbitrary moment as time 0, from which we can associate subsequent points to create absolute time points. A widely used time point is epoch time, also known as Unix time, which began on January 1, 1970, at zero seconds. This system is commonly utilized in digital environments for timekeeping and time-stamping. Physical objects can be described as generalized events, in the sense that objects are pieces of space-time. We can describe the properties of objects using state fluents, such as . Propositional Attitudes: Mental states that involve a relation between an agent and a proposition. Some examples include , or . These attitudes do not behave like normal predicates. Unlike normal predicates, which are referentially transparent, propositional attitudes are referentially opaque. Referential Transparency: An object if referentially transparent if the term used to refer to it does not matter. For example, if two terms, and both refer to the same object, referring to one term is the same as referring to the other.\nReferential Opacity: An object is referentially opaque if the term used to refer to it does matter. For example, referring to is different from referring to because the agent may not know that these terms are co-referential. <br><a data-href=\"Modal Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Modal Logic</a> is designed to address this issue. Regular logic is centered around the modality of truth, while modal logic includes special modal operators that take sentences (rather than arguments) as terms. For example, ' knows ' is represented as where is the modal operator for knowledge. Otherwise, the syntax is the same as first-order logic, though the semantics are more complicated.\nIn modal logic, we need a model which consists of the collection of possible worlds rather than just the one true world. The worlds are connected via accessibility relations, one relation for each modal operator. A world is accessible from with respect to the modal operator if everything in is consistent with what knows in .\nFor example, Austin is the capital of Texas, but for an agent who doesn't know that, the possible world where Houston is the capital is accessible. A knowledge atom is true in world if is true in every world accessible from . The truth of complex sentences in derived with recursive application of this rule, along with the standard rules of FOL. Description Logics: A class of formal languages used to reason about the knowledge of a domain through structured concepts, roles, and instances. The main inference tasks for description logics are: Subsumption: Checking if a category is a subset of another.\nClassification: Checking whether an object belongs to a particular category. Semantic Networks: A graph structure where nodes are objects or events, and edges are relationships between nodes. This notation makes it easy to perform inheritance reasoning. For example, a directed edge from the node to the node represents a hierarchical relationship saying that the cat is a pet.\nNegation, disjunction, conjunction, nested functions, and existential quantification are all missing from this semantic network. Procedural attachment can be used to increase the expressive power of semantic networks. Procedural Attachment: A technique where a query about, or an assertion of a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm. Semantic networks allow for default values for categories via an inheritance algorithm, these defaults can be overridden by a more specific value. <br>\n<a data-href=\"Monotonicity\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Monotonicity</a>: A property of logical systems which says that the addition of new information cannot invalidate previously established truths. Circumscription: A method in non-monotonic logics in which certain predicates are assumed to be false, unless they are explicitly mentioned to be true. For example, in the formula , can be circumscribed, and is assumed unless stated otherwise.\nCircumscription is a form of model-preference logic, where models with the least abnormal objects are preferred. Default Logic is a non-monotonic formalism which allows for default rules to be defined. For example, the formula means that if is true, and if is consistent with the KB, then is concluded by default.\nThe extension of a default theory consists of the original known facts, as well as all default conclusions that can be drawn from the default rules in the KB. Belief revision is the process of retracting inferences in the face of new information. If a KB contains a sentence , and we want to perform , we'd have to first perform in order to prevent a contradiction. Additionally, if other sentences are necessarily derived from , then those sentences will have to be retracted as well. Truth maintenance systems (TMSs) were designed to handle belief revision. Justification-based TMS annotates each sentence in the KB with the set of sentences which justify it, that is, the set of sentences from which the sentence was inferred. JTSMs typically assume that retracted sentences may be reconsidered, and therefore saves the sentence and it's derivations. An assumption-based TMS keeps track, for each sentence that has ever been considered, which assumptions would cause the sentence to be true. Classical Planning: The task of finding a sequence of actions which constitute a solution in a discrete, static, deterministic, fully-observable environment. <br>\n<a data-href=\"Planning Domain Definition Language\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Planning Domain Definition Language</a> (PDDL): A family of languages in a factored representation that provide a standardized way to express all actions with a single action schema, and does not need domain-specific knowledge. In PDDL, states are represented as conjunctions (AND) of ground atomic fluents. Ground meaning no variables.\n<br>PDDL uses <a data-href=\"Database Semantics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Database Semantics</a>, that is, it assumes both the closed-world assumption and the unique names assumption.\nThere are no universal or existential quantifiers in PDDL. Action Schema: A representation of an action as a family of ground actions. A schema consists of the action name, a list of all variables used in the schema, a precondition, and an effect. For example: A ground action is applicable in state if entails the precondition of . The result of action in state is state which is the set of fluents formed by starting with , removing the negated fluents in the effect of action , and adding the positive fluents. A planning domain is a set of action schemas, and a problem within a domain is defined with the addition of an initial state and a goal. The states in the search state space are ground states, and the applicable actions in a state are the grounded instantiations of the action schema. The applicable actions are determined by unifying the current state against the preconditions of each action schema. If the unification returns a possible substitution, then that substitution is applied to create a ground action. There may be multiple possible substitutions.\nA strong heuristic is needed to improve the worst case time complexity of , where is the number of actions per state, and is the number of steps in the solution. In backward search, at each step we consider an action which unifies with one of the goal literals, but with no effect which negates a goal literal. For most problem domains, backward search keeps the branching factor lower than forward search, though it is harder to come up with good heuristics. <br>\nSAT Based Planners: Translate a PDDL problem description into <a data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositional Logic</a> by propositionalizing the goals and actions, adding simultaneous exclusion axioms, adding precondition axioms, defining the initial state, and adding successor state axioms. Partial-order planning is a planning approach as a graph rather than a linear sequence. In the graph, each node is an action, and directed edges represent that the predecessor action establishes the precondition of the successor action. Planning using a factored-representation (representing states as a set of variables with values) makes it possible to define domain-independent heuristics. Admissible heuristics can be derived by relaxing the original problem, and using the cost of a solution for the relaxed problem from a given state as the heuristic value. Problems can be relaxed by either adding more edges, or abstracting nodes together.\nThe 'Ignore-Preconditions' heuristic, for example, drops all preconditions from actions, thus, adding more edges.\nThe 'Ignore-Delete Lists' heuristic removes all negative literals from action schema effects, thus, allowing monotonic progress towards the goal.\nState abstractions are a one-to-many mapping of ground states to abstract states. The simplest way to abstract states is to ignore some fluents. Forward pruning prunes promising actions, with the risk of potentially pruning the optimal solution. A preferred action may be defined by defining a relaxed problem, and solving it to get the relaxed plan. Then, a preferred action can be a step of the relaxed plan, or an action which achieves a precondition of the relaxed plan. A problem has serializable subgoals if there exists an order of subgoals that a planner can solve in that order without having to undo any of the previous subgoals. This is not necessarily an optimal plan. The subgoal independence assumption assumes that the cost of solving a conjunction (AND) of subgoals is the sum of the cost of solving each subgoal independently. Hierarchical Decomposition: The process of decomposing a complex problem into smaller components organized in a hierarchy. In a hierarchical task network, there is a set of actions called primitive actions, with a standard precondition effect schema. Higher level actions (HLA) have one or more possible refinements, into a sequence of actions, each of which may be a primitive action or another HLA.\nIf an HLA refinement contains only primitives, it is called an implementation of the HLA. The reachable states of an HLA in state , is the set of all states reachable from for any of the HLAs implementations.\nThe reachable set of a sequence of HLAs is the union of all reachable states obtained by applying in each reachable state of , where is the th HLA in the sequence.\nGiven these two definitions, a high-level plan achieves the goal if its reachable set intersects the set of goal states. An implementation of a high-level plan is the concatenation of implementations of each HLA in the plan. Writing precondition-effect schemas for the HLAs themselves make it easier to prove that a high-level plan achieves the goal.\nThe downward refinement property says that every high-level plan that claims to achieve the goal must have an implementation that does so. Angelic semantics is a type of nondeterminism where the behavior of a system varies based on optimistic choices made by an agent or the environment. In many cases we can only approximate the effect of an HLA due to it having infinite implementations. An optimistic description approximation may overstate the reachable set, while a pessimistic description may understate the reachable set. To solve a partially-observable problem, an agent will have to reason about its percepts. The percepts will be supplied from the sensors when acting, but during planning it will need a model of its sensors. For planning, we augment PDDL with the percept schema, for example: In a fully-observable environment, we would have a percept schema with no preconditions for each fluent in the environment. In sensorless and partially-observable problems, we have to switch to an open-world assumption, where if a fluent doesn't appear, then its value is unknown. Given a belief state , the agent can consider any action whose preconditions are satisfied by . Then, the general formula for updating given an applicable action in a deterministic environment is: Where is the physical transition model. This means that is simply the set of states , where each is the action applied to all states in the belief state . To construct , we must consider what happens to each literal in each physical state in when action is applied. For literals whose truth value is known in , the value in is computed by the add/delete list of action . If the literal's value is unknown, there are three options: If the action adds , then the fluent will be true in .\nIf the action removes , then it will be false in .\nIf the action doesn't change , then it'll remain unknown. The family of belief states is defined as a conjunction (AND) of literals is closed under updates defined by PDDL action schemas. If the belief state starts as a conjunction of literals, then any update will also yield a conjunction of literals. This is only true for action schemas with the same effect for all states that satisfy their precondition. Alternatively, a conditional effect can have different outcomes based on the state in which the action is applied. The syntax for a conditional effect is . When applied to a belief state , a conditional effect makes it so that is no longer in 1-CNF form, thus, introducing dependencies among fluents and increasing the complexity. Contingent planning is the generation of plans with conditional planning based on received percepts. Variables in these plans are typically assumed to be existentially quantified. Calculating the new belief state after an action and subsequent percept is done in 2 stages: The first step calculates the belief state after the action: Suppose that percept literals are received. If a percept has exactly one percept schema, , where is a conjunction (AND) of literals, then those literals can be put into the belief state alongside . If has multiple percept schemas, then we add the disjunction (OR) of the preconditions of each schema. This takes the belief state out of 1-CNF. Online planning involves interleaving action and planning. Replanning requires some form of execution monitoring to determine the need for a new plan. Replanning may be needed if the agent's model of the world is incorrect. The model for an action may have an inaccurate precondition or effect.\nThe model may lack provision for exogenous events, that is, events that originate from outside the system. Online agents have a choice of at least 3 different approaches to execution monitoring: Action Monitoring: Before performing an action, the agent verifies that all preconditions for that action still hold.\nPlan Monitoring: Before performing an action, the agent verifies that the current plan still leads to a goal.\nGoal Monitoring: Before performing an action, the agent checks to see if there is a better set of goals it could try to achieve. Scheduling refers to when and how long an action occurs. Resource constraints refer to when an agent has a limitation on the type or amount of resources required to perform a task. Job-Shop Scheduling Problem: A problem which consists of a set of jobs, each of which require a sequence of actions with ordering constraints among them. Each action has a duration and a set of resource constraints required by the action. A constraint specifies the type of resource, the quantity required, and whether it's reusable.\nActions can also produce resources.\nA solution to a job-shop scheduling problem specifies start times for each action, and must satisfy all the temporal ordering and resource constraints.\nThe quality of a solution can be quantified using the makespan cost function, which is the total duration of the plan.\nAggregation groups identical objects together and is essential for reducing complexity. For example, a resource can be represented as instead of . To minimize makespan, we must find the earliest start time for all actions consistent with the ordering constraints. The ordering constraints can be represented as a directed graph. <br>The <a data-href=\"Critical Path Method\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Critical Path Method</a> (CPM) can be applied to this graph to determine the possible start times to the actions. A path through a graph representing a partial-order plan is a linearly ordered sequence of actions. The critical path is the path whose total duration is longest.\nActions that are off the critical path have a window of time in which they can be executed. ES is the earliest start time, while LS is the latest start time. The quantity LS-ES is known as the slack of an action. If an action has 0 slack, it is a critical task.\nTogether, the LS and ES times for all actions constitutes a solution for the problem. The minimum slack heuristic, on each iteration, schedules for the earliest possible start time, the unscheduled action which has all its predecessors scheduled and has the least slack. Uncertainty in an environment may be due to partial-observability or non-determinism. <br>\n<a data-href=\"Belief State\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Belief State</a>: The set of all states that the agent could possibly be in currently. Trying to use pure logic in sufficiently complex domains tends to fail due to either: Laziness: It is too much work to list the complete set of antecedents and consequents needed to form an exception-less rule.\nTheoretical Ignorance: There is no complete theory for the domain.\nPractical Ignorance: It is impractical to gather all the necessary information. <br>\nThis means that the agent's knowledge can, at best, a degree of belief in the relevant sentences. Degrees of belief are a value between 0 (impossibility) and 1 (certainty). Our main tool for dealing with degrees of belief is <a data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability</a> theory. The ontological commitments of probability theory and logic are identical: the world is made up of propositions, that is, sentences that are either true or false.\nThe epistemological commitments differ significantly. A logical agent believes a fact to be either true, false, or it holds no opinion. A probabilistic agent, on the other hand, assigns a numerical degree of belief to a fact. An outcome is a completely specified state, where all variables are assigned a value. An agent must have preferences among the different possible outcomes. <br><a data-href=\"Utility Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Utility Theory</a> is used to represent and reason with preferences quantitively. <br>\nPreferences, as expressed by utilities, combined with <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"54\" to=\"67\" origin-text=\"probabilities\" class=\"internal-link virtual-link-a\">probabilities</a> form the general theory for rational decision-making called <a data-href=\"Decision Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Theory</a>. The fundamental idea of decision theory is that an agent is rational if it chooses the action which yields the highest expected utility. This is called the principle of maximum expected utility.\nA decision-theoretic agent's belief state represents the probabilities of world states alongside the possibilities. A possible world is a complete assignment of values to variables. The set of all possible worlds, , is called the sample space. The possible worlds, , are mutually-exclusive, meaning only one world can be true at a time; and exhaustive, meaning there is always a world that is true at any time. <br>A complete probability model specifies a probability for each possible world, denoted . The total probability for a sample space is 1. This is<a data-tooltip-position=\"top\" aria-label=\"Kolmogorov's Axioms\" data-href=\"Kolmogorov's Axioms\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Kolmogorov's normalization axiom</a>. Events are subsets of the sample space. In logic, a set of worlds corresponds to a proposition.\nVariables in probability theory are called random variables and their names begin with uppercase letters, while the values of variables begin with lowercase letters.\nA probability distribution is a mathematical function which describes the likelihood of different outcomes for the domain of a random variable. The probability of each outcome is between 0 and 1 (inclusive), and the sum of probabilities of each outcome must sum to 1. <br>Discrete probability distributions describe the probability of each possible value in the domain of a discrete random variable and are described by a <a data-href=\"Probability Mass Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Mass Function</a>.\n<br>Continuous probability distributions describe the probability of a continuous random variable. These distributions are characterized by a <a data-href=\"Probability Density Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability Density Function</a> (PDF). The probability of a proposition is defined as the sum of the probabilities of the worlds in which it holds: Unconditional probabilities, also called priors, refer to the degree of belief in a proposition, in the absence of any other information. Though, most of the time, we have some other information called evidence, which allows us to calculate conditional probability. Conditional, or posterior probabilities quantify the likelihood of one event occurring, given that another has already occurred. This is denoted as , read as 'the probability of given ' and is defined as: The product rule states that . Joint probability refers to the likelihood of two or more events occurring simultaneously. The joint probability denotes the likelihood of all combinations of the values of the variables. This results in a table of probabilities called the joint probability distribution.\n- A probability model is completely determined by the joint probability for all the random variables, this is called the full joint probability distribution. Probabilistic inference the computation of posterior probabilities for query propositions given evidence. We use the full joint distribution as the knowledge base for a probabilistic agent. Marginal probability is the likelihood of an outcome occurring irrespective of the outcome of other events. It is defined as the sum of joint probabilities of the event with all possible outcomes of other events. It is defined as: ; this process is called marginalization.\nUsing the product rule, we can replace with , obtaining a rule called conditioning. <br>\nThe denominator of a conditional probability can be viewed as a <a data-href=\"Normalization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Normalization</a> constant for the distribution , ensuring that it sums to 1. We can use to denote such constants. Therefore: This means we can calculate without knowing the prior probability . A general probabilistic inference procedure can be defined as follows: We begin with the case where the query involves a single variable . Let denote the set of evidence variables who have values . Let denote the remaining unobserved variables. The query can be evaluated as: Where the summation is over all the possible combinations of values for the unobserved variables .\nGiven the full-joint distribution, this equation can answer probabilistic queries for discrete variables, though it scales poorly. For a domain described by boolean variables, it requires an input table of size and takes time to process. For this reason, the full-joint distribution in tabular form is rarely used in practice for building reasoning systems. Two events are said to be independent if the occurrence of one does not affect the probability of the occurrence of the other. Mathematically: Independence assertions are typically based on knowledge of the domain. If the complete set of variables can be divided into independent subsets, the full-joint distribution can be factored into separate joint distributions on those subsets. <br>\n<a data-href=\"Bayes' Theorem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bayes' Theorem</a> states that: One can avoid calculating the prior probability of the evidence by instead computing a posterior (conditional) probability for each value of the query variable () and then normalizing the results. Bayes' theorem is useful for answering queries with one evidence variable, though it is no better than the full-joint distribution for variables. Conditional Independence: Describes a situation where two random variables are independent of each other with respect to a third variable: separates and because it is a direct cause of both of them.\nFor variables that are all conditionally independent given , the size of the representation grows as opposed to . The full-joint distribution of the pattern where a single cause directly influences a number of effects, all of which are conditionally independent given the cause is defined as: <br>This distribution is called the <a data-href=\"Naive Bayes Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Naive Bayes Model</a>. It is naive because it assumes that features are independent of each other.\nTo obtain the probability of the cause given some observed effects , with denoting the unobserved variables, the standard inference method from the joint distribution can be used: This means that for each possible cause, multiply the prior probability of the cause by the product of the conditional probabilities of the observed effects given the cause, then normalize the result.\nThe runtime of this calculation is linear in the number of observed effects and does not depend on the number of unobserved effects. <br>\n<a data-href=\"Bayesian Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bayesian Network</a>: A <a data-tooltip-position=\"top\" aria-label=\"Directed Acyclic Graph\" data-href=\"Directed Acyclic Graph\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">directed, acyclic graphical model</a> which represents variables and their conditional dependencies. Nodes denote variables, and directed edges represent probabilistic dependencies. Bayesian networks can represent any full joint <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"192\" to=\"203\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distribution, and can often do so very concisely. If there is an edge from to , then has a direct influence on and is said to be a parent of . This suggests that causes should be the parents of effects. Often, domain experts decide the topology of the graph. The conditional independence of two variables is indicated by the absence of a link between them.\nEach node has associated probability information which quantifies the effect of the parents on the node using a finite number of parameters. A node is a hidden variable if it is neither an input nor output node.\nOnce the topology of the graph is laid out, we only need to specify the local probability information for each variable, in the form of a conditional distribution given its parents. The local probability information for a node takes the form of a conditional probability table (if the variable is discrete). Conditional Probability Table (CPT): A table where each row gives the conditional probability for each possible value of a node for a conditioning case. Each row must sum to 1. A conditioning case is a possible combination of values for the parent nodes.\nA Boolean variable with parents has rows in its CPT. For Boolean variables, if we know the probability of true is , then the probability of false must be , therefore, we often omit the 2nd number in the CPT.\nA node with no parents has 1 row which represents the prior probabilities of the node. Assume a Bayes net containing variables, . A general entry in the joint distribution is . The semantics of a Bayesian network defines each entry in the joint distribution as: Therefore, each entry in the joint distribution is the product of the appropriate elements of the local conditional distributions in the Bayes net. If a Bayes net is a representation of the full joint distribution, then it can also be used to answer any query, by summing all the relevant joint probability values, each calculated as the product of probabilities from the local conditional distributions. We can prove that the parameters are exactly the conditional probabilities . The conditional probabilities can be computed from the joint distribution as: Where represents the values of all variables other than and its parents. This allows us to rewrite the previous equation as: This equation implies certain conditional independence relationships which will be used later to guide the construction of the network topology. To construct a Bayes net, we first rewrite the entries in the joint distribution in terms of conditional probability using the product rule: Then we repeat this process, reducing each joint probability to a conditional probability and a joint probability on a smaller set of variables. We then end up with one big product called the chain rule: Therefore, according to the previous equation, for every variable in the network: <br>\nProvided that . This condition is satisfied by the numbering of nodes in <a data-href=\"Topological Order\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Topological Order</a>, that is, any order consistent with the directed graph structure. This equation says that the Bayesian network is a correct representation of the domain only if each node is conditionally independent of its other predecessors in the node ordering, given its parents. We satisfy this condition with this methodology: Nodes: Determine the set of variables required to model the domain. Then, order them such that causes precede effects.\nLinks: For each node: Choose a minimal set of parents for from , such that equation 13.3 is satisfied. These should be all the nodes that directly influence .\nFor each parent, insert a link from the parent to .\nWrite the conditional probability table, . Because each node is connected only to earlier nodes, the graph is necessarily acyclic. Bayes nets also contain no redundant probabilities, since the only parent nodes are the ones which have a direct influence on the child. This makes it impossible to create a Bayesian network that violates the axioms of probability. Because Bayesian networks are sparse systems, they are much more compact than the full joint distribution. In a sparse (locally structured) system, each sub-component interacts directly with only a bounded number of other components. This is usually associated with linear complexity. Even in a locally structured domain, the Bayesian network will only be compact if the nodes are well-ordered. If we stick to a causal model, that is, models where we focus on casual rules instead of diagnostic rules, the resulting Bayes net is often more compact. Specifying the conditional probability tables for a fully connected network, where each variable has all its predecessors as parents, is just as complex as specifying the full joint distribution. For this reason, we often omit links even if a slight dependency does exist. The non-descendants property states that each variable is conditionally independent of its non-descendants, given its parents. The non-descendants property, in conjunction with the interpretation of the network parameters as conditional probabilities suffices to reconstruct the full joint distribution defined in equation 13.2.\nTherefore, the semantics of the Bayes net can be viewed as defining a set of conditional independence properties, from which the full joint distribution can be derived from.\nAnother independence property implied by the non-descendants property is that: <br>A variable is conditionally independent of all other nodes in the network, given its <a data-href=\"Markov Blanket\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Blanket</a>. A node's Markov blanked is its parents, children, and children's parents. <br>\nA more general conditional independence question is whether a set of nodes is conditionally independent of another set , given a set . To determine whether <a data-tooltip-position=\"top\" aria-label=\"D-Separation\" data-href=\"D-Separation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">D-separates</a> and : Consider just the ancestral subgraph consisting of , and their ancestors.\nAdd links between any unlinked pair of nodes that share a child. This results in the so-called moral graph.\nReplace all directed links with undirected links.\nIf blocks all paths between and in the resulting graph, then d-separates and , therefore, is conditionally independent , given . Otherwise, the original Bayes net does not require conditional independence. Note that a node's Markov blanked d-separates it from all other variables. Relationships between parents and children are usually describable by a canonical distribution that fits some standard pattern. In such cases, the complete table can be specified just by naming the pattern and perhaps supplying a few parameters. Many Bayes net systems allow users to specify deterministic function using a general-purpose programming language. Context-Specific Independence (CSI): A conditional distribution exhibits CSI if a variable is conditionally independent of some of its parents given certain values of others. Bayes nets often implement CSI using if-then-else statements. <br>\n<a data-tooltip-position=\"top\" aria-label=\"Noise-based Logic\" data-href=\"Noise-based Logic\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Noisy logical relationships</a> allow for uncertainty or randomness when defining logical connections. The noisy-OR model allows for uncertainty about the ability of each parent to cause the child to be true. The model makes two assumptions: It assumes that the possible causes listed are exhaustive, if some are missing, a leak-node can be added that covers unmentioned causes.\nIt assumes that inhibition of each parent is independent of inhibition of any other parents. Given these assumptions, the child is false iff (if and only if) all of its true parents are inhibited. The probability of this is simply the product of the inhibition probabilities for each parent. <br>\nContinuous variables have an infinite number of values, so providing explicit probabilities for each value is impossible. Continuous variables can be handled by discretization, or using one of the standard families for probability density functions, such as a <a data-href=\"Gaussian Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gaussian Distribution</a>. <br><a data-href=\"Discretization\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Discretization</a>: The process of dividing up the possible values of a continuous variable into a fixed set of intervals. Hybrid Bayesian Network: A Bayesian network with both continuous and discrete variables. To specify a hybrid network we have to specify the conditional distribution for a discrete variable given continuous parents, and the conditional distribution for a continuous variable given discrete or continuous parents. <br>\nTo handle continuous children with continuous parents, we specify how the distribution over the child depends on the continuous value of the parent. In other words, we specify the parameters of the child distribution as a function of the parent. A common choice is a linear-Gaussian conditional distribution, where the child has a Gaussian distribution whose <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"77\" to=\"81\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> varies linearly with the value of the parent and whose <a href=\"https://emujakic.github.io/TechKB/notes/math/standard-deviation.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"56\" to=\"74\" origin-text=\"standard deviation\" class=\"internal-link virtual-link-a\">standard deviation</a> is fixed. The linear-Gaussian distribution takes the values of the child's other parents as parameters.\n<br>A network containing only continuous variables with linear-Gaussian distributions has a joint distribution that is a <a data-href=\"Multivariate Gaussian Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multivariate Gaussian Distribution</a> over all the variables. <br>\nTo handle the distribution of discrete children with continuous parents we can use parameterized models like the <a data-href=\"Probit Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probit Model</a>, <a data-href=\"Logistic Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Logistic Function</a>, or a <a data-href=\"Threshold Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Threshold Function</a>. These models can be generalized to handle multiple continuous parents by taking a linear combination of the parent values. One way to make a soft threshold function is to use the integral of the standard Gaussian distribution: The basic task for any probabilistic inference system is to compute the posterior distribution for a set of query variables, given some evidence variables. will denote the query variable, will denote the set of evidence variables, will denote the value of an evidence variable, and will denote the hidden variables. A typical query is of the form . In the general case, it is intractable to calculate the exact posterior probabilities of the query variables. Some exact methods include: Enumeration: Computes the probability by summing terms from the full joint distribution, . Since a Bayes net gives a complete representation of the full joint distribution, a query can be answered by computing the sums of products of conditional probabilities from the network. The time complexity of this method is for a network with Boolean variables. <br>\n<a data-href=\"Variable Elimination\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Variable Elimination</a>: Builds upon enumeration by using <a data-href=\"Dynamic Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Programming</a> to store the results of calculations for later use. Variable elimination evaluates expressions such as equation 13.5 in right-to-left order. Intermediate results are stored and summations over each variable are done only for the portions of the expression which include that variable. The time complexity of exact inference on Bayesian networks depends strongly on the topology of the network. Networks where there is at most 1 undirected path between any two nodes are called singly connected or polytrees. Exact inference can be performed on these networks with time and space complexity linear in the size of the network.'\nFor multiply connected networks, variable elimination can have a exponential time and space complexity in the worst case. Approximate inference algorithms are useful for large networks where exact inference is impractical. We will focus on two families of sampling algorithms: direct sampling and Markov chain sampling. Direct Sampling: The basis of any sampling algorithm is the generation of samples from a known probability distribution. To sample from a Bayes net with no evidence variables, we sample each variable in turn, in topological order. The probability distribution from which a value is sampled is conditioned on the value sampled from the variable's parents. In any sampling algorithm, the values are computed by counting the samples generated. We expect these values to converge in the limit to the true probability. An estimate is consistent if it becomes exact in the large-sample limit. Rejection Sampling: A general method for producing samples from a hard-to-sample distribution given an easy-to-sample distribution. Rejection sampling generates samples from the prior distribution specified by the Bayes net, then, it rejects all samples that do not match the evidence. The estimate, is obtained by counting how often occurs in the remaining samples. The complexity of rejection sampling depends primarily on the fraction of samples that are accepted. This fraction is exactly equivalent to the prior probabilities of the evidence. Hence, for problems with many evidence variables, convergence is extremely slow. Importance Sampling: Estimates the effect of sampling from some distribution using samples from another distribution . We ensure that the answers are correct in the limit by applying a correction factor , known as the weight, to each sample when counting up the samples. Importance sampling allows us to sample from an easier distribution and apply the necessary conditions. Let the non-evidence variables be . The only technical requirement is that should not be zero for any where is nonzero.\n<br>We want to pick a that is easy to sample from and is as close as possible to the true posterior . A common approach is <a data-href=\"Likelihood Weighting\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Likelihood Weighting</a>. The algorithm fixes the value for each evidence variable, and samples all the non-evidence variables in topological order, each conditioned on its parents. This guarantees that each sample is consistent with the evidence. Let the sampling distribution produced by this algorithm be .\nIn order to complete the algorithm, we need compute the weight for each sample generated. According to the general scheme for importance sampling, the weight should be: Where the normalizing factor is the same for all samples. Since and cover all the variables in the Bayes net, is just the product of all conditional probabilities. We can write this as the product of all the conditional probabilities for the non-evidence variables times the product of the conditional probabilities for the evidence variables: Thus, the weight is the product is simply the product of the conditional probabilities for the evidence variables given their parents. The weight is calculated iteratively, multiplying by the conditional probability each time an evidence variable is encountered. The normalization is done at the end. <br>\n<a data-href=\"Markov Chain Monte Carlo\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Chain Monte Carlo</a>: Unlike the previous algorithms, which generate each new sample from scratch, MCMC algorithms generate samples by making a random change to a proceeding sample. A <a data-href=\"Markov Chain\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Chain</a> is a stochastic process that generates a sequence of states. <a data-href=\"Gibbs Sampling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Gibbs Sampling</a> is a MCMC algorithm well-suited for Bayesian networks. We'll also discuss a more general <a data-href=\"Metropolis-Hastings\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Metropolis-Hastings</a> algorithm. Gibbs sampling starts with an arbitrary state with the evidence variables fixed at their observed values, and generates a new state by randomly sampling a value for one of the non-evidence variables . Since is independent of all other variables given its Markov blanked, Gibbs sampling for means sampling conditioned on the current values of the variables in its Markov blanket. The method of calculating the Markov blanket distribution , where denotes the values of the variables in 's Markov blanket, is given by: Therefore, for each value , the probability is given by the product of the probabilities from the CPTs of and its children. Metropolis-Hastings generates samples according to target probabilities . In the case of Bayesian networks, we want w. MH sampling has two stages in each iteration: Sample a new state from a proposal distribution , given the current state .\nProbabilistically accept the new state according to the acceptance probability: If the proposal is rejected, the state remains at . The proposal distribution is responsible for proposing a next state . This could be defined as: With probability 0.90, perform Gibbs sampling to generate .\nElse, generate using the Likelihood Weighting algorithm. This proposal distribution gets around the problem of Gibbs sampling get stuck in one part of the state space. Causal Networks are a restricted class of Bayesian networks that only permits causally compatible node orderings. This means that variables that are the causes of other variables should come first in the node ordering. In the previous chapter, we focused on probabilistic reasoning in the context of static worlds. Here, we focus on probabilistic reasoning over a history of evidence variables. In discrete-time models, the world is viewed as a series of time slices. The time interval between slices, , is assumed to be the same for all intervals. Each time slice in a discrete-time probability model contains a set of random variables which may or may not be observable. We'll use to denote the set of state variables at time , which are assumed to be unobservable; will denote the set of observable evidence variables.\nWe deal with noisy measurements by keeping an evidence variable for the observed measurement value, and a separate state variable for the actual value. For example, there may be an evidence variable and a corresponding unobservable state variable . We assume that the state sequence starts at time , and evidence starts arriving at time .\nThe notation denotes the sequence of integers from to inclusive and the notation to denote the set of variables from to inclusive. The transition model specifies how the world evolves, and the sensor model specifies how the evidence variables get their values. <br>\nThe transition model specifies the <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"35\" to=\"46\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> distribution over the latest state variables given the previous values, . Since the set is unbounded in size as increases, we make the <a data-href=\"Markov Assumption\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Assumption</a>. <br>\nThe Markov assumption says that the current state depends only on a fixed number of previous states. Processes satisfying this assumption are called Markov processes or <a data-tooltip-position=\"top\" aria-label=\"Markov Chain\" data-href=\"Markov Chain\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Chains</a>. A first-order Markov process says that the current state depends only on the previous state. Therefore: Hence, in a first order Markov process, the transition model is simply the conditional distribution . To avoid the problem of having to specify a different distribution for each possible time-step, we make the assumption that changes in the world state are time-homogeneous. The sensor model specifies how the evidence variables get their values. States should be able to generate the current sensor values; thus, we make the sensor Markov assumption: Thus, our sensor model is . The direction of dependence between state and sensors goes from the actual state of the world to the sensor values. This is because the world state causes the sensors to take on particular values. The direction of inference goes the opposite way: based on the values of the sensors, we want to infer the world state. In addition to the transition and sensor models, we need to specify the prior probability distribution at time , . With that, we have a specification of the complete joint distribution over all the variables. For any time step : The three terms on the right hand side are the initial state model , the transition model , and the sensor model .\nStandard Bayesian networks cannot be used to represent temporal models since they cannot handle an infinite set of variables. The ability to handle an infinite set of variables comes from two things: Defining the infinite set using integer indices.\nThe use of implicit universal quantification to define the sensor and transition models for each time step. There are two ways to improve the accuracy of a first-order Markov process in a domain where it is an approximation of the true environment: Increasing the order of the Markov process model.\nIncreasing the set of state variables. For example, we could add a variable if we are trying to predict rain. Though, adding state variables also increases prediction requirements since we now have to predict the new variables as well. Alternatively, we can add additional sensors that provide information directly about the new state variables. The basic inference tasks that must be solved for temporal models are: Filtering: The process of computing the belief state , the posterior distribution over the most recent state given all available evidence.\nPrediction: The task of computing the posterior distribution over the future state, given all evidence to date. That is, computing for some .\nSmoothing: The task of computing the posterior distribution over a past state given all evidence up to the present. That is, computing for some . Smoothing provides a more accurate estimate of the state at time than was available at that time.\nMost Likely Explanation: Given a sequence of observations, we want to compute the most likely sequence of states to have generated those observations. That is, computing . In addition to these inference tasks, we have: Learning: The task of learning the transition and sensor models from observations, if not yet known. A good filtering algorithm needs to maintain a current state estimate and update it as new evidence arrives rather than going back over the entire percept history. Therefore, given the result of filtering up until time , the agent needs to compute the result for from the new evidence : For some function . This process is called recursive estimation. We can see this calculation as being composed of two parts: The current state distribution is projected forward from to .\nThen, it is updated using the new evidence . Rearranging the formula gives us: Where is a normalizing constant used to make probabilities sum up to 1. Now, we plug in an expression for the one-step prediction , obtained by conditioning on the current state : We can think of the filtered estimate as a message that is propagated forward along the sequence, modified by each transition and updated by each new observation.\nWhen all the state variables are discrete, the time and space for each update is constant. Otherwise, a finite agent would not be able to keep track of the current state distribution indefinitely. Prediction can be seen as filtering without the addition of new evidence. Therefore, the recursive computation for predicting the state at from a prediction is: As we try to predict further and further into the future, the predicted distribution converges to a fixed point called the stationary distribution of the Markov process defined by the transition model. The mixing time of the process is the time taken to reach the fixed point. The more uncertainty there is in the transition model, the shorter the mixing time will be, therefore, prohibiting us from making accurate predictions about the future. We can use a forward recursion to compute the likelihood of an evidence sequence . This is a useful quantity if we want to compare different temporal models that might have produced the same evidence sequence. For this recursion, we use a likelihood message: Having computed , we obtain the actual likelihood by summing out : Notice that the likelihood message represents probabilities of longer and longer evidence sequences, thus, leading to smaller and smaller probabilities. Smoothing is the process of computing the distribution over past states given evidence up until the present, for some . We can split the computation into two parts: the evidence up to , and the evidence from to : <br>Where represents <a data-href=\"Pointwise Multiplication\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pointwise Multiplication</a> of vectors. We have defined a backward message , analogous to the forward message . The forward message can be computed by filtering forward from 1 to . The backwards message can be computed as a recursive process that runs backwards from : In this model expression, all terms come from either the model or from the previous backwards message. Hence giving us the desired recursive formulation in message form: Where implements the update described in equation 14.9. The backwards phase is initialized with a vector of 1s. This is because is an empty sequence, so the probability of observing it is 1. Both the forward and backward recursions take constant time per step. Hence, if we want to smooth a whole sequence, one naive method is to simply run the whole smoothing process once for each time step to be smoothed. This results in a time complexity of . <br>A better approach would be to utilize <a data-href=\"Dynamic Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Programming</a> to reduce the complexity to . The key is to record the results of forward filtering over the whole sequence. Then we run the backward recursion from down to 1, computing the smoothed estimate at each time step from the computed backward message and the stored forward message . This algorithm is called the <a data-href=\"Forward-Backward Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Forward-Backward Algorithm</a>. The forward-backward algorithm is a special case of the polytree propagation algorithm used with clustering methods.\nThe forward-backward algorithm has two major drawbacks: The space complexity can be too high when the state space and/or the sequences are long.\nThe basic algorithm needs to be modified to work in an online setting where smoothed estimates must be computed for earlier time slices as new observations are continuously added to the end of the sequence. Finding the most likely sequence involves taking a percept sequence and determining the most probable sequence of states that led to that percept sequence. A linear-time algorithm for finding the most likely sequence relies on the Markov property. The idea is to view each sequence of states as a path through a graph whose nodes are the possible states at each time step. The task is to find the most likely path through the graph, where the likelihood of any path is the product of the transition probabilities along the path and the probabilities of the given observations at each state. Because of the Markov property, there is a recursive relationship between the most likely paths to each state and most likely paths to each state . This property can be used to construct a recursive algorithm for computing the most likely path given the evidence.\n<br>This algorithm is called the <a data-href=\"Viterbi Algorithm\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Viterbi Algorithm</a>, which has a linear time and space complexity. Though, numerical underflow is an issue for the algorithm. <br>\n<a data-href=\"Hidden Markov Model\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hidden Markov Model</a>: A temporal probabilistic model in which the state of the system is described by a single, discrete random variable. The possible values of the variable are the possible states of the world. If you have a model with multiple variables, you can represent it with an HMM by combining the variables into a single megavariable whose values are all possible tuples of values of the individual state variables. HMMs allow for discrete and continuous evidence variables.\nLet be a single, discrete state variable that has values denoted by integers where is the number of possible states. The transition model becomes an matrix , where: That is, is the probability of a transition from state to state . To put the sensor model in matrix form, we only need to specify how likely it is for each state to cause an evidence value to appear. We place these values into an diagonal observation matrix, , one for each time step. The th diagonal entry is and the other entries are 0. If we use column vectors to represent the forward and backward messages, all the computations become simple matrix-vector operations. The forward equation becomes: The backward equation becomes: From these equations, the time complexity of the forward-backward algorithm applied to a sequence of length is , because each step requires multiplying an -element vector by an matrix. <br>\n<a data-href=\"Kalman Filter\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Kalman Filter</a>: A filtering method which can estimate continuous state variables from noisy observations over time. Kalman filters need suitable conditional density functions to represent the transition and sensor models. We will use linear-Gaussian distributions. This means that the next state must be a linear function of , with some Gaussian noise.\nConsider the task of tracking a moving object with evidence variables at each time step representing the location and velocity of the object at time . Let the time interval between observations be . Assuming constant velocity during the interval, the position update is given by . Adding Gaussian noise, we obtain a linear-Gaussian transition model: <br>A <a data-href=\"Multivariate Gaussian Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multivariate Gaussian Distribution</a> for variables is specified by a -element <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"9\" to=\"13\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> and a <a data-href=\"Covariance Matrix\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Covariance Matrix</a> .\nA key property of the linear-Gaussian family of distributions is that it remains closed under Bayesian updating. That is, given any evidence, the posterior is still in the linear-Gaussian family. <br>\n<a data-href=\"Dynamic Bayesian Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Bayesian Network</a> (DBN): Extend the semantics of Bayesian networks to handle temporal probability models. Each slice of a DBN can have any number of state variables , and evidence variables . Every hidden Markov model can be represented as a DBN with a single state variable and a single evidence variable. Likewise, every discrete DBN can be represented as a HMM. The difference between the models is that by decomposing the state of a complex system into its constituent variables, we can take advantage of sparseness in the temporal probability model.\nA DBN needs a transition matrix size of if the number of parents of each variable is bounded by . This means that DBNs are linear in the number of variables.\nTo construct a DBN, one must specify: The prior distribution over the state variables, .\nThe transition model, .\nThe sensor model . The specification of the sensor and transition models necessitates the specification of the topology of the connections between successive slices and between the state and evidence variables. Since the transition and sensor models are assumed to be time-homogeneous, it is most convenient to specify them for the first slice.\nGaussian error models are used in sensor models to model the noise in measurement values. Sensors are also susceptible to failure. Transient failures occur when a sensor temporarily transmits inaccurate readings. Persistent failures are long-term disruptions that typically require manual intervention. For the system to be able to handle error properly, the sensor model must include the possibility of failure. The simplest kind of failure model allows a certain probability that the sensor will return some incorrect value, regardless of the true state of the world. This is the transient failure model.\nTo handle persistent failures, we need a persistent failure model. We can achieve this by augmenting the state of the system with an additional variable which describes the status of the sensor; that is, the probability that the sensor is in working order or not. When the sensor is in working order, this model is identical to the transient failure model. Though, when the sensor is broken, the probability that the sensor is broken increases with each time step. To perform exact inference in a DBN, one can construct the full Bayesian network representation by replicating slices until the network is large enough to accommodate the observations. This is called unrolling the DBN. <br>We can make exact inference more efficient by performing the computation recursively. The filtering equation discussed earlier works by summing out the state variables of the previous time step to get the distribution for the new time step. This can be performed by the <a data-href=\"Variable Elimination\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Variable Elimination</a> algorithm, and it turns out that running variable elimination with the variables in temporal order exactly mimics the operation of the recursive filtering update. This allows us to perform each update in constant time and space. Though, the constant for the per-update time and space complexity is generally exponential in the number of state variables. This makes exact inference infeasible for large numbers of variables. <br>Approximate inference can be performed with the <a data-href=\"Likelihood Weighting\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Likelihood Weighting</a> or <a data-href=\"Markov Chain Monte Carlo\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Markov Chain Monte Carlo</a> algorithms discussed previously. Though, each algorithm has to be adapted to be applied to a DBN. <br>Recall that likelihood weighting works by sampling the nonevidence nodes of the network in topological order, weighing each sample by the likelihood that it occurs given the observed evidence. We can perform this algorithm on a DBN by running all samples together through the DBN, one slice at a time. The first adaptation is to use the samples themselves as an approximation of the current state distribution. This approach is called <a data-href=\"Sequential Importance Sampling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Sequential Importance Sampling</a> (SIS). In likelihood weighting, the algorithms accuracy suffers if the observed evidence is downstream of the variables being sampled, since the samples are generated without any influence from the evidence variables. If we look a the typical structure of a DBN, we'll notice that none of the state variables have any evidence variables among its ancestors. Hence, although the weight of each sample is determined by the evidence, the actual samples generated will be independent of the evidence. This means that in practice, the fraction of samples that remain reasonably close to the actual series of events drops exponentially with , the length of the sequence. Therefore, to maintain a given level of accuracy, we need to increase the number of samples exponentially with . Though, a real-time filtering algorithm can only use a bounded number of samples.\n<br>To address this issue, we focus the set of samples on the high-probability regions of the state space. This can be done by throwing away samples that have a very low weight, while replicating those that have high weights. A family of algorithms, called <a data-href=\"Particle Filtering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Particle Filtering</a> are designed to do just that.\nParticle filtering works as follows: first, we generate a population of samples from the prior distribution . Then the update cycle is repeated for each times step: Each sample is propagated forward by sampling the next state value given the current value for the sample, based on the transition model .\nEach sample is weighted by the likelihood it assigns to the new evidence , .\nThe population is resampled to generate a new population of samples. Each new sample is selected from the current population. The probability that a sample is selected is proportional to its weight. The new samples are unweighted. Decision-Theoretic Agent: An agent that can make rational decisions based on what it believes and what it wants. Such an agent can make decisions under uncertainty and with conflicting goals. A decision-theoretic agent assigns a continuous value to states. <br>\n<a data-href=\"Decision Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Theory</a>: A framework for making rational decisions under uncertainty. The desirability of an action is based off the immediate outcomes of the action. Therefore, the environment is assumed to be episodic. <br>\nWe begin with an agent that can perform some actions . There may be uncertainty about the current state, therefore, the agent assigns a <a href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"83\" to=\"94\" origin-text=\"probability\" class=\"internal-link virtual-link-a\">probability</a> to each possible current state . There also may be uncertainty regarding the outcomes of actions; the transition model is given by , the probability of reaching state when taking action in state . This can be abbreviated to : <br>The agent's preferences are defined by a <a data-href=\"Utility Function\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Utility Function</a> , which assigns a numerical value which encodes the desirability of a state. The expected utility of an action given the evidence, , is the average utility value of the outcomes, weighted by the probability that the outcome occurs: <br>\nThe <a data-href=\"Maximum Expected Utility\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Maximum Expected Utility</a> (MEU) principle says that a rational agent should choose the action which maximizes expected utility: The MEU principle is not the only way to make decisions. An agent can act in a way to achieve the highest possible utility in a single state, rather than the average, or attempt to minimize the worst possible loss. We use the following notation to describe an agent's preferences: : The agent prefers over .\n: The agent is indifferent between and .\n: The agent prefers over , or is indifferent between them. We can think of the set of possible outcomes for each action as a lottery, and each action as a ticket. A lottery with possible outcomes that occur with probabilities is written: Each outcome can be either an atomic state or another lottery. The primary issue for utility theory is to understand how preferences between complex lotteries are related to preferences between the underlying states in those lotteries. The following are six constraints that we require any reasonable preference relation to obey: Orderability: Given any two lotteries, a rational agent must either prefer one or else view both as equally preferable. That is, the agent cannot avoid deciding.\n<br><a data-tooltip-position=\"top\" aria-label=\"Transitive Property\" data-href=\"Transitive Property\" href=\"https://emujakic.github.io/TechKB/notes/math/transitive-property.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transitivity</a>: Given any three lotteries, if an agent prefers to and prefers to , the agent must prefer to .\nContinuity: If some lottery is between and in preference, then there is some probability for which the rational agent will be indifferent between getting for sure and the lottery that yields with probability and with probability : Substitutability: If an agent is indifferent between two lotteries and , then the agent is indifferent between two more complex lotteries that are the same except that is substituted for in one of them: This also holds true if we substitute for in this axiom. Monotonicity: Suppose two lotteries have the same two possible outcomes, and . If an agent prefers outcome to outcome , then the agent must prefer the lottery that has a higher probability for .\nDecomposability: Compound lotteries can be reduced to simpler ones using the laws of probability. <br>These constraints are known as the <a data-href=\"Axioms of Utility Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Axioms of Utility Theory</a>. From these axioms, we can derive the following consequences: Existence of Utility Function: If an agent's preferences obey the axioms of utility, then there exists a function such that iff (if and only if) . Furthermore, iff .\nExpected Utility of a Lottery: The utility of a lottery is the sum of the probabilities of each outcome times the utility of that outcome: <br>The preceding theorems establish that a utility function exists for a rational agent, though, not that the utility function is unique. In a deterministic environment, an agent only needs a preference ranking on states, the numbers don't matter. This is called a value function or <a href=\"https://emujakic.github.io/TechKB/notes/math/ordinal-data.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"7\" origin-text=\"ordinal\" class=\"internal-link virtual-link-a\">ordinal</a> utility function. Preference Elicitation: The process of presenting choices to a human, and using the observed preferences to derive an underlying utility function. There is no absolute scale for utilities. A scale can be established by fixing the utilities of any two particular outcomes. Typically, we fix the utility of the best possible prize at and a worst possible catastrophe at . Normalized utilities use a scale with and .\nGiven a utility scale, between and , we can assess the utility of any particular prize by asking the agent to choose between and s standard lottery . The probability is adjusted until the agent is indifferent between and the standard lottery. Assuming normalized utilities, the utility of is given by . Once this is done for each prize, the utilities for all lotteries involving these prizes are determined. Utility theory has its roots in economics, with the primary utility measure being money. It is usually the case that an agent always prefers more money to less, all else being equal. This is called a monotonic preference. The expected monetary value (EMV) of a lottery is the sum of each payout, times the probability of that payout.\n<br>The utility of money is almost exactly equivalent to the logarithm of the amount. Most people have a utility function that is concave for positive wealth. When going into debt, commonly, a reversal of the concavity associated with positive wealth is displayed. This is illustrated with the following figure:<img alt=\"utilityOfMoney.png\" src=\"https://emujakic.github.io/TechKB/resources/utilityofmoney.png\" target=\"_self\" style=\"width: 500px; max-width: 100%;\"> If we focus on the positive part of the curves, then for any lottery L, the utility of being faced with that lottery is less than the utility of being handed the expected monetary value of the lottery as a sure thing. That is: These agents are called risk-averse, they prefer a guaranteed smaller reward over a potentially larger reward. On the other hand, in the negative region of the curve, the behavior is risk-seeking.\nAn agent with a linear curve is called risk-neutral. The value an agent will accept instead of the lottery is called the certainty equivalent of the lottery. The difference between the EMV of a lottery and its certainty equivalent is called the insurance premium. The rational way to choose the best action is to maximize expected utility: In reality, our model usually oversimplifies the real world, either because we don't have complete information, or because the computation of the true expected utility is too difficult. In that case, we are really working with estimates of the true expected utility. We will assume that the estimates are unbiased, that is, the expected value of the error, , is zero. Though, even when the estimates are unbiased, the real outcome will typically be significantly worse than what we estimated.\nNegative errors are called pessimistic estimates, while positive errors are called optimistic estimates.\n<br>The tendency for the estimated expected utility of the best choice to be too high is called the optimizer's curse. We can avoid the curse with a Bayesian approach that uses an explicit probability model of the error in the utility estimates. Given this model and a prior on what me might expect the utilities to be, we treat the utility estimate as evidence and compute the posterior distribution for the true utility using <a data-href=\"Bayes' Theorem\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bayes' Theorem</a>. Decision theory is a normative theory: it describes how a rational agent should act. A descriptive theory describes how actual agents do act. Multi-attribute Utility Theory: A decision-making framework used to compare options that have multiple attributes. Let the attributes be and let be a complete vector of assignments. We will assume that utilities are monotonically increasing. If ordering has higher utilities for all attributes than another ordering , we say that strictly dominates . Strict dominance is often used to narrow down the field of choices to real contenders, though it rarely yields a unique choice. This is straightforward in the deterministic case, where the values for all attributes are known. Strict dominance is established under uncertainty if all possible concrete outcomes for dominate all possible outcomes for . Stochastic dominance is a more generalized form of dominance than strict dominance. If two actions and lead to probability distributions and on attribute , then stochastically dominates on if: For first-order stochastic dominance: <br>Where is the <a data-href=\"Cumulative Distribution\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Cumulative Distribution</a> function corresponding to . The CDFs can be expressed as: If stochastically dominates , then for any monotonically non-decreasing utility function , the expected utility of is at least as high as the expected utility of .\n<br>If an action is stochastically dominated by another action on all attributes, then it can be discarded. Algorithms exist for propagating this kind of qualitative information among uncertain variables in <a data-tooltip-position=\"top\" aria-label=\"Qualitative Probabilistic Network\" data-href=\"Qualitative Probabilistic Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Qualitative Probabilistic Networks</a>. Suppose we have attributes, each of which can take on distinct values. To specify the complete utility function, we need values in the worst case. Multiattribute utility theory aims to identify additional structure in preferences so that we don't need to specify all values individually. Having identified some regularity in preferences, we then derive representation theorems to show that an agent with a certain kind of preference structure has a utility function: Where is ideally a simple function such as addition. We begin with the deterministic case: The basic regularity that arises in deterministic preferences structures is called preference independence. Two attributes and are preferentially independent of a third attribute if the preference between outcomes and does not depend on the particular value for .\nA set of attributes exhibit mutual preferential independence (MPI) if the values of each attribute does not affect the way in which one trades off the other attributes against each other. For example, if an agent prefers ​ over regardless of the value of ​, and this preference holds for all combinations of the attributes, then the set of attributes is considered to be mutually preferentially independent.\nMPI leads to a simple form for the agent's value function: If attributes are mutually preferentially independent, then the agent's preferences can be represented by a value function: Where each refers only to the attribute .\nA value function of this form is called an additive value function. Typically, this represents an exponential reduction in the number of preference experiments needed. Even when MPI doesn't strictly hold, an additive value function can still function as a good approximation to the agent's preferences. When uncertainty is present in the domain, we need to also consider the structure of preferences between lotteries and to understand the resulting properties of utility functions, rather than just value functions. Utility independence extends preference independence to cover lotteries: a set of attributes is utility independent of a set of attributes if preferences between lotteries on the attributes in are independent of the particular values of the attributes in . A set of attributes are mutually utility independent (MUI) if each of its subsets is utility-independent of the remaining attributes. <br>MUI implies that the agent's behavior can be modeled using a multiplicative utility function. For conciseness, we use to <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"8\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> : In general, an -attribute problem exhibiting MUI can be modeled using single attribute utilities and constants. Each of the single attribute utility functions can be developed independently. <br>\n<a data-href=\"Decision Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Decision Network</a>: Also known as an influence diagram, combines Bayesian networks with additional node types for actions and utilities. In its general form, a decision network represents information about the agent's current state, its possible actions, the state that will result from each action, and the utility of that state. Three types of nodes are used: Chance Nodes (ovals): Represent random variables, just as in Bayesian networks. Each chance node is associated with a conditional distribution that is indexed by the state of the parent nodes.\nDecision Nodes (rectangles): Represent points where the decision maker has a choice of actions.\nUtility Nodes (diamonds): Represent the agent's utility function. The utility node has as parents all variables describing the outcomes that directly affect utility. The utility node is associated with a description of the agent's utility as a function of the parent attributes. <br>The following is a figure depicting a decision network for selecting a site for an airport:<img alt=\"decisionNetwork 1.png\" src=\"https://emujakic.github.io/TechKB/resources/decisionnetwork-1.png\" target=\"_self\" style=\"width: 500px; max-width: 100%;\">\nActions are selected by evaluating the decision network for each possible setting of the decision node(s). Once the decision node is set, it behaves exactly like a chance node that have been set as an evidence variable. The algorithm for evaluation decision networks is the following: Set the evidence variables for the current state.\nFor each possible value of the decision node: Set the decision node to that value.\n<br>Calculate the posterior <a data-tooltip-position=\"top\" aria-label=\"Probability\" data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">probabilities</a> for the parent nodes of the utility node, using a probabilistic inference algorithm.\nCalculate the resulting utility from the action. Return the action with the highest utility. Previously we have assumed that all relevant information is available to the agent before it has to make its decision. This is rarely the case in practice. One of the most important aspects of decision theory is knowing what questions to ask. Information value theory enables an agent to choose what information to acquire. Observation actions affect only the agent's belief state, not the external physical state. The value of any observation must derive from the potential to influence the agent's eventual decision. Information has value to the extent that it is likely to cause a change of plan and to the extent that the new plan will be significantly better than the old plan. To derive a general mathematical formula for the value of information, we'll assume that exact evidence can be obtained about the value of some random variable , therefore, the value of perfect information (VPI) is used. In the agent's initial information state, the value of the current best action is: The value of the new best action after the new evidence is obtained will be: Though, is a random variable whose value is currently unknown, so to determine the value of discovering we must average over all possible values that we might discover, using over current beliefs about its value: The expected value of information can never be negative, since in the worst case, one can just ignore the information. Though the actual value of information can be negative since it can lead to a plan that turns out to be worse than the original plan.\nVPI depends on the current state of information. For any given piece of evidence , the value of acquiring it can go down or up. Thus, VPI is generally not additive: However, VPI is order dependent: The notation denotes the VPI calculates according to the posterior distribution where is already observed. An rational agent should ask questions in a reasonable order, should avoid asking irrelevant questions, should take into account the importance of each piece of information relative to its cost, and should stop asking questions when appropriate. We assume that each observable evidence variable has an associated cost, , which reflects the cost of obtaining the evidence. The agent requests what seems to be the most efficient observation in terms of utility gain per cost unit. We assume that the result of the action is that the next percept provides the value of . If no observation is worth the cost, the agent selects a real action. This agent algorithm implements of myopic (shortsighted) form of information gathering. Myopic control is based on the same heuristic idea as a greedy search and often works well in practice. However, if there is no single evidence variable that is worth requesting, the agent may hastily take an action when it would've been better to request two or more variables first. The treasure hunt problem goes as follows: There are locations ; each location contains treasure with independent probability ; it costs to check location . This corresponds to a decision network where all potential evidence variables are absolutely independent. The question is what is the optimal order of location examination? Let be a sequence of observations; be the concatenation of sequences and ; be the expected cost of ; be the probability that finds treasure; and be the probability that it doesn't. Given these definitions, we have: That is, the sequence of will certainly incur the cost of , and will incur the cost of only if fails. Sensitivity analysis is the study of how changes in the values of model parameters affect the output of a model or process. Sensitivity analysis is particularly important in probabilistic and decision-theoretic systems because the probabilities used are typically either learned from data or estimated by human experts. This makes the probabilities themselves subject to considerable uncertainty. For a utility-driven decision-making process, you can think of the output as either the actual decision made or the expected utility of that decision. Consider the latter first: because the expectation depends on probabilities from the model, we can compute the derivative of the expected utility of any given action with respect to each of those probability values.\nIf, instead, we are concerned about the actual decisions made, then we can simply vary the parameters systematically to see whether the decision changes, and, if so, what is the smallest perturbation that causes such a change. If the optimal decision changes considerably as the parameters of the model change, then there is a good chance that the model may produce a decision that is substantially suboptimal in reality.\nA robust or minimax decision is one that gives the best result in the worst case. In this context, worst-case means worst with respect to all plausible variations in the parameter values of the model. Letting stand for all the parameters in the model, the robust decision is defined as: <br>The robust approach leads to designs that work very reliably in practice, particularly in <a data-href=\"Control Theory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Control Theory</a>. In other cases, it leads to overly conservative decisions. Bayesian decision theory offers an alternative to robust methods: explicitly model the uncertainty present in the parameters of the model using hyperparameters.\nIn addition to parametric uncertainty, decision-theoretic systems in the real world suffer from structural uncertainty. Structural uncertainty includes the assumption of independence or dependence between variables, or variables that the model omits entirely. Uncertainty can also be present within in the utility function. There are two versions of this problem: one in which an agent is uncertain about its own utility function, and another where a machine is supposed to help a human but is uncertain about what the human wants. In the former case, we could extend the decision network formalism to allow for uncertain utilities. Rather than saying that there is uncertainty in the utility function, we can externalize that uncertainty into a new random variable. With this new variable, the utility function can stay deterministic, while still being able to handle changing beliefs about preferences. For example, if an agent is unsure about whether it likes a particular movie , that uncertainty can be modeled with a new random variable with a prior probability distribution. In the case of an agent trying to learn a human's utility function, the central question is: under what circumstances will the agent defer to the human? If the agent is not certain whether its actions align with the human's preferences, it is better for the agent to allow itself to be turned off by the human. The human's decision then provides the agent with information, and the expected value of information is always non-negative.\nLet be the agent's prior probability density over the human's utility for the proposed action . The value of going ahead with is defined as: The value of action , deferring to the human, is composed of two parts: if then the human lets the agent go ahead, so the value is , but if then the human switches the agent off, so the value is 0: Comparing the expressions, we see that , because the expression for has the negative-utility region zeroed out. The two expressions have equal value only when the negative region has zero probability, when the agent is certain that the human likes the proposed action.\nThe model should be further elaborated to model the cost of the human's time: the agent should be less inclined to bother the human if the downside risk is small. Furthermore, the system should allow for some probability of human error. The agent should be less likely to defer to the human if the human is action against its own best interests. Peter. R. Norvig, Artificial Intelligence: A Modern Approach, Global Edition. ","aliases":[],"inlineTags":[],"frontmatterTags":["#textbook"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Textbook Summary: Artificial Intelligence: A Modern Approach","level":1,"id":"Textbook_Summary_Artificial_Intelligence_A_Modern_Approach_0"},{"heading":"Author(s):","level":3,"id":"Author(s)_0"},{"heading":"Introduction","level":2,"id":"Introduction_0"},{"heading":"Ch.1 Introduction","level":2,"id":"Ch.1_Introduction_0"},{"heading":"Ch.2 Intelligent Agents","level":2,"id":"Ch.2_Intelligent_Agents_0"},{"heading":"Ch.3 Solving by Searching","level":2,"id":"Ch.3_Solving_by_Searching_0"},{"heading":"Ch.4 Search in Complex Environments","level":2,"id":"Ch.4_Search_in_Complex_Environments_0"},{"heading":"Ch.5 Constraint Satisfaction Problems","level":2,"id":"Ch.5_Constraint_Satisfaction_Problems_0"},{"heading":"Ch.6 Adversarial Search","level":2,"id":"Ch.6_Adversarial_Search_0"},{"heading":"Ch.7 Logical Agents","level":2,"id":"Ch.7_Logical_Agents_0"},{"heading":"Ch.8 <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/First-Order Logic.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"5\" to=\"22\" origin-text=\"First-Order Logic\" class=\"internal-link virtual-link-a\">First-Order Logic</a></span>","level":2,"id":"Ch.8_First-Order_Logic_0"},{"heading":"Ch.9 Inference in <span class=\"glossary-entry virtual-link virtual-link-span virtual-link-default\"><a href=\"NOTES/Math/First-Order Logic.md\" target=\"_blank\" rel=\"noopener noreferrer\" from=\"18\" to=\"35\" origin-text=\"First-Order Logic\" class=\"internal-link virtual-link-a\">First-Order Logic</a></span>","level":2,"id":"Ch.9_Inference_in_First-Order_Logic_0"},{"heading":"Ch.10 Knowledge Representation","level":2,"id":"Ch.10_Knowledge_Representation_0"},{"heading":"Ch.11 Automated Planning","level":2,"id":"Ch.11_Automated_Planning_0"},{"heading":"Ch.12 Quantifying Uncertainty","level":2,"id":"Ch.12_Quantifying_Uncertainty_0"},{"heading":"Ch.13 Probabilistic Reasoning","level":2,"id":"Ch.13_Probabilistic_Reasoning_0"},{"heading":"Ch.14 Probabilistic Reasoning Over Time","level":2,"id":"Ch.14_Probabilistic_Reasoning_Over_Time_0"},{"heading":"Ch.15 Making Simple Decisions","level":2,"id":"Ch.15_Making_Simple_Decisions_0"},{"heading":"Ch.16 Making Complex Decisions","level":2,"id":"Ch.16_Making_Complex_Decisions_0"},{"heading":"References","level":2,"id":"References_0"}],"links":["notes/math/range.html#_0","notes/ai/turing-test.html#_0",".html","notes/math/first-order-logic.html#_0","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0","notes/math/range.html#_0",".html",".html",".html","notes/math/mean.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","projects/ai-chess-robot/chess-engine.html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/commutative-property.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html","notes/math/propositional-logic.html#_0",".html","notes/math/propositional-logic.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/propositional-logic.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/first-order-logic.html#_0","notes/math/first-order-logic.html#_0","notes/math/propositional-logic.html#_0","notes/math/first-order-logic.html#_0","notes/math/first-order-logic.html#_0",".html","notes/math/probability.html#_0",".html",".html",".html",".html","notes/math/first-order-logic.html#_0",".html","notes/math/first-order-logic.html#_0",".html",".html",".html",".html",".html","notes/math/propositional-logic.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/first-order-logic.html#_0","notes/math/transitive-property.html#_0",".html","notes/math/ordinal-data.html#_0","notes/math/ordinal-data.html#_0",".html",".html",".html",".html",".html",".html","notes/math/propositional-logic.html#_0",".html",".html","notes/math/probability.html#_0",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html","notes/math/mean.html#_0","notes/math/standard-deviation.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/mean.html#_0",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0",".html",".html","notes/math/transitive-property.html#_0",".html","notes/math/ordinal-data.html#_0",".html",".html",".html","notes/math/mean.html#_0",".html","notes/math/probability.html#_0",".html"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/resources/utilityofmoney.png","fullURL":"https://emujakic.github.io/TechKB/textbooks/artificial-intelligence-a-modern-approach-summary.html","pathToRoot":"..","attachments":["resources/utilityofmoney.png","resources/decisionnetwork-1.png"],"createdTime":1751236285335,"modifiedTime":1761507447000,"sourceSize":183434,"sourcePath":"TEXTBOOKS/Artificial Intelligence A Modern Approach Summary.md","exportPath":"textbooks/artificial-intelligence-a-modern-approach-summary.html","showInTree":true,"treeOrder":27,"backlinks":[],"type":"markdown"},"textbooks/computer-organization-and-design-risc-v-edition-summary.html":{"title":"Computer Organization and Design RISC-V Edition Summary","icon":"","description":"\nName: David A Patterson and John L. Hennessy\nEdition: 6th Edition\nComputer Organization and Design: RISC-V Edition serves as a comprehensive guide to understanding the principles and practices of modern computer systems. The book covers essential topics including data representation, instruction execution, pipelining, and memory hierarchy. This summary attempts to break down the main ideas and insights from the book.\n***\n## Ch.1 Computer Abstractions and Technology\n- **Personal Computer** (PC): A dedicated computer for use by an individual.\n- **Server**: A specialized computer used to run programs for multiple clients.\n- **Supercomputer**: a high-performance server, typically used for advanced scientific calculations or simulations.\n- **Embedded Computer**: A computer integrated into another system such as a car or smart TV.\n- **Personal Mobile Device**: A portable computer designed for personal use, typically battery-operated with Wi-Fi capabilities.\n- **Cloud Computing**: Large collections of servers which provide computing services over the internet. Integrated Circuit (IC): A compact assembly of electronic components made from <a data-href=\"Semiconductor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Semiconductor</a> material. It can contain billions of components integrated into a single package. ICs enable the abstraction of specific computational capabilities and the efficient mass manufacturing of cost-effective electronic components. <br>\n<a data-href=\"Central Processing Unit\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Central Processing Unit</a> (CPU): The primary component of a computer responsible for executing program instructions. Modern CPUs typically have multiple cores. Multicore Processor: A single IC containing multiple independent cores, or processing units.\n<br>Multicore processors allow <a data-href=\"Parallel Processing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Parallel Processing</a>, which is the simultaneous execution of tasks. The seven great ideas in computer architecture include: Abstraction: Hiding lower-level details from higher level representations, allowing a simpler model at high levels.\nCommon Case Fast: Focusing on improving the performance of the tasks that occur most.\nParallelism: Executing multiple tasks simultaneously.\nPipelining: The technique of breaking a complex task into a series of subtasks, allowing for the simultaneous execution of these subtasks sequentially, improving processing throughput.\nPrediction: Anticipating the outcome of an action based on historical data or patterns, allowing for proactive decision-making rather than waiting for results.\nHierarchy of Memories: Organizing different types of memory where critical information is stored in the fastest, scarcest memory, and less-critical information is stored in slower, larger memory.\nDependability via Redundancy: Detecting failures and including redundant components that can take over when a failure occurs. <br>\n<a data-href=\"Moore's Law\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Moore's Law</a>: A prediction made by Gordon Moore which states that the number of <a data-tooltip-position=\"top\" aria-label=\"Transistor\" data-href=\"Transistor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">transistors</a> that could be fit on an IC will double every two years. Moore's Law has slowed in recent years, making it no longer accurate. <br>\nSystems Software: Software designed to manage and control computer hardware. Acts as an interface between hardware and application software. This includes software such as operating systems, device drivers, firmware, or <a data-tooltip-position=\"top\" aria-label=\"Bootloader\" data-href=\"Bootloader\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">bootloaders</a>. <br>\n<a data-href=\"Operating System\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Operating System</a>: A type of systems software which managers computer hardware resources and provides services for user programs. <br>\n<a data-href=\"Compiler\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Compiler</a>: A software which translates high-level programming language statements (such as <a data-href=\"C\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">C</a>) into <a data-href=\"Assembly Language\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Assembly Language</a> statements. <br>\nElectric signals are the only way to speak directly to hardware. Digital systems typically use binary signals which are either on or off. These signals are represented in base 2 numbers called <a data-tooltip-position=\"top\" aria-label=\"Binary Number\" data-href=\"Binary Number\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">binary numbers</a>. Each binary digit is called a bit. Instruction: A command that the computer hardware can decode and execute. <br>\n<a data-href=\"Assembler\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Assembler</a>: A program which translates assembly instructions into <a data-href=\"Machine Language\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Language</a>, a binary representation of instructions which the computer hardware can understand. The compilation and translation from a high-level language into machine language is an example of abstraction. High-level languages allow for the concise development of complex programs in a symbolic syntax that humans can understand. The five classic components of a computer are: Input: Devices, such as keyboards which feed information to a computer.\nOutput: Devices such as monitors which display information to the user.\nMemory: The components which store data and instructions.\nDatapath: The hardware components responsible for the processing and transportation of data.\nControl: The hardware components which direct the operation of datapath components. <br>\nGraphics display devices, such as monitors, displays an image as a <a data-href=\"Matrix\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Matrix</a> of pixels, which is typically represented as a matrix of bits called a bitmap. A frame buffer is typically used to store the bitmap. Memory can be either volatile or nonvolatile. Volatile memory loses its data whenever power is turned off, volatile memory retains its data even after power loss. Some major memory types include: <br>\n<a data-href=\"DRAM\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">DRAM</a> (Dynamic Random Access Memory): A type of volatile memory built as an IC which can provide random access to any address. DRAM is typically the main memory of a computer, that is, the memory used to store programs while they are running. <br>Memory cells consist of a <a data-href=\"Capacitor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Capacitor</a> and a <a data-href=\"Transistor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transistor</a> which stores each bit of data as an electrical charge. Because the capacitor leaks charge over time, the data has to be periodically refreshed.\nDRAM permits access times of around 50 nanoseconds. <br>\n<a data-href=\"Cache Memory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Cache Memory</a>: A small, high-speed volatile memory, typically found inside the CPU. Cache memory acts as a buffer for slower, larger memory like DRAM. The fastest L1 cache allows access times of around 3 nanoseconds. <br>\n<a data-href=\"SRAM\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">SRAM</a> (Static Random Access Memory): Similar to DRAM, SRAM is a type of volatile memory built as an IC, though SRAM is faster, does not need to be refreshed, and is more reliable. Though this comes at a higher cost per bit and larger footprint. <br>SRAM access times typically <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"28\" to=\"33\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> from 10 to 20 nanoseconds. <br>\nSecondary Memory: Typically consists of <a data-href=\"Flash Memory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Flash Memory</a> and magnetic disks. Secondary memory is nonvolatile, therefore it is used to store perpetual data across program runs. Secondary memory is significantly slower than primary memory. <br>\n<a data-href=\"Instruction Set Architecture\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Instruction Set Architecture</a> (ISA): The vocabulary of instructions which a computer can decode and execute. Popular ISAs include <a data-href=\"RISC-V\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">RISC-V</a>, <a data-href=\"x86\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">x86</a>, MIPS, and <a data-href=\"ARMv8\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">ARMv8</a>. Application Binary Interface (ABI): The combination of the instruction set and the operating system interface for application programmers. Networks: Interconnect multiple computers together, thus, allowing them to communicate, share resources, and enable non-local access. Local Area Network (LAN): A network which interconnects devices within a limited geographical area, typically a single building. Wide Area Network (WAN): A network which spans over a large geographical area, connecting multiple LANs together. WANs can span across entire continents. <br>\n<a data-href=\"Semiconductor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Semiconductor</a>: A material which does not conduct electricity very well. <br>\n<a data-href=\"Transistor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Transistor</a>: A Semiconductor device, typically used as an electrically controlled switch. <br>\n<a data-href=\"VLSI\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">VLSI</a> (Very large-scale integrated circuit): An IC which consists of millions of transistors. Performance: Multiple factors are required to effectively assess the performance of a processor. <br>\nResponse/Execution Time: The total time required for the CPU to complete a task. This includes disk/memory access times, I/O times, etc. The performance of a CPU is the <a data-href=\"Reciprocal\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Reciprocal</a> of the execution time. CPU Time: The time the CPU takes to compute a specific task. This does not include factors external to the CPU like I/O or memory accesses. Throughput/Bandwidth: The number of tasks a CPU can complete per unit time. The primary unit time used is the clock cycle of the CPU. <br><a data-href=\"Clock Cycle\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Clock Cycle</a>: Each CPU has an internal clock, which is a periodic <a data-href=\"Square Wave\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Square Wave</a> that oscillates between high and low. A clock cycle is one complete cycle of the CPU clock. Clock Period: The length of one complete clock cycle. The clock rate is the inverse of the clock cycle. CPI (Clock Cycles per Instruction): The average number of clock cycles it takes for a processor to complete an instruction. The average is taken because different instructions require different amounts of clock cycles to complete. Instruction Count: The number of instructions executed by a program. Workload: A set of programs that a computer is required to execute.\nInstruction Mix: The distribution of different types of instructions in a given program or workload. The CPU time of program can now be defined as: Since the clock rate is the inverse of the clock cycle time, we can also define the equation as: Power Wall: A term used to describe the limitations on processor design due to power consumption and heat dissipation requirements. Making processors faster would require making them disproportionately less power-efficient, which is a problem for embedded computers which are typically battery-operated; heat dissipation is a major problem for data centers and supercomputers which require significant cooling infrastructure.\n<br>For <a data-href=\"CMOS\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">CMOS</a> ICs, the primary source of energy consumption is dynamic energy, that is, the energy consumed when a transistor switches states. Benchmark: A program used to compare and measure computer performance. MIPS (Million Instructions per Second): Measures how many millions of instructions a computer can execute in a second. Amdahl's Law: A rule which states that the performance improvement possible is limited by the amount that the improved component is used. Instruction Set: The vocabulary of instructions which a computer can decode and execute. <br><a data-href=\"RISC-V\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">RISC-V</a>: An open standard instruction set designed to be simple and efficient. RISC stands for (reduced instruction set computing).\n<br><a data-href=\"x86\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">x86</a>: An instruction set developed by Intel. x86 is a much more complex instruction set, allowing for more high-level operations. Stored-Program Concept: The idea that programs themselves can be stored in computer memory, allowing for more flexibility by making programs easier to modify. The stored-program concept also enables dynamic program execution. The principles of hardware design are: Simplicity Favors Regularity.\nSmaller is Faster.\nGood Design Demands Good Compromises. Every computer must be able to perform arithmetic. The RISC-V add instruction is add a, b, c. This instruction adds variables b and c, and stores their result in a. There is also a corresponding sub instruction with the same format.\nEach RISC-V arithmetic instruction takes three operands and performs exactly one operation on them. The operands of arithmetic instructions must come from registers. Therefore, if a variable is in memory, it must first be loaded into a register in order to be able to operate on it.\nRequiring each instruction to have exactly three operands conforms to the principle simplicity favors regularity. Byte: A group of 8 bits. Each bit is a binary digit. Word: A group of 32 bits, or four bytes.\nDoubleword: A group of 64 bits, or two words. <br>\n<a data-href=\"Register\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Register</a>: Small, fast memory locations inside the CPU that hold temporary data during processing. RISC-V has a set of 32 general-purpose registers. These registers are denoted as x0-x31. Each register is 32 bits (one word) wide. The RISC-V convention is the letter x, followed by the register number. Registers are visible to the programmer. Using only 32 registers conforms to the design principle smaller is faster. Having more than 32 registers may increase the clock cycle time since electrical signals must travel farther. Since most programs need to store more than 32 variables, the compiler tries to keep the most frequently used variables in registers, in order to minimize the number of data transfer instructions required. The compiler puts less frequently used variables in memory, this process is called spilling registers. RISC-V dedicates the register x0 to be hard-wired to the value 0, regardless of what operations are performed on it. To access data in main memory, data transfer instructions are used. To access a word in memory, the instruction must supply a memory address. RISC-V uses byte addressing, meaning sequential addresses differ by one byte. Since each word has 4 bytes, the addresses of sequential words differ by 4 bytes. Some computers use the address of the most-significant bit, the leftmost bit, as the word address; while other computers use the address of the least-significant bit, the rightmost bit, as the word address. RISC-V uses the latter, this is referred to as little-endian.\nByte addressing also effects the array index. If you want to get the first element from a base address, you offset the base address with 0, lw x5, 0(x6). To access the next element in the array, you need to offset the base address by the size of each element, in this case, the size of each word is 4 bytes. Therefore, the next element would be loaded using lw x5, 4(x6). Memory is just a large single-dimensional array, so addressing acts as the index to the array. To copy a value in memory to a register, the load instruction is used. To save the value of a register into memory, a store instruction is used. For example, in the instruction lw x5, 40(x6), the register x6 stores the base memory address. That memory address is offset by the immediate value 40, and the data in the new memory address is stored in register x5. The instruction lw stands for load word.\nThe instruction sw x5, 40(x6) stores the data in register x5 in the memory address in register , plus the offset 40. The instruction sw stands for store word. RISC-V assembly language includes arithmetic, data transfer, logical, conditional/unconditional branch, and shift instructions. <br>A more detailed description of the RISC-V assembly language is described <a data-tooltip-position=\"top\" aria-label=\"RISC-V\" data-href=\"RISC-V\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">here</a>. Many programs require the use of constants in operations. In RISC-V, these constants are called immediates, and RISC-V offers versions of the arithmetic instructions where one of the operands is an immediate. The instruction addi x5, x6, 4, stores the sum of the value in register x6 and 4 in the register x5. addi stands for add immediate. Overflow occurs when the result of an operation is larger than the register it is to be stored in. <br>\n<a data-href=\"Twos's Complement\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Twos's Complement</a>: A method for representing signed numbers in binary form. In two's complement, the value of the most-significant bit (the leftmost bit) determines the sign of the value. If the most-significant bit is a 1, the value is negative, else, it is positive. Positive numbers are represented the same way as in standard binary notation. <br>\nNegative numbers are represented by taking the corresponding positive representation, flipping all the bits, then adding 1. The flipping of the bits without adding 1 is referred to as <a data-href=\"One's Complement\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">One's Complement</a>. For example, to represent -5 in two's complement, we start with the binary representation of 5, which is 0000 0101. We then flip each bit, resulting in the one's complement representation 1111 1010. Then we add one, 1111 1011. Sign extension is a technique used to preserve the sign bit of a number when converting from a smaller bit-width to a larger one. If you're loading a signed byte into a 4 byte register, the three remaining bytes should be filled with 0's if the number is positive, and 1's if the number is negative. RISC-V offers a load byte unsigned instruction lbu, which zero-extends the leftmost bits with 0 regardless of the sign of the number. The load byte instruction, lb, preserves the sign of the data. <br>\nInstruction Format: Each RISC-V instruction is 32 bits long. The layout of each segment of the instruction is the instruction format. Each segment of the instruction is referred to as a field. The binary representation of the assembly instruction is referred to as <a data-href=\"Machine Language\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Language</a> and a sequence of such instructions is called machine code. The R-Type (register type) instruction format is used when all three operands of the instruction are registers, such as arithmetic or logical instructions. The R-type instruction format has the following fields: opcode: Denotes the operation and instruction format of the instruction. The opcode is 7 bits wide.\nrd: The destination register which receives the operation. This field, like all register fields, is 5 bits wide.\nfunct3: An additional opcode field. This field is 3 bits wide.\nrs1: The first register operand. This field is 5 bits wide.\nrs2: The second register operand. This field is 5 bits wide.\nfunct7: An additional opcode field. This field is 7 bits wide. The I-Type (immediate type) instruction format is used for arithmetic or logical instructions where one of the operands is a constant value. The load word instruction, lw, is also an I-type instruction where the immediate represents the address offset. the I-type instruction format has the following fields: opcode: Denotes the operation and instruction format of the instruction. The opcode is 7 bits wide.\nrd: The destination register which receives the operation. This field, like all register fields, is 5 bits wide.\nfunct3: An additional opcode field. This field is 3 bits wide.\nrs1: The first register operand. This field is 5 bits wide.\nimmediate: A 12 bit two's complement value which stores the constant operand. The S-Type (store type) instruction format is used for sw (store word) instructions. In this format, the 12 bit immediate is split into two fields to ensure that the rs1 and rs2 fields are in the same bits for all formats. The S-type instruction format has the following fields: opcode: Denotes the operation and instruction format of the instruction. The opcode is 7 bits wide.\nimmediate[4:0]: The lower 5 bits of the 12 bit immediate.\nfunct3: An additional opcode field. This field is 3 bits wide.\nrs1: The first register operand. This field is 5 bits wide.\nrs2: The second register operand. This field is 5 bits wide.\nimmediate[11:5]: The upper 7 bits of the 12 bit immediate. <br>\n<a data-href=\"Hexadecimal\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hexadecimal</a>: A base-16 numerical system where values 0-9 represent the numbers 0 to 9, and values A-F represent values 10 to 15. Memory addresses are commonly represented in hexadecimal notation. Logical operations are used to operate on individual bits, or fields of bits. These operations are also called bit-wise operations. Shifts move all the bits in a variable either right or left, filling the emptied bits with 0's. Shifting left by bits is the same as multiplying by , while shifting right by bits is the same as dividing by . The RISC-V shift operations include slli (shift left logical immediate) and srli (shift right logical immediate). These instructions take as arguments, a destination register, the register to shift, and the amount to shift by. These instructions use the I-type instruction format. For example, the instruction slli x11, x19, 4 takes the data in register x19, shifts it left 4 times, fills the emptied bits with zeros, and stores the result in x11.U-type RISC-V also provides a srai (shift right arithmetic immediate), which fills the emptied bits with copies of the sign bit to preserve the sign of the data. RISC-V also provides bitwise and, or, xor instructions, as well as their immediate counterparts andi, ori, and xori. The and instruction leaves a 1 in a bit position only if both operands have a 1 in that position. <br>The and instruction is commonly used to create a <a data-href=\"Bit Mask\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Bit Mask</a>, which is used to force certain bits to 0. The or instruction leaves a 1 in a bit position if either operand has a 1 in that position. The or instruction is commonly used to set certain bits to 1. The xor instruction leaves a 1 in a bit position if exactly one operand has a 1 in that position. The xor instruction can be used to with an immediate operand where all bits are 1 to perform a bitwise operation. Decision-making statements allow a computer to perform different operations conditionally. Conditional branches are a type of decision-making instruction which branch to a certain instruction if a condition holds true. The beq (branch if equal) instruction branches to an address if two registers are equal. For example, the instruction beq x2, x3, L1 branches to the statement labelled L1 if the data in registers x2 and x3 are equal.\nRISC-V also provides: bne (branch if not equal)\nblt (branch if less than)\nbge (branch if greater than or equal)\nbltu (branch if less than unsigned)\nbgeu (branch if greater than or equal unsigned) Loops are used to iterate a computation a number of times. Loops are constructed in assembly language using the conditional branches discussed earlier. Basic Blocks are a sequence of assembly instructions which execute linearly without any jumps or branches. Unconditional branches always branch to a certain instruction. Unconditional branches will be explained further in the section about procedures. Case/Switch statements are commonly encoded as a table of addresses called a branch address table. This allows the program to index the table directly with the variable used in the condition. Procedures, or functions, are subroutines of a program which get passed arguments, which are then used to perform a specific task. Procedures can also return results. The caller is the program that called the procedure. The callee is the procedure that was called. To execute a procedure, the program must: Put parameters in a place that is accessible to the procedure.\nTransfer control to the procedure.\nAcquire the storage resources needed for the procedure.\nPerform the desired task.\nPut the result value in a place accessible to the calling program.\nReturn control to the caller. RISC-V allocates its 32 registers using the following convention for procedure calling: x1: One register for storing the return address of the caller. x10-x17: Eight registers for passing parameters and return values. <br>\nIf a procedure needs more registers than the eight allocated for arguments, then we would need to spill registers to memory. This is typically done using a <a data-href=\"Stack\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Stack</a> data structure, which is a LIFO (last-in first-out) structure. <br>\nA stack keeps a <a data-href=\"Pointer\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pointer</a> to the most recently allocated address. In RISC-V, the stack pointer is commonly stored in register x2, also called sp. Placing data onto the stack is called a push, while removing data from the stack is a pop. Stacks typically grow from higher addresses to lower addresses. That means, to push values onto the stack you must decrement the stack pointer by 4. While adding to the stack pointer shrinks the stack. RISC-V also separates 19 of the 32 registers into one of two groups: x5-x7 and x28-x31: Temporary registers that are not preserved by the callee on a procedure call. x8-x9 and x18-x27: Saved registers which must be preserved by the callee. RISC-V provides an unconditional branch instruction, also called a jump instruction, specifically for procedures. The jal (jump and link) instruction branches to an address, and simultaneously stores the address of the following instruction in the destination register, typically x1. The address is passed as an immediate argument to the instruction.\nThe jalr (jump and link register) instruction branches to an address stored in a register. This is typically used to by a procedure to return to the return address of the caller. For example, the instruction jalr x0, 0(x1) jumps to the address stored in x1, without storing the current address by dumping it to register x0. <br>\n<a data-href=\"Program Counter\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Program Counter</a> (PC): The register which holds the address of the current instruction being executed. Leaf procedures are procedures that do not call any other procedures. If a procedure does call other procedures, it is a nonleaf procedure. Recursive procedures are procedures that invoke clones of themselves. Some recursive functions can be implemented iteratively, which can significantly reduce overhead. To handle nonleaf procedures, care must be taken that the argument and return address registers are not overwritten. One solution is to push all the other registers that must be preserved onto the stack; then upon the return, the registers are restored from memory, and the stack pointer is readjusted. The stack pointer, sp, is preserved by the procedure by adding exactly the same amount of bytes that was subtracted from it. <br>\nThe portion of the stack that is used to store a procedure's spilled registers is called the <a data-href=\"Procedure Frame\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Procedure Frame</a>. Some RISC-V compilers use register x8 as a frame pointer, which points to the first word in the procedure frame. <br>\n<a data-href=\"Storage Classes\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Storage Classes</a>: The C language supports the auto and static storage classes. These storage classes define the lifetime, and scope of the variable. auto is the default storage class for any variable declared inside a function/procedure. These variables are local to the procedure and are discarded when the procedure exits.\nstatic is the default storage class for variables that are not declared within any function. These variables are commonly called global variables. Static variables are preserved across function calls. Some RISC-V compilers reserve register x3 for the global pointer, that is, the register reserved for pointing to static data. <br>\nIn the <a data-href=\"Linux\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Linux</a> <a data-href=\"Operating System\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Operating System</a>, memory is allocated as follows: Reserved Memory: The first portion of low-end memory is reserved for the operating system and system-level functions.\nText Segment: Following this is the text segment, which contains the machine code for the routines defined in the source file.\nStatic Data Segment: Above the text segment lies the static data segment, which holds static and constant variables.\n<br><a data-href=\"Heap\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Heap</a>: The static data segment is followed by the heap, which is used for dynamic data structures, such as <a data-tooltip-position=\"top\" aria-label=\"Linked List\" data-href=\"Linked List\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">linked lists</a>. The heap typically grows upwards, while the stack grows downwards towards the heap. <br>\n<a data-href=\"Dynamic Memory Allocation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Memory Allocation</a>: The C language provides explicit functions for memory allocation. The malloc() function allocates space on the heap and returns a <a data-href=\"Pointer\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pointer</a> to it. The free() function releases space on the heap to which the passed pointer points to. <br>Forgetting to free memory which is no longer in use causes a <a data-href=\"Memory Leak\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Memory Leak</a>. This is the cause of many bugs in C programs.\nIf memory is freed too early, this creates dangling pointers, which are pointers that point to some unknown data in the heap. <br>\n<a data-href=\"ASCII\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">ASCII</a>: A character encoding standard which represents characters as 8-bit bytes. Though, since RISC-V software is required to keep the stack aligned to quadword (16 byte) addresses, a char variable may occupy as much as 16 bytes. RISC-V provides instructions to transfer bytes including lbu (load byte unsigned), which loads a byte from memory and places it in the 8 rightmost bits of a register. The lb (load byte) instruction sign extends the byte. The sb (store byte) instruction takes the 8 rightmost bits of a register and writes it to memory.\n<br>Characters are normally combined to form <a data-tooltip-position=\"top\" aria-label=\"String\" data-href=\"String\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Strings</a>. In C, the end of a string is denoted by the null character \\0. RISC-V provides instructions to load and store 16-bit halfwords including lhu (load half unsigned), lh (load half), and sh (store half). RISC-V provides the lui (load upper immediate) instruction, which loads a 20-bit constant into the top 20 bits of a register, the lower 12 bits are filled with zeros. This instruction enables the creation of a 32 bit constant with 2 instructions. The first instruction, lui, loads bits 12-31 of the immediate, followed by an addi instruction to load the bottom 12 bits.\nlui uses a new instruction format, the U-type format, since other formats cannot accommodate a 20 bit immediate. The U-type format has the following fields: opcode: Denotes the operation and instruction format of the instruction. The opcode is 7 bits wide.\nrd: The destination register which receives the operation. This field, like all register fields, is 5 bits wide.\nimmediate[31:12]: The upper 20 bits of the immediate. <br>\n<a data-href=\"PC-Relative Addressing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">PC-Relative Addressing</a>: An addressing scheme where the address to branch or jump to is the sum of the current program counter, and the constant/immediate in the instruction. RISC-V uses PC-relative addressing for both conditional branches and unconditional jumps. Procedure calls, on the other hand, may need to jump to addresses that are very far from the current PC. RISC-V allows for very long jumps using 2 instructions: The lui (load upper immediate) instruction writes the upper 20 bits of the address to a temporary register.\nThe jalr (jump and link register) instruction adds the lower 12 bits of the address to the register and jumps to the sum. RISC-V branch instructions represent the number of halfwords (2 bytes) between the branch and the branch target. Note that RISC-V instructions have byte addresses, meaning sequential words (4 bytes) differ by 4. <br>\n<a data-href=\"Addressing Mode\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Addressing Mode</a>: Defines how operands are identified to determine an address. In RISC-V, the primary addressing modes are as follows: Immediate Addressing: The operand is a constant within the instruction.\nRegister Addressing: The operand is a register.\nBase Addressing: The operand is at the memory location defined as the sum of the base address stored in a register, and an immediate in the instruction.\nPC-Relative Addressing: The branch address is the sum of the current PC and an immediate in the instruction. Parallel execution is when multiple processors perform tasks simultaneously. Parallelism is simple to implement if tasks are independent, though in the real world, tasks often need to cooperate. <br>\nCooperation means some tasks are writing values that others must read. When tasks cooperate, care must be taken to ensure that the processes are synchronized, else a <a data-href=\"Data Race\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Data Race</a> may occur. A data race occurs when two or more memory accesses to the same location occur across threads simultaneously and at least one is a write operation. This leads to unpredictable results because the final value of the shared data depends on the order of the memory accesses. An atomic exchange is an operation which interchanges a value in a register for a value in memory. The operation is atomic because the exchange is indivisible, meaning nothing can happen in between the memory read and write. The pair of instructions is effectively atomic if all other operations performed by all processors occur before or after the pair.\nIn RISC-V, the pair of instructions include a special load lr.w (load-reserved word) and a special store sc.w (store-conditional word). These instructions are used in sequence, if the contents of the memory location specified by the load are changed before the store to the same address occurs, then the store-conditional fails and aborts the write operation. sc.w specifies three registers: one to hold the address, one to indicate whether the operation failed or succeeded, and one to hold the value to be stored. Store-conditional returns 0 only if it succeeds, and writes a non-zero value otherwise. A loop is typically implemented to continue attempting the store-conditional until it returns a zero. Lock and unlock synchronization mechanisms create regions, called mutual exclusions, where only a single processor can operate. To implement synchronization in a multiprocessor, the ability to atomically read and write a memory location is critical. A lock is a synchronization primitive which allows a processor to create a mutual exclusion. If two or more threads try to perform an exchange simultaneously, the processor which performs the exchange first will lock the memory, preventing the other processor from operating on the memory until the first processor unlocks it. The steps to translate a C program into a program running on the computer are: Preprocessing: The C preprocessor handles preprocessor directives such as #include and #define and removes comments.\nCompilation: The compiler translates the C program into an assembly language program.\n<br>Assembly: The assembler translates the assembly language into machine language. This results in the creating of an <a data-href=\"Object File\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Object File</a> which has a .o or .obj file extension. The assembler uses a <a data-href=\"Symbol Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Symbol Table</a> to keep track of labels used in branches and data transfer instructions. The assembler may also use pseudoinstructions, which are abstractions of assembly language to make the assembly language more readable.\n<br>Linking: The <a data-href=\"Linker\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Linker</a> is responsible for combining multiple object files into a single executable. The linker makes it possible to compile and assemble procedures independently, thus allowing for local changes in a procedure without having to recompile the entire program.\nLoading: The loader is responsible for loading the executable file into memory and setting up the program's runtime environment. <br>\n<a data-href=\"Dynamically Linked Libraries\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamically Linked Libraries</a> (DLLs): Library routines that are linked to a program at runtime rather than compile time. DLLs allow for multiple programs to share the same library code, thus, reducing memory requirements. <br>\n<a data-tooltip-position=\"top\" aria-label=\"Pointer\" data-href=\"Pointer\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pointers</a>: In the C language, pointers are variables that store addresses. It is a common fallacy to believe that using pointers rather than array indices leads to more efficient programs. Though, modern compilers can produce code for array indexing that is just as efficient as pointers. Modern C compilers adhere to the following structure: Front-End: Responsible for checking the syntax and semantics of the source program, and translating the source into an intermediate form. The front-end includes four separate functions: Scanning reads in characters and tokenizes them. Tokens include reserved words, names, operators, etc.\nParsing takes the token stream, validates its syntax, and produces an abstract syntax stream, which is a representation of the syntactic structure of the program.\nSemantic analysis takes the abstract syntax tree and checks for semantic correctness. This includes checking for the proper declaration of variable types, and that the types of operators and objects match. This process is called type checking. During this process, a symbol table is generated representing all named classes, variables, and functions, which is used to type check the program.\nIntermediate representation generation takes the symbol table and abstract syntax tree and generates the intermediate representation as the output of the front end. Intermediate representations usually use simple operations on a set of primitive types. The most common forms look similar to the RISC-V assembly language with an infinite number of virtual registers. <br>\nHigh-Level Optimizations: Transformations that are done close to source level. The most common high-level optimizations performed include <a data-href=\"Procedure Inlining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Procedure Inlining</a> and <a data-href=\"Loop Unrolling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Loop Unrolling</a>. Procedure inlining replaces a call to a function with the function itself.\nLoop unrolling replicates the body of a loop multiple times. This reduces loop overhead. Local and Global Optimizations: This stage includes three classes of optimizations: Local Optimizations: Optimizations that are local to a single basic block. This is often run before and after global optimizations. Global Optimizations: Optimizations across multiple basic blocks. Code motion finds code in the body of a loop that is loop invariant, meaning the code computes the same value for each iteration of the loop. This code can be taken out of the loop and only be computed once.\nData flow analysis gathers information about how data is read and modified throughout the execution of a program. A control flow graph represents nodes as basic blocks, and arcs represent control flow between basic blocks. Global Register Allocation: Allocates variables to registers for regions of the code. Several optimizations are performed both locally and globally, including: Common Subexpression Elimination: Finds multiple instances of the same expression and computes them only once, storing the result for future use. For example, a = b+c followed by d = b+c and be optimized to a = b+c, d = a.\nConstant Propagation: Collapses constant values whenever possible.\nCopy Propagation: Propagates values that are simple copies of other variables.\nDead Store Elimination: Finds stores to values that are not used again and eliminates the store. Dead code elimination finds and eliminates unused code.\nStrength Reduction: Replaces complex expressions, such as multiply or divide, with simpler ones like left/right shift. Compilers must be conservative when optimizing. That is, a compiler should only attempt an optimization if it is certain that it will not affect the functionality of the program. Register allocation is one of the most important optimizations for modern load-store architectures. Global register allocation uses a region-based approach, where a region is a section of code during which a particular variable could be allocated to a register. A region is selected using an iterative process: Choose a definition (change) of a variable in a given basic block, add that block to the region.\nFind any uses of that definition, which is a data flow analysis problem. Add any basic block that contains such uses, as well as any basic block through which the value passes through to reach a use, to the region.\nFind any other definitions that also can affect a use found in the previous step and add the basic blocks containing those definitions, as well as the blocks through which the definitions pass through to reach a use, to the region.\nRepeat steps 2 and 3 until convergence. The set of basic blocks found by this process have the following property: If the designated variable is allocated to a register in all these basic blocks, then there is no need for loading or storing the variable.\nModern global register allocators start by constructing the regions for each virtual register in a function. Since certain regions will overlap, they may not use the same registers. This interference can be organized with an interference graph, where each node represents a region, and the arcs between nodes represent that the regions share some basic blocks. <br>Once the interference graph has been constructed, the problem of register allocation is equivalent to the problem of <a data-href=\"Graph Coloring\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Graph Coloring</a>, where you must color each node in the graph such that no two adjacent nodes are the same color. If the graph cannot be colored using the number of registers available, the allocator must spill registers to memory.\nSpilling is equivalent to splitting up a region. When a region is split, loads and stores must be used to get the value from memory. The final steps of the compiler are code generation and assembly. Most compilers do not use a stand-alone assembler, they instead perform most of the same functions, such as filling in symbolic values and generating the machine code as the last stage of code generation. <br>\nIn an <a data-href=\"Object-Oriented Programming\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Object-Oriented Programming</a> language like Java, programmers can think in terms of abstract objects. The type of object is called a class, a particular object is an instance of a class, and creating an instance of an object is called instantiation. The operations in a class are called methods, the variable members of a class are called fields. Inheritance allows for child classes to extend parent classes, which allows the child to redefine some of the methods of its parent, as well as inherit the methods it leaves unchanged.\nJava uses an automatic garbage collector, which frees memory without explicit direction from the programmer.\nJava programs are distributed as Java bytecodes which are interpreted by the Java Virtual Machine (JVM). <br>\n<a data-href=\"MIPS\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">MIPS</a> is another RISC architecture that is widely used in embedded systems. The MIPS instruction set architecture share some common features with RISC-V, including: All instructions are 32 bits wide.\nBoth have 32 general-purpose registers, with one being hardwired to zero.\nThere are no instructions for loading or storing many registers.\nBoth have branch if zero and branch if not zero instructions.\nBoth sets of addressing modes work for all word sizes. One of the main differences between RISC-V and MIPS is for conditional branches. While RISC-V simply provides branch instructions to compare two registers, MIPS' comparison instructions set a register to 1 or 0 depending on the outcome of the comparison. <br>\n<a data-href=\"ARMv8\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">ARMv8</a> is another RISC ISA, and is the most popular ISA for embedded devices. ARMv8 is very similar to MIPS, though ARMv8 is a 64-bit ISA. V8 has 32 general-purpose registers, where one register is hardwired to zero. Its addressing modes work for all word sizes. <br>\n<a data-href=\"x86\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">x86</a> is a CISC (complex instruction set computing) ISA, which provides more powerful instructions than a RISC architecture, with the goal to reduce the instruction count of programs. This reduced instruction count comes at the cost of slower, more complex instructions, which may result in a slower clock cycle time. The RISC-V architecture is partitioned into a base architecture, and several extensions. Each extension is named with a letter of the alphabet, with the base architecture labelled as I \"Integer\". The following are some unmentioned instructions in the base RISC-V architecture: auipc is used for PC-relative memory addressing. Like the lui instruction, it holds a 20-bit constant that corresponds to bits 12 through 31 of an integer. This instruction adds this constant to the PC and writes the sum to a register.\nslt (set less than) and sltu (set less than unsigned) compare two integers and write the Boolean result to a register.\nslti(set less than immediate) and sltiu (set less than immediate unsigned) do the same but with an immediate as the second register. The five standard extensions of the base architecture are: M (Multiply and Divide): Adds instructions for multiplication and division.\nA (Atomic Memory Operations): Adds atomic memory operations for multiprocessor synchronization.\nF and D (Floating-Point): Provides operations on floating-point numbers.\nC (16-Bit Instructions): Provides equivalent instructions that are only 16 bits long. Some common fallacies and pitfalls include: <br>Fallacy: More powerful instructions <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"36\" to=\"40\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> higher performance. More powerful instructions typically incur more overhead and force a longer clock cycle time. Fallacy: Write in assembly language to obtain the highest performance. Modern compilers can produce code just as fast or even faster than assembly language programmers. Pitfall: Forgetting that sequential word addresses in machines with byte addressing do not differ by one. Sequential addresses should be incremented by the number of bytes in a word (typically 4). Binary addition is performed by adding digits bit by bit, from right to left, with carries passed to the next digit. Binary subtraction uses addition by simply negating the appropriate operand beforehand. When adding operands with different signs, overflow cannot occur, since the result cannot be greater than one of the operands.\nOn the other hand, when subtracting, overflow cannot occur if both operands have the same signs. This is because when we subtract operands of the same sign, it is the same as adding operands of different signs, since subtraction negates one of the operands. Overflow occurs when the result of a computation cannot fit in the destination register. If adding two 32-bit integers, the 32nd bit may have a carry, thus, resulting in an overflow. In this case, the sign bit (most-significant bit) is set with the value of the result instead of the proper sign of the result. Therefore, overflow occurs when adding two positive numbers results in a negative sum, or vice versa.\n<br>Overflow occurs in subtraction when we subtract a negative number from a positive number and get a negative result, or when we subtract a positive number from a negative number and get a positive result. Such results <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"217\" to=\"221\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> that a borrow occurred from the sign bit.\nIn the case of unsigned integers, overflow has occurred if the sum is less than either addends, or the difference is greater than the minuend (the number being subtracted from). <br>\n<a data-href=\"Arithmetic Logic Unit\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Arithmetic Logic Unit</a> (ALU): The hardware component responsible for performing arithmetic and logical operations on data. The ALU is typically capable of performing addition, subtraction, multiplication, division, AND, OR, NOT, and XOR operations. In multiplication, the first operand is the multiplicand, the second operand is the multiplier, and the result is the product. If we ignore the sign bits, the length of the multiplication of an -bit multiplicand and an -bit multiplier is a product that is bits long. The algorithm for binary multiplication is similar to that of decimal multiplication. It consists of the following steps: Align the operands one above the other.\nStarting from the least-significant bit of the multiplier, multiply each bit of the multiplier with the entire multiplicand.\nFor each subsequent bit of the multiplier, shift the partial product one position to the left.\n<br>Add the partial products to get the product. <img alt=\"MultiplicationHardware 1.png\" src=\"https://emujakic.github.io/TechKB/resources/multiplicationhardware-1.png\" target=\"_self\"> In this figure, the multiplier is placed in the right half of the product register. The simplest way to perform signed multiplication is to convert both operands to their corresponding positive values, and remember the original signs of each operand. If the signs, differ, than the product can be negated to get the signed product. For signed multiplication, the shifting steps would need to sign-extend the sign of the product. <br>\nFaster multiplications are possible by providing one 32-bit adder for each bit of the multiplier, one input is the multiplicand ANDed with the multiplier bit, and the other is the output of the previous adder.<img alt=\"MultiplierParallelTree.png\" src=\"https://emujakic.github.io/TechKB/resources/multiplierparalleltree.png\" target=\"_self\"> RISC-V has four multiply instructions: mul: Multiply\nmulh: Multiply high, gets the upper 32-bits of a 64-bit product if both operands are signed.\nmulhu: Multiply high unsigned, gets the upper 32-bits of a 64-bit product if both operands are unsigned.\nmulhsu: Multiply high signed-unsigned, gets the upper 32-bits of a 64-bit product if one operand is signed and the other is unsigned. In division, the dividend is the number being divided, the divisor is the number the dividend is divided by, the quotient is the primary result of the division, and the remainder is the secondary result. The algorithm for binary division is similar to that of decimal division. It consists of the following steps: Starting from the left, compare the divisor with the portion of the dividend, if the divisor is less than or equal to that portion, subtract the divisor from it.\nFor each subtraction, write a 1 in the quotient. If the divisor is larger than the partial dividend, write a 0.\nBring down the next bit of the dividend.\nRepeat until all the bits of the dividend have been brought down.\n<br>If the final subtraction leaves a value smaller than the divisor, that value is the remainder.<img alt=\"DivisionHardware 1.png\" src=\"https://emujakic.github.io/TechKB/resources/divisionhardware-1.png\" target=\"_self\"> The hardware performs this algorithm by initializing the quotient to zero, and the remainder is initialized to the dividend. Next, you subtract the divisor from the remainder, and if the result is positive, a 1 is generated in the quotient; if the result is negative, the original value is restored by adding the divisor, and a 0 is generated in the quotient. The divisor is shifted right, and the algorithm iterates. Like multiplication, the easiest way to handle signed division is the remember the signs of the operands and then negate the quotient if the signs disagree. To get the correct sign of the remainder, we match it with the sign of the dividend. <br>\nThe <a data-href=\"SRT Division\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">SRT Division</a> technique tries to predict several quotient bits per step using a table lookup based on the upper bits of the dividend and remainder. <br>A <a data-href=\"Nonrestoring Division\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Nonrestoring Division</a> algorithm is even faster, taking only one clock cycle per step. In this algorithm, if the remainder becomes negative, instead of immediately adding the divisor back, it adds the dividend to the shifted remainder in the following step. RISC-V provides 4 division instructions: div: Divide\ndivu: Divide unsigned\nrem: Remainder\nremu: Remainder unsigned Note that RISC-V instructions ignore overflow, so it is up to the software to determine whether the quotient is too large. Division can also result in a division by zero, which must also be detected by software. <br>\n<a data-href=\"Floating-Point\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Floating-Point</a> numbers, also called real numbers, are number with fractional values. The name comes from the fact that the binary point can be placed anywhere in the number. <br>\nFloating-point numbers are typically represented in binary using <a data-href=\"Scientific Notation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Scientific Notation</a>. Scientific notation is made up of a fraction, a base, and an exponent. A number in scientific notation with no zeros to the left of the decimal point is a normalized number. For example, is normalized, while and are not. Normalized form offers three advantages: It simplifies exchanges of data that include floating-point numbers.\nIt simplifies floating-point arithmetic algorithms.\nIt increases the accuracy of the numbers that can be stored in a word. <br>\nA floating-point representation must find a compromise between the size of the fraction, which determines the precision of the representation, and the size of the exponent, which determines the <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"5\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of the representation. <br>The RISC-V representation of a floating-point number consists of a sign bit, an 8-bit exponent field, and a 23-bit fraction field.<img alt=\"riscvFloatingPoint.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvfloatingpoint.png\" target=\"_self\">\nOverflow occurs in floating-point representations when the exponent is too large to fit in the exponent field. Floating-points are also subject to underflow, which occurs when the non-zero fraction is too small to be represented. This means that the negative exponent is too large to fit in the exponent field.\n<br>One way to reduce the chances of under/overflow is to increase the size of the exponent. A double-precision floating-point is a 64-bit doubleword, as opposed to the 32-bit single-precision floating-point discussed earlier. <img alt=\"riscvDoublePrecision 1.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvdoubleprecision-1.png\" target=\"_self\">\n<br>Some computers signal an <a data-href=\"Exception\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Exception</a>, or interrupt, when an over/underflow is detected. An exception is a unscheduled event that disrupt the execution of a program. The address of the instruction that caused the exception is saved in a register, and the computer jumps to a predefined address to invoke the proper routine for that exception type. RISC-V computers do not raise exceptions for overflow or underflow and instead software can read the floating-point control and status register (fcsr) to check whether an over/underflow has occurred. <br>\nThe <a data-href=\"IEEE 754\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">IEEE 754</a> floating-point standard is a widely standard for floating-point representations. IEEE 754 makes the leading 1 bit of normalized binary numbers implicit. We use the term significand when referring the number that is 1 plus the fraction. Since 0 has no leading 1, it is given the reserved exponent 0, so the hardware won't attach a 1 to it. Thus, represents 0, and the rest of the numbers use the following form: IEEE 754 reserves the largest exponent to represent and .\n<br>IEEE 754 also has a symbol for invalid operations. such as . This symbol is NaN (Not a Number).<img alt=\"ieee754.png\" src=\"https://emujakic.github.io/TechKB/resources/ieee754.png\" target=\"_self\">\nBiased notation represents the most positive exponent as and the most negative exponent as . The bias is the number that is subtracted from the normal, unsigned representation to determine the value. IEEE 754 uses a bias of 127 for single precision, so an exponent of is represented as .\nThe exponent bias for double precision is 1023.\nBiased notation means that the representation for floating-points is really: IEEE 754 also added a 16-bit format for half-precision and a 128-bit format for quadruple-precision. To perform floating-point addition, we use the following algorithm: Shift the significand of the number with the smaller exponent to the right until both numbers have the same exponent.\nAdd the significands, then, normalize the result.\nIf the resulting exponent is too large (overflow) or too small (underflow) to fit in the designated field, handle these cases accordingly.\n<br>Round the significand if necessary to fit in its field. It may be necessary to re-normalize after rounding.<img alt=\"floatingPointAdditionHardware 1.png\" src=\"https://emujakic.github.io/TechKB/resources/floatingpointadditionhardware-1.png\" target=\"_self\"> To perform floating-point multiplication, we use the following algorithm: The exponent of the product is simply the sum of the exponents of the operands. When adding biased exponents, you must remember to subtract the bias from the sum in order to not include the bias twice.\nMultiply the significands of each operand. The position of the binary/decimal point in the product is determined by the total number of digits to the right of the point in each operand.\nNormalize the resulting product.\nIf the resulting exponent is too large (overflow) or too small (underflow) to fit in the designated field, handle these cases accordingly.\nRound the significand if necessary to fit in its field. It may be necessary to re-normalize after rounding.\nThe sign of the product is the result of an XOR of each operands sign: if the signs are the same, the result is positive, otherwise, the result is negative. RISC-V supports the IEEE 754 single and double-precision formats with the following instructions: fadd.s and fadd.d: floating-point addition single and double precision, respectively.\nfsub.s and fsub.d: floating-point subtraction single and double precision, respectively.\nfmul.s and fmul.d: floating-point multiplication single and double precision, respectively.\nfdiv.s and fdiv.d: floating-point division single and double precision respectively.\nfsqrt.s and fsqrt.d: floating-point square root single and double precision, respectively.\nfeq.s and feq.d: floating-point equals single and double precision, respectively.\nflt.s and flt.d: floating-point less-than single and double precision respectively.\nfle.s and fle.d: floating-point less-than-or-equals single and double precision, respectively.\nThe comparison instructions set an integer register to 0 if the comparison is false and 1 if it is true. RISC-V includes 32 separate floating-point registers labelled f0-f31. Hence, they include separate loads and stores for floating-point registers: fld and fsd for double-precision.\nflw and fsw for single-precision.\nThe base registers for floating-point data transfers remain integer registers.\nUnlike the integer register, the floating-point register f0 is not hardwired to 0. The floating-point instructions use the same format as their integer counterparts: Loads use the I-type format.\nStores use the S-type format.\nArithmetic instructions use the R-type format. Since floating point numbers are mere approximations of real numbers, the IEEE 754 standard offers several modes of rounding the programmer can choose from: IEEE 754 keeps two extra bits on the right during floating-point calculations, called the guard and round bits. The guard bit is placed immediately to the right of the least significant bit of the mantissa, followed by the round bit. These two bits store the next bit that would be lost due to truncation, and uses them to determine how to round the result.\nThe IEEE 754 standard also keeps track of a sticky bit that is set to 1 whenever there is non-zero bits to the right of the round bit, and is otherwise 0. Accuracy in floating-point representations is measures in terms of the number of bits in error in the least significant bits of the significand. This measure is called the number of units in the last place (ulp). IEEE 754 guarantees that the computer uses numbers within one-half ulp.\nIEEE 754 provides four rounding modes: Always round up.\nAlways round down.\nTruncate.\nRound to nearest even. Many graphics systems originally used 8 bits to represent each of the three primary colors, plus 8 bits for the location of a pixel. The addition of speakers and microphones required support for sound as well. 16 bits of precision were sufficient for audio samples. All microprocessors have special support so that bytes and halfwords take up less space and memory. This support was typically limited to data transfer operations.\nMany graphics and audio applications would perform the same operations on vectors of data. By partitioning the carry chains within a 128-bit adder, a processor can use parallelism to perform simultaneous operations on vectors of sixteen 8-bit operands, eight 6-bit operands, four 32-bit operands, or two 64-bit operands. <br>Since this parallelism occurs within a wide word, it is called <a data-href=\"Subword Parallelism\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Subword Parallelism</a>. It is also known as vector or SIMD, for single instruction, multiple data parallelism. The performance of a computer is determined by three factors: Instruction count.\nClock cycle time.\nClock cycles per instruction (CPI). The first two steps of every instruction are: Send the program counter (PC) to the memory that contains the code and fetch the instruction from memory.\nRead one or two registers using the fields of the instruction and its instruction format. <br>\nAll instruction classes use the <a data-href=\"Arithmetic Logic Unit\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Arithmetic Logic Unit</a> (ALU) after reading registers. Memory-reference instructions use the ALU to calculate a memory address.\nArithmetic-logical instructions use the ALU for operation execution.\nConditional branches use the ALU for equality tests. After using the ALU, the following actions required to complete various instruction classes differ: Memory-reference instructions need to access memory to either read or write data.\nArithmetic-logical instructions must write the output of the ALU back into a register.\nConditional branch instructions may need to change the next instruction address. <br>\n<a data-href=\"Multiplexer\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multiplexer</a> (MUX): A digital switch that selects one of several input signals based on control signals. Control lines must also be set based on fields of the instruction to direct the operations of each component (e.g., ALU, Memory, etc.).\n<br>A control unit takes the instruction as input, and outputs the value of the control lines for the functional units and multiplexers.<img alt=\"risc-vDatapath.png\" src=\"https://emujakic.github.io/TechKB/resources/risc-vdatapath.png\" target=\"_self\"> The datapath elements in the RISC-V implementation consist of two different types of logical elements: Combinational Elements: Elements whose outputs are determined entirely by its inputs. For example, AND and OR gates are combinational elements.\nState Elements: Elements that contain internal state, also called memory elements. For example, main memory and registers are state elements. State elements have at least two inputs and one output. The inputs are the data value to be written into the element, and the clock signal, which determines when the value is written. The output of the state element is a value that was written in an earlier clock cycle. State elements can be read at any time.\nState elements are also called sequential elements. <br>\n<a data-href=\"Clocking Methodology\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Clocking Methodology</a>: The approach used to determine when data are valid and stable relative to the clock. Edge-triggered clocking is a clocking methodology where values stored in sequential elements are updated only on a clock edge. A clock edge is the transition from high to low or vice versa. The rising edge is the transition from low to high, while the falling edge is the transition from high to low. We use the rising edge in this book. Setup Time: The minimum time before the clock edge during which the input data must remain stable.\nHold Time: The minimum time after the clock edge during which the input data must remain stable. The time necessary for signals to propagate through the datapath determines the minimum possible clock cycle time. The term asserted means that a signal is driven logically high, and the term deasserted means a signal is driven logically low. These terms are used because, at times, a 1 can represent either a logical high or a logical low, depending on the hardware implementation. Elements which are asserted with a 1 are called active high, while elements which are asserted with a zero are called active low. For the 32-bit RISC-V architecture, nearly all state and logic elements will have 32-bit wide inputs and outputs. This data is transferred using buses, which are a set of parallel wires that carry multiple bits of data simultaneously. The datapath elements we need to execute each class of RISC-V instructions are: Memory Unit: Stores the instructions of a program and outputs instructions given an address. The memory unit has read and write control signals, an address input, and an input for the data to be written to memory. We will also need a hardware unit that can sign-extend the 12-bit signed offset in the instruction to a 32-bit signed value.\nProgram Counter (PC): A register which holds the address of the next instruction. The PC is incremented by 4, so that it points at the next instruction.\nALU: The arithmetic logic unit which performs arithmetic and logical operations based on the setting of its control lines. The ALU takes two 32-bit inputs and produces a 32-bit result, as well as a 1-bit signal if the result is 0.\nRegister File: A data structure containing the processor's 32 general-purpose registers. The register file always outputs the contents of whatever register numbers are on the ReadRegister inputs. Writes, however, are controlled by a write control signal, which must be asserted for a write to occur at the clock edge. <br>\nThe beq instruction has three operands, two registers which are tested for equality, and a 12-bit offset used to compute the branch target address relative to the branch instruction address. This is an example of <a data-href=\"PC-Relative Addressing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">PC-Relative Addressing</a>. When the condition is true, the branch target address is the new PC, and we say that the branch is taken. When the condition is false, the PC is incremented by 4, and we say that the branch is not taken.\n<br>The branch datapath requires an immediate generation unit and an <a data-href=\"Adder\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Adder</a>. The immediate generation unit (ImmGen) takes an instruction as input, and selects the 12-bit immediate field and outputs a 32-bit sign-extended result. <br>\nThe simple datapath which implements the capabilities described thus far shown in the figure below:<img alt=\"riscvDatapath2 1.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvdatapath2-1.png\" target=\"_self\"> This figure omits the control unit, which takes an instruction as input, and sets the control lines for each multiplexer and functional unit. The RISC-V ALU defines the four following combinations of control inputs: 0000: Logical AND, used for AND instructions.\n0001: Logical OR, used for OR instructions.\n0010: Addition. Used for add instructions, as well as data transfer instructions to calculate the memory address. 0110: Subtraction, used for sub and conditional branch instructions. We can generate the 4-bit ALU control signal with a small control unit that takes as input the funct7 and funct3 fields of the instruction, and a 2-bit control field called ALUOp. The ALUOp field indicates whether the operation to be performed should be add (00) for loads and stores, subtract and test if zero (01) for conditional branches, or be determined by the funct7 and funct3 fields (10).\nThe output of the ALU control unit is a 4-bit control signal which determines the function of the ALU.\nThis control unit uses multiple levels of decoding: the main control unit generates the ALUOp bits, which are then used as input to the ALU control that generates the actual control signals. Multiple levels of decoding can reduce the size and latency of the main control unit. <br>\n<a data-href=\"Truth Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Truth Table</a>: A table which determines the truth values of logical expressions based on their inputs. <br><a data-href=\"Don't Care\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Don't Care</a> terms are terms whose truth value have no effect on the output. Don't cares are typically represented symbolically as or .\n<br>The following figure is the truth table for the ALU control unit:<img alt=\"aluTruthTable.png\" src=\"https://emujakic.github.io/TechKB/resources/alutruthtable.png\" target=\"_self\"> Some major observations about RISC-V instruction formats are: The opcode field is always in bits 6:0. Depending on the opcode, the funct3 field (bits 14:12) and the funct7 field (bits 31:25) serve as an extended opcode.\nThe first register operand is always in bits 19:15 for R-type and branch instructions. This field also specifies the base address for data-transfer instructions.\nThe second register operand is always in bits 24:20 for R-type and branch instructions. This field also specifies the register operand that gets copied to memory for store instructions.\n<br>The destination register is always in bits 11:7 for R-type and load instructions.<img alt=\"riscVinstructionFormats.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvinstructionformats.png\" target=\"_self\"> <br>\nThe following figure shows the RISC-V datapath with the control unit, which takes the opcode as input, and outputs the value of each control signal:<img alt=\"riscVControlUnit 1.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvcontrolunit-1.png\" target=\"_self\"> ALUOp is bold to indicate that it is a 2-bit bus line. <br>\nThe following figure shows the truth table for the control unit for each instruction format:<img alt=\"riscVInstructionFormatControl.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvinstructionformatcontrol.png\" target=\"_self\"> The design we have discussed so far is a single-cycle design. This type of datapath performs the entire instruction in one clock cycle, requiring the clock cycle to be long enough to accommodate the longest instruction. This means the clock speed is limited by the longest possible path through the datapath. This results in a clock speed that is far too slow for modern processing. The alternative to a single-cycle design is a multicycle design, where each instruction is broken into a series of steps. These steps correspond to functional unit operations. Each step takes 1 clock cycle to execute, allowing a functional unit to be used multiple times per instruction, as long as it is used in distinct clock cycles. This also allows instructions to take different amount of clock cycles to execute. Though, pipelined datapaths are used on almost all modern chips over multicycle implementations. <br>\n<a data-href=\"Pipelining\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Pipelining</a> is an implementation technique where the execution of multiple instructions are overlapped. This technique is similar to an assembly line, where different stages of execution occur simultaneously. By allowing multiple instructions to be in different stages of execution at the same time, pipelining significantly enhances the overall performance and throughput of the CPU. A pipelined datapath is divided into stages that operate concurrently. RISC-V instructions include five stages: Instruction Fetch (IF): The CPU fetches the next instruction from memory based on the PC.\nInstruction Decode (ID): The fetched instruction is decoded, determining the setting of control lines, and the operands required. This involves fetching the necessary registers from the register file.\nExecution (EX): The actual operation specified by the instruction is performed.\nMemory Access (MEM): Handles read and write accesses if required by the instruction.\nWrite Back (WB): Writes the result of the instruction into the appropriate register in the register file. Note that the speed-up acquired by pipelining only applies when multiple instructions need to be executed. The time it takes to execute one instruction is the same as it would be in a single-cycle implementation. This is because pipelining improves throughput, that is, the amount of work that a CPU can perform in a given time frame. The speed-up gained from a pipelined implementation the amount of time each stage takes, as well as the amount of work that needs to be done. Let be the number of pipeline stages: The pipeline achieves an ideal speed-up of if each stage is of equal length. If the stages are of unequal length, the overall pipeline speed is determined by the longest stage.\nWhen a CPU starts executing, the pipeline is empty, and it isn't full until at least instructions have started executing. This is called the start-up time.\nConversely, wind-down time occurs when the pipeline is no longer receiving new instructions. This period is required to complete the execution of any remaining instructions in the pipeline before the CPU can safely shut down.\nPipelining also incurs some overhead, including stalls, structural hazards, data hazards, control hazards, and data duplication, which will be discussed later. The RISC-V instruction set architecture was designed for pipelined execution. This was done by making all instructions the same length, that is, 4 bytes. This makes the instruction fetch (IF) and instruction decode (ID) stages simpler to implement in hardware.\nRISC-V also has only a few instruction formats, with the source and destination registers being located in the same bit positions in each format. Hazards are situations in a pipelined datapath which prevent the next instruction from being executed in the following clock cycle. There are three different types of hazards: Structural Hazards: Occur when the hardware resources available are insufficient to support the combination of instructions that are set to execute.\nData Hazards: Occur when instructions which are close together have data dependencies. This requires the pipelined to be stalled to wait for the data to become available. These stalls can be minimized or potentially eliminated if, instead of waiting for the previous instruction to write the data back to the register file, additional hardware can be added to forward or bypass the data to a further stage in the pipeline. This is only valid if the destination stage is later in time than the source stage.\nA load-use data hazard is a type of data hazard where data being loaded by a load instruction has not yet become available when another instruction needs it. These hazards can be mitigated by using either hardware detection and stalls, or by reordering the code to allow time for the data to be loaded in time. Control Hazards: Also called branch hazards, occur when the proper instruction cannot execute in the proper pipeline cycle because the instruction fetched was not the instruction required. This occurs when a branch instruction changes the control flow of the program, causing the instructions in the pipeline to be invalid. Two solutions to deal with control hazards include: Stalling: This solution simply stalls until the result of the condition is computed to start fetching instructions again. Though, the slowdown resulting from this solution is far too high for modern computers.\n<br>Predicting: This solution involves predicting the outcome of the condition and fetching instructions based off that prediction. This option results in no slowdown if the prediction is correct, though, if the prediction is incorrect, the pipeline will have to be restarted, so instruction execution can start from the correct address. This technique is called <a data-href=\"Branch Prediction\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Branch Prediction</a>. Dynamic branch prediction make their guesses depending on the behavior of each conditional branch, rather than some predetermined formula or pattern. A popular approach to dynamic branch prediction involves keeping a history of recent branch results, and using the recent past behavior to predict the future. This can result in prediction accuracies of more than 90%. <br>\nThe following figure denotes the previous single-cycle datapath divided into the corresponding five pipeline stages:<img alt=\"riscpipeline.png\" src=\"https://emujakic.github.io/TechKB/resources/riscpipeline.png\" target=\"_self\"> In this figure, data moves from left-to-right, with two exceptions: The write-back stage, which writes a result back into the register file. This can lead to data hazards.\nThe selection of the PC source. This can lead to control hazards. <br>In this datapath, the instruction memory is used during only one stage of the pipeline, allowing it to be shared by the following instructions. Though, to retain the value of an individual instruction for the following stages, the value read from the instruction memory must be saved to a register. Therefore, we must place registers where each dividing line is present in the figure. These registers, called pipeline registers, are present in the following datapath figure:<img alt=\"riscvpipeline2.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvpipeline2.png\" target=\"_self\"> The highlighted lines denote the datapath for the destination register of a load instruction.\nThese pipeline registers are used to store and pass any information needed by a later stage. We will now focus on creating the control for the pipelined datapath. We will borrow the ALU control logic, branch logic, and control lines from the single-cycle implementation. We assume that the PC and all pipeline registers are written on each clock cycle, therefore, they require no explicit write signals.\nTo specify control for the pipeline, we need only set the control values during each pipeline stage. Therefore, we can divide the control lines into five groups:\nInstruction Fetch (IF): Since the control signals to read instruction memory and write the PC are always asserted, there is no control to set in this stage.\nInstruction Decode (ID): The two source registers are always in the same location in all RISC-V instruction formats, therefore, there is no control to set in this stage.\nExecution (EX): The signals to be set are ALUOp and ALUSrc. These signals select the ALU operation, and select the source of the second operand as either the second register argument or a sign-extended immediate.\nMemory Access (MEM): The signals to be set are Branch, MemRead, and MemWrite. The branch if equal, load, and store instructions set these signals, respectively. Recall that PCSrc selects the next sequential address unless control asserts Branch and the ALU result was 0.\nWrite Back (WB): The two signals to be set are MemToReg, which decides between sending the ALU result or the memory value to the register file, and RegWrite, which writes the chosen value to the register file. <br>\nSince the rest of the control lines start with the EX stage, we can create the control information at the instruction decode stage, and pass the control signals via the pipeline registers. This is denoted with the following figure:<img alt=\"risvpipelinecontrol.png\" src=\"https://emujakic.github.io/TechKB/resources/risvpipelinecontrol.png\" target=\"_self\"> Data hazards occur when instructions which are close together have data dependencies. If a register is read and written in the same clock cycle, we assume that the write occurs in the first half of the clock cycle, and the read in the latter half. This way, the read delivers what is written, and thus, we have no data hazard. If an instruction in the pipeline needs a result of a instruction that is backward in the pipeline, the datapath can forward the data to the instruction as soon as the result is available. Here, we only consider the challenge of forwarding to an operation in the EX (execution) stage. When an instruction tries to use a register in its EX stage that an earlier instruction in the pipeline intends to write to in its WB stage, we need to forward the value to be written. Because some instructions do not write registers, we need to check that the RegWrite signal is asserted before we forward. Additionally, if the register being written to is register x0, we should avoid forwarding the potentially non-zero value. <br>We can provide hardware support for forwarding by adding multiplexers to each input of the ALU, and with the proper control signals, we can forward a value from a pipeline register into the ALU input. This is illustrated in the figure below:<img alt=\"forwardingALU.png\" src=\"https://emujakic.github.io/TechKB/resources/forwardingalu.png\" target=\"_self\"> The forwarding unit takes the Rd fields of the EX/MEM and MEM/WB pipeline registers and forwards their value to the ALU if these conditions are met: The RegWrite control line is asserted in the corresponding pipeline register.\nRegister Rd is not x0.\nRegister Rd is the same register as register Rs1 or register Rs2 for the EX stage. One complication occurs if both the EX/MEM and MEM/WB meet all of these conditions. In this case, the EX/MEM value should be forwarded, since this is the most recent value. Forwarding cannot be used for a read-after-write hazard, because the data is still being read from memory when the ALU needs the result. This requires the pipeline to be stalled. Hence, we need a new functional unit, called the hazard detection unit. The hazard detection unit operates during the ID stage so that it can insert a stall between the load and the instruction dependent upon it. The hardware detection unit stalls if the following conditions are met: The ID/EX pipeline register asserts MemRead. The only instruction that asserts MemRead is a load instruction.\nThe ID/EX.RegisterRd register equals the IF/ID.RegisterRs1 or IF/ID.RegisterRs2 register. If these conditions hold, the instruction stalls one clock cycle. To prevent the instructions in the ID stage and IF stage from progressing, you simply prevent the PC register and the IF/ID register from changing during a stall.\nThough, the further stages of the pipeline, starting from the EX stage, still must be doing something. We make these stages perform NOPs, which are instructions that does no operation to change state. We can implement nops by simply deasserting all seven control signals in the EX, MEM, and WB stages. <br>The datapath with the hardware detection unit and forwarding unit is illustrated below:<img alt=\"hazarddetectionUnit.png\" src=\"https://emujakic.github.io/TechKB/resources/hazarddetectionunit.png\" target=\"_self\"> Control hazards occur when the proper instruction cannot execute in the proper pipeline cycle because the instruction fetched was not the instruction needed. This occurs when a branch instruction changes the control flow of the program, causing the instructions in the pipeline to be invalid. Control hazards generally occur less frequently than data hazards. Dealing with control hazards by stalling the pipeline until the branch is complete is far too costly. Control hazards are almost always addressed with prediction. Some common prediction schemes include: Assume branch not taken: This prediction scheme always assumes that the branch will not be taken, and therefore, continues execution down the sequential instruction stream. If the prediction is wrong, the pipeline must be flushed, and execution continues down the branch target. To discard instructions in the pipeline, we simply change the original control values to zero for the IF, ID, and EX pipeline stages. This forces a NOP instruction in each stage. To flush the IF stage, we add a control line called IF.Flush, which clears the contents of the IF/ID pipeline register when asserted.\nWe can reduce the cost of a misprediction by moving the conditional branch execution to an earlier stage in the pipeline. This requires us to move the computation of the branch target address and the outcome of the branch decision. We can move the address calculation from the EX stage to the ID stage, since the PC value and immediate field are both available. We just need to provide another adder in the ID stage to perform the computation.\nMoving the branch decision computation is considerably more difficult. Equality can be evaluated by simply XORing the two registers read during the ID stage. Though, if a branch is dependent on a result that is still in the pipeline, additional forwarding and hazard detection hardware will be required. <br><a data-href=\"Dynamic Branch Prediction\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Dynamic Branch Prediction</a>: This prediction scheme utilizes runtime information to make more accurate predictions about branch outcomes. One approach is to look up the address of the instruction to see if the branch was taken the last time the instruction was executed. This approach can be implemented with a branch prediction buffer, or branch history table. A branch prediction buffer is a small memory indexed by the lower portion of the address of the branch instruction. The memory contains a bit signifying whether the branch was last taken or not. If the prediction is incorrect, the bit is inverted and stored again. This is called a 1-bit prediction scheme. This scheme can be improved by using more bits. A 2-bit scheme only inverts the bit when a prediction is wrong twice. <br>The 2-bit dynamic prediction scheme only uses information about a particular branch to make its prediction.<a data-tooltip-position=\"top\" aria-label=\"Correlating Predictor\" data-href=\"Correlating Predictor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Correlating Predictors</a>, on the other hand, make use of both local and global behavior of recently executed branches for its predictions. A typical correlating predictor might have two 2-bit predictors for each branch, with the choice between predictors being conditioned on whether the last executed branch was taken or not.\n<br><a data-tooltip-position=\"top\" aria-label=\"Tournament Branch Predictor\" data-href=\"Tournament Branch Predictor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Tournament Branch Predictors</a> use multiple predictors, tracking, for each branch, which predictor is the most accurate. Exceptions and interrupts are events, other than branches, which change the sequential flow of instruction execution. They were initially created to handle unexpected events from within the processor. We use the term exception to refer to any unexpected change in control flow, while the term interrupt will be used only when the event is externally caused. Many architectures do not distinguish between exceptions and interrupts.\nDetecting and handling exceptions is often on the critical timing path of the processor, which determines the minimum possible clock cycle time. The basic action that the processor must perform when handling an exception is to save the address of the current instruction in the supervisor exception cause register (SEPC) and then transfer control to the operating system at some specified address. The operating system can then take some action, which may involve proving some service to the user application, or stopping the execution of the program and reporting an error. If the OS decides to continue execution of the program, it uses the SEPC to determine where to restart execution.\nFor the OS to handle an exception, it must know the reason for the exception, as well as the instruction that caused it. The method RISC-V uses is to include a register, called the Supervisor Exception Cause Register (SCAUSE), which includes a field that indicates the reason for the exception.\nAnother method is to use vectored interrupts, where the address to which control is transferred to is determined by the cause of the exception, possible added to a base register. Therefore, the OS knows the reason for the exception based off the address at which it is initiated. When the exception is not vectored, a single entry-point for all exceptions can be used, and the OS decodes the status register to determine the cause. To add hardware support for exceptions to our RISC-V implementation, we need additional registers and control signals. We need two additional registers: SEPC: A 64-bit register used to hold the address of the affected instruction.\nSCAUSE: A 64-bit register used to record the cause of the exception. A pipelined implementation treats exceptions as another form of control hazard. If an exception is detected, we must flush the instructions that follow the faulting instruction, and begin fetching instructions from the new address. A new control signal, ID.Flush is OR-ed with the stall signal from the hazard detection unit to flush during ID. To flush the instruction in the EX stage, a new signal, EX.Flush causes new multiplexers to zero the control lines.\nTo branch to the exception address, we simply add an input to the PC multiplexer that branches to the fixed address.\n<br>The following figure illustrates the new datapath:<img alt=\"riscVExceptions.png\" src=\"https://emujakic.github.io/TechKB/resources/riscvexceptions.png\" target=\"_self\">\nThe final step is to save the address of the faulting instruction in the SEPC register.\nWhen there are multiple instructions in the pipeline, it is necessary to associate an exception with the appropriate instruction. Moreover, multiple exceptions can occur in a single clock cycle. In RISC-V implementations, the hardware sorts exceptions so that the earliest instruction is interrupted. <br>\nPipelining exploits potential parallelism among instructions, called <a data-href=\"Instruction-Level Parallelism\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Instruction-Level Parallelism</a> (ILP). There are two primary ways to increase the degree if ILP: the first is to increase the depth of the pipeline. Another approach, is to replicate the internal components of the computer so that it can handle multiple instructions per pipeline stage. This technique is called <a data-href=\"Multiple Issue\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Multiple Issue</a>. <br>Launching multiple instructions per stage allows the instruction execution rate to exceed to clock rate, resulting in a CPI (clock cycle per instruction) less than 1. It is sometimes more intuitive to flip the metric to IPC (instructions per clock cycle), which is the <a data-href=\"Reciprocal\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Reciprocal</a> of the CPI.\nThere are two main ways to implement a multiple-issue processor, with the main distinction being the division of work between the hardware and the compiler: Static Multiple Issue: A multiple-issue implementation approach where many decisions are being made at compile time.\nDynamic Multiple Issue: A multiple-issue implementation approach where many decisions are being made at runtime. Two primary responsibilities must be dealt with in a multiple-issue pipeline: Packing instructions into issue slots, which involves determining how many instructions and which instructions can be issued in a given clock cycle.\nDealing with data and control hazards. One of the most important methods for finding and exploiting more ILP is speculation. That is, an approach where the compiler or processor guess the outcome of an instruction to remove it as a dependence in executing other instructions. Speculation may be wrong, so any speculation mechanism will require a back-out capability which undoes the effect of the speculated instructions. In software speculation, the compiler usually inserts additional instructions that check the validity of the speculation and provide a fix-up routine to use when the speculation is wrong.\nIn hardware speculation, the processor usually speculative result until it knows they are no longer speculative. If the speculation was correct, the instructions are completed by allowing the contents of the buffers to be written to registers or memory. If the speculation is incorrect, the hardware flushes the buffers and re-executed the correct instruction sequence. Speculation can also incur exceptions that were otherwise not present. In compiler-based speculation, such problems are avoided by adding special speculation support that allows such exceptions to be ignored until it is clear that they must occur. In hardware-based speculation exceptions are simply buffered until it is clear that the instruction causing them is no longer speculative. At that point, the exception is promptly raised and handled. <br>\nStatic multiple issue processors use the compiler to assist with packaging instructions and handling hazards. In a static issue processor, you can think of the set on instructions issued in a given clock cycle (issue packet), as one large instruction with multiple operations. Static multiple-issue processors typically restrict what mix of instructions can be initiated in a given clock cycle. The approach is called the <a data-href=\"Very Long Instruction Word\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Very Long Instruction Word</a> (VLIW). If one instruction in an issue packet cannot be used, we must replace it with a NOP. In some processors, the compiler takes full responsibility for removing all hazards, scheduling the code, and inserting NOPs so that the code executes without any needs for hardware hazard detection. In others, the hardware detects data hazards and generates stalls between two issue packets, while requiring that the compiler avoid all dependencies within an instruction packet.\n<br>A compiler technique that can get more performance from loops is <a data-href=\"Loop Unrolling\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Loop Unrolling</a>, where multiple copies of a loop body are made. After unrolling, more potential ILP is made available by overlapping instructions from different iterations. <br>\nDynamic multiple issue processors, known as <a data-href=\"Superscalar Processors\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Superscalar Processors</a>, can decide at runtime how many instructions to issue in a given clock cycle. The compiler still tries to schedule instructions to separate dependencies and thereby improve the instruction issue rate. The main difference between superscalars and VLIW processors is that the code, whether scheduled or not, is guaranteed to execute correctly on superscalars. In some VLIW designs, recompilation is required when moving across different processor models.\nMany superscalars extend dynamic issue decisions to include dynamic pipeline scheduling. Dynamic pipeline scheduling provides hardware support for the reordering of instruction execution to avoid pipeline stalls. In processors which support dynamic pipeline scheduling, the pipeline is divided into three major units: Instruction fetch and issue unit: Fetches instructions, decodes them, and sends each instruction to a corresponding functional unit for execution.\nMultiple functional units: These units execute instructions and contain buffers known as reservation stations, which hold operands and the operation. When all operands are available and the functional unit is ready, the result is computed. This result is then dispatched to any reservation stations waiting for it, as well as to the commit unit.\nCommit Unit: This unit buffers results until it is safe to write them into the register file or memory. The buffer, referred to as the reorder buffer, also supplies operands similarly to forwarding logic in statically scheduled processors. The combination of buffering results in the reservation stations and the reorder buffer provides a form of register renaming. Register renaming is a technique used to eliminate false dependencies between instructions. For example, write-after-read and write-after-write instructions that use the same destination register have a name dependency, but no logical dependency. Register renaming addresses this issue by mapping architectural registers to a larger pool of physical registers, effectively removing the name dependency. When an instruction issues, it is copied to a reservation station for the appropriate functional unit. Any operands that are available in the register file or reorder buffer are also immediately copied into the reservation station. The instruction is buffered until all the operands and the functional unit are available. For the issuing instruction, the register copy of the operand is no longer required, and can be overwritten if needed.\nIf an operand is not in the register file or reorder buffer, it must be being computed by a functional unit. The functional unit that is producing the result is tracked, and when that unit produces the result, it is copied directly into the waiting reservation station. Dynamically scheduled pipelines perform out-of-order execution, since instructions can be executed in a different order than they were fetched. The instruction fetch and decode unit issues instructions in sequential order, which allows dependencies to be tracked, and the commit unit is required to write results to registers and memory in program fetch order. This is called in-order commit.\nAlthough the front-end (fetch and issue) and back-end (commit) of the pipeline run in order, the functional units are free to initiate execution whenever the data they need are available. Dynamic scheduling is often extended by including hardware speculation, especially for branch outcomes. Because the instructions are committed in order, we know whether the branch prediction was correct or not before any instructions from the predicted path are committed.\nOut-of-order execution creates new pipeline hazards, such as a name dependence. Our original pipeline hazard was the result of a true data dependence, a name dependence, on the other hand, occurs when two instructions use the same register or memory location without any flow of data between the instructions. There are two types of name dependencies between an instruction i that proceeds an instruction j in program order: Antidependence: Occurs when instruction j writes a register or memory location that instruction i reads. This is also called a write-after-read (WAR) dependence. The original ordering must be preserved to ensure that i reads the correct value.\nOutput Dependence: Occurs when instructions i and j write the same register or memory location. This is also called a write-after-write (WAW) dependence. The ordering must be preserved so that the value finally written corresponds to instruction j.\nA true data dependence corresponds to a read-after-write dependence. Both pipelining and multiple-issue execution aim to increase peak instruction throughput and attempt to exploit instruction-level parallelism. The downside of dynamic multiple issue and hardware speculation is potential energy inefficiency. Some modern processor designs are not as deeply pipelined or aggressively speculative as its predecessors. This leads to lower overall performance but higher performance per joule. The principle of locality states that programs access a relatively small portion of their address space at any given time. There are two types of locality: Temporal Locality: If an item is referenced, it is likely to be referenced again soon.\nSpatial Locality: If an item is referenced, nearby items are likely to be referenced soon. Memory Hierarchy: A structure consisting of multiple levels of memories, where smaller, faster memories are close to the CPU, and larger, slower memories are farther. The faster memories are smaller because they are more expensive per bit. The minimum unit of information that can be present or not is called a block or a line.\nIf the data requested by the processor is present in the highest level of the hierarchy, this is called a hit. If the data is not found, it is called a miss, and the search continues to lower levels in the hierarchy. The hit rate is the fraction of memory accesses found at a given level. The miss rate, on the other hand, is the fraction of memory accesses not found at a given level.\nHit time is the time to access data at a given level of the hierarchy. The miss penalty is the time to replace a block in the current level with the corresponding block in the lower level. There are four primary technologies used in modern memory hierarchies: Static Random Access Memory (SRAM): Integrated circuits (ICs) that are memory arrays with a single access port that can provide either a read or a write. SRAMs have a fixed access time to any data address, though the read and write access times may differ. <br>Unlike DRAMs, SRAMs don't have to be refreshed. SRAMs typically use six to eight <a data-tooltip-position=\"top\" aria-label=\"Transistor\" data-href=\"Transistor\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">transistors</a> per bit to store data. Dynamic Random Access Memory (DRAM): Integrated circuits that store bits as a charge in a capacitor. A single transistor is then used to access this stored charge for read or writes. Because DRAMs only use a capacitor and transistor for each bit, they are much cheaper and denser than SRAM. The capacitors must be periodically refreshed since the capacitor cannot store the charge indefinitely. To refresh, the value in each cell is simply read and written back. The charge can be kept for several milliseconds. DRAMs use a two-level decoding structure which allow entire rows to be refreshed at a time.\nDRAMs buffer rows for repeated access. The buffer acts like an SRAM: by changing the address, random bits can be accessed in the buffer until the next row access.\n<br>SDRAMs (synchronous DRAMs), are clocked, which eliminates the time needed for the memory and processor to synchronize. SDRAM can transfer bits in bursts without needing to specify additional address bits for each transfer. Instead, the clock signal enables the transfer of successive bits in a burst <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"275\" to=\"279\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a>. This is called double data rate (DDR) DRAM. The name means that data is transferred on both the rising and falling edge of the clock.\nTo sustain DDR bandwidth capabilities, DRAM can be organized to read or write from multiple banks, each with their own row buffer. With multiple banks, there is just one access time and then accesses rotate between the banks. This rotating access scheme is called address interleaving.\nFor PCs and servers, DRAMs come in a DIMM (dual inline memory module) package, where each DIMM typically contains 4-16 DRAMs. Nonvolatile Memory (NVM): Typically implemented using flash memory, which is a type of EEPROM (electronically erasable programmable read-only memory). Writes wear out flash memory bits, to address this issue, the device controller tries to spread the writes evenly across the device. This technique is called wear leveling. Hard Disk Drive (HDD): Commonly referred to as hard drives, HDDs are a mechanical device which store data on a collection of platters. These platters rotate on a spindle at a fixed RPM. The platters are covered with a magnetic recording material on each side. Data is read from and written to the HDD using the read/write head, which is a movable arm containing a small electromagnetic coil.\nEach platter is divided into concentric circles, called tracks. Each track is in turn divided into sectors. Sectors are typically 512 to 4096 bytes in size.\nEach platter spins in conjunction, so that every head is over the same track of every surface. The term cylinder is used to refer to all the tracks under the heads at a given point on all surfaces.\nTo access data, the OS must direct the disk through a three-stage process: the first is to position the head over the proper track. This operation is called a seek, and the time it takes to move the head to the track is the seek time. Once the head is over the correct track, we must wait for the desired sector to rotate under the head. This time is called the rotational latency. The last component is transfer time, which is the time it takes to transfer a block of bits. The transfer time is a function of the sector size, the rotation speed, and the recording density of a track.\nMost disk controllers have a built-in cache that stores sectors as they are passed over. <br>\n<a data-href=\"Cache\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Cache</a>: A small, high-speed memory located close to the CPU that holds frequently or recently accessed data. When the CPU needs data, it first checks the cache. If the data is found, this results in a hit, significantly reducing memory access time. If the data is not found, a miss occurs, and the CPU must fetch the data from the main memory. Once the data is retrieved, it is typically stored in the cache for future reference. <br>A direct-mapped cache is a cache structure where each word can go in exactly one place in the cache. The location is typically assigned based of the address of the word in memory. This type of cache can be thought of as a <a data-href=\"Hash Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hash Table</a> where the hash function is simply a modulo of the number of blocks in the cache. Collisions are handled by simply overwriting the block with the new data. Since multiple addresses can be mapped to one cache location, to know whether the data in the cache corresponds to the requested word, a set of tags are added to the cache. The tags contain the address information of the stored data. These tags only need to store the upper bits of the address, corresponding to the bits not used to index the cache.\nThe index of a cache block, along with the tag contents of the block, uniquely specify the memory address of the word contained in the block. Because the index field is used as an address to reference the cache, and because an -bit field has values, the total number of entries in a cache must be a power of 2. Since words are aligned to multiples of 4 bytes, the least significant two bits of each address specify a byte within a word. Hence, if the words are aligned in memory, the two least significant bits can be ignored when selecting a word in a block.\nWe also need a mechanism to determine whether the data in the cache is valid. The most common method is to use a valid bit, where, if the bit is not set, then the data in the corresponding block is invalid. The total number of bits required for a cache is a function of the cache size and address size, since the cache includes both the data and the tag field.\nLarger block sizes exploit greater spatial locality to lower miss rates. Though, increasing the block size also increases the miss penalty since more data has to be transferred for each miss. A technique called early restart can be used to hide some transfer time of large blocks so that the miss penalty is effectively smaller. Simply resume execution as soon as the requested word of the block is available, rather than wait for the entire block. This is commonly used for instruction accesses.\nA more sophisticated scheme, called requested word first, is to organize the memory so that the requested word is transferred from the memory to the cache first. The remainder of the block is then transferred, starting with the address after the requested word and wrapping around to the beginning of the block. As mentioned earlier, a cache miss occurs when a request for data is not present in the cache and must be fetched from main memory. The control unit must detect a cache miss and process the miss by fetching the requesting the data from memory, or a lower-level cache. Cache miss handling is done in collaboration with the processor control unit and with a separate controller that initiates the memory access and refills the cache. The processing of a cache miss creates a pipeline stall. More sophisticated out-of-order processors can allow execution of instructions while waiting for a cache miss.\nThe steps taken on an instruction cache miss are as follows: Send the original PC value to the memory. Since the program counter is incremented in the first clock cycle, the original PC is the current value minus 4.\nInstruct main memory to perform a read and wait for the memory to complete its access.\nWrite the cache entry, putting the data from memory in the data portion of the entry, writing the upper bits of the address into the tag field, and setting the valid bit.\nRestart the instruction execution at the first step, which will re-fetch the instruction, now finding it in the cache. The control of the cache on a data access, as opposed to an instruction access, is essentially identical. In the case of writes, the data in the cache and main memory can become inconsistent. The simplest way to keep the cache and main memory consistent is to always write the data into both the cache and memory. This is called a write-through scheme. In the case of a write miss, we must first fetch the words of the block from memory, place the block in the cache, then overwrite the word that caused the miss. We could also write the word directly to main memory using the full address.\nA write-through scheme suffers from intolerably poor performance, since every store instruction results in a write to main memory. One solution is to use a write buffer. A write buffer stores the data while they are waiting to be written to memory. When a write to main memory completes, the entry in the write buffer is freed. If the write buffer becomes full while the processor performs a write, the processor must stall until there is space in the write buffer.\nInstead of a write-through scheme, a write-back scheme only writes the new value to the cache, the modified block is then written to the lower level of the hierarchy when it is replaced. CPU time can be divided into the clock cycles that the CPU spends executing the program, and the clock cycles that the CPU spends waiting for memory. We assume that the cost of cache hits are part of the normal CPU execution cycles. Therefore: The memory stall clock cycles come mainly from cache misses. Memory stall cycles can be defined as the sum of the stall cycles from reads and writes. For a write-through scheme, we have two sources of stalls: write misses, which require that we fetch the block before continuing the write, and write buffer stalls, which occur when the write buffer is full when a write happens. Though, in systems with a reasonable write buffer depth and a memory capable of accepting writes at a rate that significantly exceeds the average write frequency in programs, the write buffer stalls will be rare, and we can safely ignore them. In most write-through cache organizations, the read and write miss penalties are the same, therefore, we can combine the reads and writes by using a single miss rate and miss penalty.\nWrite-back schemes also have potential additional stalls arising from the need to write a cache block to memory when the block is replaced. <br>If the processor is made faster, but the memory system is not, then the fraction of CPU time spent on memory stalls will increase due to <a data-href=\"Amdahl's Law\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Amdahl's Law</a>.\nLarger caches can result in longer hit times, and the increase in hit time for a larger cache can dominate the improvement in hit rate, leading to a decrease in performance. A metric, called average memory access time (AMAT) can be used to compare alternative cache designs. Average memory access time is the average time to access memory considering both hits and misses and the frequency of different accesses: Placement schemes dictate which cache locations blocks can be mapped to. A direct mapped cache maps each block to exactly one location in the cache.\n<br>In a fully-associative cache, a block in memory can be associated with any entry in the cache. To find a given block in the cache, a full search must be done. To make this search practical, it is done in parallel with a comparator associated with each cache entry. These comparators significantly increase the hardware cost, making fully-<a href=\"https://emujakic.github.io/TechKB/notes/math/associative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"316\" to=\"327\" origin-text=\"associative\" class=\"internal-link virtual-link-a\">associative</a> caches impractical for larger cache sizes.\nIn a set-associative cache, there are a fixed number of locations where each block can be placed. A set-associative cache with locations for a block is called an -way set-associative cache. An -way set-associative cache consists of a number of sets, each of which contain blocks. Each block is directly mapped to a set, and then all the blocks in the set are searched for a match. All the tags in the selected set can be searched in parallel to decrease the AMAT. This is similar to hash table chaining, where multiple entries can exist at a single hash table index, allowing collisions to be handled by storing multiple records in a linked list or array.\nThe set containing a memory block is given by the block number, modulo the number of sets in the cache. A direct-mapped cache can be thought of as a one-way set-associative cache, while a fully-associative cache with entries is simply an -way set-associative cache. The advantage of increasing the degree of associativity is that it usually decreases the miss rate, while the main disadvantage is a potential increase in hit time. If the total cache size is kept the same, increasing the associativity raises the number of blocks per set, which is the number of simultaneous compares needed to perform the search in parallel.\nIn a direct-mapped cache, only a single comparator is needed. While in an -way set-associative cache, comparators are needed, as well as an -to-1 multiplexer to choose among the potential members of the selected set. The cost of an associative cache are the extra comparators and any delay imposed by having to do the compare and select from among the members of the set.\nWhen a miss occurs in a direct-mapped cache, the requested block can only go in one position, and the block currently occupying that position must be replaced. In an associative cache, there is a choice of which block to replace. The most common scheme is the least recently used (LRU) scheme, where the block replaced is the one that has been unused for the longest time. To close the gap between the fast clock rates of modern processors and the increasingly long time required to access DRAMs, most microprocessors support an additional level of caching. This second-level cache is normally on the same chip and is accessed whenever a miss occurs in the primary cache. This is called multilevel caching. A two-level cache structure allows the primary cache to focus on minimizing hit time to yield a shorter clock cycle, while allowing the secondary cache to focus on minimizing miss rate to reduce the penalty of long memory access times. The secondary cache often uses higher associativity than the primary cache given the focus of reducing miss rates.\nMultilevel caching causes us to differentiate between the local miss rate, which is the miss rate of one level of the cache, and the global miss rate, which is the miss rate of the entire cache structure.\n<br><a data-href=\"Out-of-Order Processors\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Out-of-Order Processors</a> execute instructions during the miss penalty. Therefore, instead of miss rates, we use misses per instruction as the primary performance metric. Standard algorithmic analysis frequently ignores the impact of the memory hierarchy. Given the importance of the memory hierarchy to program performance, many software optimizations were invented that can dramatically improve performance by reusing data within the cache and hence lower miss rates. When dealing with arrays, we can get good memory performance if we store the array in memory so that accesses to the array are sequential in memory. Storing the arrays row-by-row is called row major order, while storing arrays column-by-column is called column major order.\nThough, neither row major nor column major order are optimal when we are dealing with multiple arrays where some are accessed by rows and some by columns. Instead of operating on entire rows or columns of an array, blocked algorithms operate on sub-matrices or blocks. The goal is to maximize accesses to the data loaded into the cache before the data are replaced. Blocking can also be used to improve register allocation. By taking a small block size, such that the block can fit in registers, we can minimize the number of loads and stores in the program. It is crucial that the memory hierarchy of a system is dependable. As mentioned in chapter One, the one great idea for dependability is redundancy. We'll assume there is a specification of proper service. Users can then see a system alternating between two states of delivered service with respect to the specification: Service Accomplishment: The service is delivered as specified.\nService Interruption: The delivered service is different from the specified service. Transitions from state 1 to state 2 are caused by failures, and transitions from state 2 to state 1 are restorations. Failures can be transient or permanent.\n<br>Reliability is a measure of the continuous service accomplishment. Hence, <a data-tooltip-position=\"top\" aria-label=\"Mean\" data-href=\"Mean\" href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">mean</a> time to failure (MTTF) is a reliability measure. A related measure, called the annual failure rate (AFR) is simply the percentage of devices that are expected to fail in a year given the MTTF.\n<br>Availability is a measure of service accomplishment with respect to the alternation between the two states of accomplishment and interruption. Service interruption is measured as <a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"4\" origin-text=\"mean\" class=\"internal-link virtual-link-a\">mean</a> time to repair (MTTR). The mean time between failures (MTBF) is simply the sum of . Therefore, availability is statistically quantified as: One shorthand notation for availability is to quote the number of nines of availability. This refers to the fraction of time a system is operational and can be represented as follows: Two nines (99%): 3.65 days of repair/year.\nThree nines (99.9%): 526 minutes of repair/year.\nFour nines (99.99%): 52.6 minutes of repair/year.\nFive nines (99.999%): 5.26 minutes of repair/year. To increase the MTTF, you can improve the quality of the components or design a system that can continue to operate in the presence of failed components. Hence, we need to differentiate between the failure of the system, which is called a failure, and the failure of a component, which is called a fault. There are three ways to improve the MTTF: Fault Avoidance: Preventing fault occurrence by construction.\nFault Tolerance: Using redundancy to allow service to continue despite the presence of faults.\nFault Forecasting: Predicting faults before they occur, allowing the component to be replaced before it faults. <br>\nThe <a data-href=\"Hamming Distance\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hamming Distance</a> between two bit patterns is just the minimum number of bits that are different between any two bit patterns. A bit pattern has even parity if the number of 1s is even, otherwise, it has odd parity. When a word is written into memory, its parity bit is also written, where a 1 denotes odd parity, and a 0 denotes even parity. That way, when a word is read out, its parity can be calculated and compared to its stored parity to determine if an error has occurred. A parity bit can only detect errors, not correct them. Furthermore, a parity bit can only detect an odd number of errors, since any even number of errors will result in the original parity. <br>If we used a code that had a minimum distance of 3, then any single bit error would be closer to the correct pattern than any other valid pattern. The <a data-href=\"Hamming Error Correction Code\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hamming Error Correction Code</a> (ECC) uses extra parity bits to allow the position identification of a single error. The steps to calculate the Hamming ECC are: Number the bits, starting with the leftmost bit as position 1.\nMark all bit positions that are powers of 2 as parity bits (e.g., positions 1, 2, 4, 8, ...).\nAll other bit positions are used for data bits.\nThe position of the parity bit determines the sequence of data bits that it checks: Bit 1 checks every bit where the rightmost bit of the address is 1 (i.e., odd-numbered positions).\nBit 2 checks bits in positions where the second rightmost bit is 1 (i.e., positions 2, 3, 6, 7, ...).\nBit 4 checks bits in positions where the third rightmost bit is 1 (i.e., positions 4-7, 12-15, etc.). Set parity bits to create even parity for each group. <br>Using this code, you can detect and correct any 1-bit error. Though, at the cost of one more bit, we can make the minimum Hamming distance in a code be 4. This enables us to correct single bit errors and detect double-bit errors. To do so, you simply add a parity bit that is calculated over the whole word. This is called the Single Error Correcting/Double Error Detecting (<a data-href=\"SEC/DED\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">SEC/DED</a>) code. The algorithm to correct one error and detect two is just to calculate the parity over the ECC groups as before plus one more over the entire group . Virtual machines are software emulations of physical computer systems. These virtual machines are managed by a hypervisor, or virtual machine monitor (VMM). The VMM is responsible for creating, managing, and executing virtual machines. The underlying hardware platform is called the host, and its resources are shared among the guest VMs. The VMM is responsible for mapping virtual resources to physical resources.\nThe overhead incurred by virtualization depends on the workload. User-level processor-bound applications have zero virtualization overhead, since the OS is rarely invoked. I/O intensive workloads, on the other hand, can result in high virtualization overhead due to the large amounts of system calls and privileged instructions necessary to perform I/O.\nVMMs have the following requirements: Present a software interface to guest software.\nIsolate the state of guests from each other.\nProtect itself guest software.\nControl access to privileged state, I/O, exceptions, and interrupts.\nGuest software should behave exactly as if it were running on the native hardware, excluding performance related behavior or limitations.\nGuest software should not be able to change the allocation of real system resources directly. The VMM must be at a higher privilege level than the guest VM, which generally runs in user mode. The basic system requirements necessary to support VMMs are: At least two processor modes: system and user.\nA privileged subset of instructions that is available only in system mode, resulting in a trap if executed in user mode. All system resources must be controllable from just these instructions. An ISA is considered virutalizable if it allows the VM to execute directly on the hardware. Examples include IBM 370 and RISC-V.\nSince the guest OS cannot directly interact with physical resources, when it attempts to modify or access information related to hardware resources using a privileged instruction, it will trap to the VMM. The VMM is then responsible for affecting the appropriate changes to the corresponding physical resources. <br>\n<a data-href=\"Virtual Memory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Virtual Memory</a> is a technique where main memory acts as a cache for secondary storage. Main memory need only contain the active portions of many programs, thus, exploiting the principle of locality. <br>A program is compiled into its own address space, a <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"4\" to=\"9\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of memory locations accessible only to the program. The virtual memory system implements the translation of a program's address space to physical addresses. This translation process enforces protection of a program's address space from other processes.\nA virtual memory block is called a page, and a virtual memory miss is called a page fault.\nThe processor produces a virtual address, which is translated to a physical address, which is can be used to access main memory. This process is called address mapping or address translation.\nVirtual memory also simplifies the loading of a program by providing relocation. Relocation maps the virtual addresses used by a program to different physical addresses before the addresses are used to access memory. This allows us to load the program anywhere in main memory. Today, all virtual memory systems relocate the program as a set of fixed-size blocks (pages), thereby eliminating the need to allocate a program contiguously. In virtual memory, the address is broken into a virtual page number and a page offset. The physical page number constitutes the upper portion of the physical address, while the page offset constitutes the lower portion. The number of bits in the page offset determine the page size. The number of pages addressable with the virtual address can be different from the number of pages addressable with the physical address. Having a larger number of virtual pages than physical pages is the basis for the illusion of a larger amount of virtual memory. A page fault to disk incurs an enormous miss penalty of millions of clock cycles. This led to several key decisions in designing virtual memory systems: Pages should be large enough to amortize the high access time. Sizes from 4KiB to 64KiB are common today.\nAllowing fully associative placement of pages in memory. This means that virtual pages can be mapped to any physical page.\nPage faults can be handled in software since the overhead will be negligible compared to the disk access time. Additionally, software can afford to use clever algorithms for choosing how to place and replace pages.\nVirtual memory systems use write-back schemes, where modified pages are only written back to secondary storage when they are discarded from memory. To keep track of whether a page has been written to since it was read into memory, a dirty bit is set whenever any page is written to. Therefore, a page only needs to be written back to secondary memory if the dirty bit is set. In virtual memory systems, pages are located using a table that indexes the main memory. This structure is called a page table, and it resides in main memory. A page table is indexed by the virtual page number to discover the corresponding physical page number. Each program has its own page table. To locate the page table in memory, the hardware includes a register, called the page table register, that points to the start of the page table. A valid bit is used in each page table register where, if the bit is not asserted, the page is not present in main memory and a page fault occurs.\nThe operating system is responsible for allocating the physical memory and updating the page table, so that the virtual address spaces of different processes do not collide.\nA range of techniques are used to reduce the amount of storage required for the page table: The simplest technique is to keep a limit register that restricts the size of the page table for a given process. If the virtual page number becomes larger than the contents of the limit register, entries must be added to the page table. This technique allows the page table to grow as a process consumes more space. This technique requires that the address space expand in just one direction.\nAllowing growth in only one direction is not sufficient, since most languages require two areas whose size is expandable: the stack, and the heap. Because of this, it is convenient to divide the page table and let it grow from the highest address down, and the lowest address up. This results in two separate page tables and two separate limits. The high-order bit of an address usually specifies which page table to index. The major disadvantage of this scheme is that it does not work well when the address space is used sparsely, as opposed to a contiguous set of virtual addresses.\nAnother approach is to apply a hashing function to the virtual address so that the page table need only be the size of the number of physical pages in main memory. This is called an inverted page table. This makes the lookup process more complex since we can no longer just index the page table.\nModern systems also allow the page table to be paged itself. This technique enables some critical problems, such as a never-ending series of page faults, and the way these problems are addressed are highly processor-specific. Though, in general, these issues are addressed by placing all the page tables in the address space of the operating system and placing at least some of the page tables for the operating system in a portion of main memory that is physically addressed and is always present.\nMultiple levels of page tables can be used to reduce the total amount of page table storage. This is the solution used by the RISC-V architecture. Address translation happens by first looking in the level 0 table, using the highest order bits of the address. If the address is valid, the next set of high-order bits are used to index the page table indicated by the level 0 entry, and so on. This scheme allows the address space to be used in a sparse fashion, with the primary disadvantage is the added complexity for address translation. The page table, along with the program counter and registers, specifies the state of a process. If we want to allow another process to use the processor, we must save this state. Later, the state is restored, and the process can continue execution. This sequence is called a context switch. The process is considered active when it is in possession of a processor, otherwise, it is inactive.\nWhen a page fault occurs, the operating system must be given control. The transfer is performed using the exception mechanism discussed in chapter 4. Once the OS gets control, it must find the page in secondary memory and decide where to place it in main memory. The OS usually creates space on secondary memory for all the pages of a process when the process is created. This space is called swap space. At that time, it also creates a data structure to record where each virtual page is stored on disk.\nThe OS also creates a data structure that tracks which processes and which virtual addresses use each physical page. When a page fault occurs, if all the pages in main memory are in use, the OS must select a page to replace. Most operating systems follow the least recently used (LRU) replacement scheme. The replaced pages are then written to swap space in secondary memory. Most operating systems approximate LRU by keeping track of which pages have been used recently and which have not. RISC-V computers provide a reference bit, which is set whenever a page is accessed. The OS periodically clears the reference bits and later records them so it can determine which pages were touched during a particular time period. <br>Modern processors include a special cache that keeps track of recently used address translations. This cache is called the <a data-href=\"Translation-Lookaside Buffer\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Translation-Lookaside Buffer</a> (TLB). Each tag entry in the TLB holds a portion of the virtual page number, and each data entry holds a physical page number. Because the TLB is accessed instead of the page table on every reference, the TLB will need to include other status bits, such as the dirty and reference bits.\nTLBs work with multi-level page tables by loading the physical address and protection tags from the last level page table.\nIf we look up the virtual page number in the TLB and get a hit, the physical page number is used to form the address, and the corresponding reference bit is asserted. If the processor is performing a write, the dirty bit is also asserted. If a miss occurs, on the other hand, we must determine whether it is a TLB miss or a page fault. The processor handles a TLB miss by loading the translation from the last-level page table into the TLB and retrying the reference. We will need to select a TLB entry to replace, this includes copying the reference and dirty bits back to the page table entry when we replace an entry.\nHandling a TLB miss or a page fault requires using the exception mechanism to interrupt the running process, transferring control to the OS, and later resuming execution of the interrupted process. The program counter of the instruction that caused the page fault in stored in the SEPC (supervisor exception program counter) register.\nA TLB miss or page fault exception must be asserted by the end of the same clock cycle that the memory access occurs, so that the next clock cycle begins exception handling rather than continuing normal execution.\nBetween the time we begin executing the exception handler in the OS and the time that the OS has saved all the state of the process, the OS is particularly vulnerable. If another exception occurred when we were processing the first exception, the control unit would overwrite the exception link register, making it impossible to return to the instruction that caused the page fault. This can be avoided by providing the ability to enable and disable exceptions. When an exception occurs, the processor can set a bit that disables all other exceptions, this could happen at the same time the supervisor bit is asserted. The processor can then save just enough state to allow it to recover if another exception occurs, specifically, the SEPC register and the supervisor exception cause (SCAUSE) registers, which records the cause of the exception. Once the OS knows the virtual address that caused the page fault, it must: Look up the page table entry using the virtual address and find the location of the referenced page in secondary memory.\nChoose a physical page to replace. If the chosen page is dirty, it must also be written back to secondary memory.\nStart a read to bring the referenced page from secondary memory into the chosen physical page. Page fault exceptions for data accesses are particularly hard to handle since they occur in the middle of instructions, and cannot be completed before handling the instruction. Making instructions restartable, can make handling such exceptions easier. Since in RISC-V architectures each instruction writes only one data item, and this write occurs at the end of the instruction cycle, we can simply prevent the instruction from completing and restart the instruction from the beginning. Some systems use small, fully associative TLBs because a fully associative mapping has a lower miss rate. Furthermore, since the TLB is small, the cost of high associativity is marginal. Other systems use large TLBs with small associativity. Virtual memory and cache systems work together as a hierarchy, so that data cannot be in a cache unless it is present in main memory. The operating system maintains this hierarchy by flushing the contents of any page from the cache when it decides to migrate that page to secondary storage. Simultaneously, the OS modifies the page tables and TLB. A cache that is physically indexed and physically tagged requires that both the cache index and tag are physical addresses rather than virtual addresses. This means that the amount of time required to access memory, assuming a cache hit, must accommodate both a TLB access and a cache access. Alternatively, the processor can index the cache with a completely or partially virtual address. This is called a virtually addressed cache, and it uses tags that are virtual addresses. The single most important function of virtual memory in modern systems is the ability to share a single memory with multiple processes, while providing memory protection among these processes and the OS. This protection mechanism must ensure that processes cannot write outside their own address space. The write access bit in the TLB can protect a page from being written. To enable the OS to implement protection in the virtual memory system, the hardware must provide at least the following three capabilities: Support at least two modes that indicate whether the running process is a user process or system process. System processes are also called supervisor, kernel, or executive processes.\nprovide a portion of the processor state that a user process can read but not write. This state includes the user/supervisor mode bit, the page table pointer, and the TLB.\nProvide mechanisms whereby the processor can go from user mode to supervisor mode, and vice versa. The first direction is typically implemented by a system call exception, implemented as a special instruction (ecall in RISC-V). A system call is an instruction that transfers control from user mode to a dedicated location in supervisor code space, invoking the exception mechanism in the process. As with any exception, the PC (program counter) at the point of the system call is saved in the supervisor exception program counter (SEPC) register, and the processor is set to supervisor mode.\nTo return to user mode from the exception, use the supervisor exception return sret instruction, which resets to user mode and jumps to the address in SEPC. By using these mechanisms and storing the page tables in the OS's address space, the OS can write to the page tables while preventing user processes from changing them. We also want to prevent processes from reading or writing the data of other user processes. Since each process has its own virtual address space, if the OS keeps the page tables organized so that the independent virtual pages map to disjoint physical pages, processes cannot access each other's data. When processes want to share information, the OS must assist them, since this requires changing the page table of the accessing process. The write access bit can be used to restrict the sharing to read-only, and, like the rest of the page table, this can only be changed by the OS.\nThe sharing process would request the OS to create a page table entry for a virtual page in the accessing process's address space that points to the same physical page that the sharing process wants to share. There are three sources of misses in a memory hierarchy: Compulsory Misses: Cache misses caused by the first access to a block that has never been in the cache. They are also referred to as cold-start misses. Compulsory misses can be reduced by increasing the block size.\nCapacity Misses: Cache misses caused when the cache cannot contain all the block needed during execution of a program. Capacity misses can be reduced by increasing the cache size.\nConflict Misses: Cache misses that occur in set-associative or direct-mapped caches when multiple blocks compete for the same set. They are also referred to as collision misses. Conflict misses can be reduced by increasing the associativity of the cache, though, this may slow access time. <br>\n<a data-href=\"Finite-State Machine\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Finite-State Machine</a> (FSM): A sequential logic function consisting of a set of inputs and outputs, a next-state function that maps the current state and the inputs to a new state, and an output function that maps the current state and possibly the inputs to a set of asserted outputs. FSMs are used in control units of CPUs to manage the datapath. The implementation of an FSM usually assumes that any outputs not explicitly asserted are deasserted. Similarly, the control of a datapath makes the same assumption about control signals.\nMultiplexer controls are different, since a multiplexer always selects one of the inputs. Therefore, in an FSM, we must specify the setting of all multiplexer controls that we care about.\n<br>An FSM can be implemented with a temporary register to hold the current state, and a block of combinational logic that determines both the datapath signals to be asserted and the next state. The combinational control logic for an FSM is implemented with either a ROM (<a data-href=\"Read-Only Memory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Read-Only Memory</a>), or a PLA (<a data-href=\"Programmable Logic Array\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Programmable Logic Array</a>).\nThere are two styles of FSMs: Moore Machine: The output depends only on the current state.\nMealy Machine: The output depends on the current state and the input. multicore multiprocessor integrates multiple processing cores onto a single physical chip, typically sharing a common physical address space. Caching shared data in such architectures leads to the cache coherence problem. Since each processor maintains its own cache, it can result in inconsistencies where different processors view the same memory location differently if not properly managed.\nA memory system is coherent if any read of a data item returns the most recently written value of that item. Writes to the same memory location must also be serialized. That is, two writes to the same location by any two processors must appear in the same order by all processors. In a cache coherent multiprocessor, the cache provides both migration and replication of shared data items: Migration: A data item can be moved to a local cache and used there transparently.\nReplication: When shared data are being simultaneously read, the caches make a copy of the data item in the local cache. Supporting migration and replication is critical to performance in accessing shared data, therefore, many multiprocessors introduce a hardware protocol to maintain coherent caches. The most popular cache coherence protocol is snooping. Each cache that has a copy of the data from a block of physical memory also has a copy of the sharing status of the block, but no centralized state is kept. The caches are all accessible via some broadcast medium (e.g., a bus), and all cache controllers monitor (snoop) on the medium to determine whether they have a copy of a block that is requested on a bus or switch access.\nOne method for enforcing coherence is to ensure that a processor has exclusive access to a data item before it writes that item. This is called a write invalidate protocol because it invalidates copies in other caches on a write. This ensures that no other readable or writable copies of an item exist when a write occurs, all other cached copies of the item are invalidated. If two processors attempt to write the same data item simultaneously, one of the writes will win the race, causing the other processor's copy to be invalidated. Therefore, this protocol also enforces write serialization. The block size also plays an important role in cache coherency. Large blocks can cause false sharing, where two unrelated shared variables residing in the same cache block lead to unnecessary cache invalidations. Programmers and compilers should lay out data carefully to avoid false sharing. <br>\n<a data-href=\"RAID\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">RAID</a>: Standing for redundant array of inexpensive/independent disks, RAID is a technology that combines multiple physical secondary storage devices into a single logical unit to improve throughput and data redundancy. The original motivation for RAID was to allow parallel access to secondary storage, thus, improving I/O throughput of a system. The flaw with this argument was that disk arrays could make reliability much worse, since the failure rate of an array of disks is much higher than that of a single disk. The solution was to add redundancy so that the system could cope with disk failures without losing information.\nDependability is the reason for the widespread use of RAID today.\nThere are seven stages of RAID:\n0. RAID 0 (No Redundancy): Spreads data across multiple disks, called striping, without offering any redundancy. Striping allocates logically sequential blocks to separate disks to allow higher I/O performance than a single disk. RAID 1 (Mirroring): Mirrors each disk in the array so that whenever data is written to one disk, it is also written to the corresponding redundant disk for that disk. This RAID level is the most expensive since it requires the most disks.\nRAID 2 (Error Detecting and Correcting Code): Borrows error detection and correction schemes most often used for memories. This level of RAID has fallen into disuse.\nRAID 3 (Bit-Interleaved Parity): The cost of higher availability can be reduced to , where is the number of disks in a protection group. Rather than keeping a complete copy of the original data for each disk, we only need to add enough redundant information so that we can restore the disk content on a failure. Reads or writes go to all disks in the group, with one extra disk to hold the check information in case of a failure. Unlike RAID 1, multiple disks must be read to determine the missing data.\nRAID 4 (Block-Interleaved Parity): This level uses the same ratio of data disks to check disks as RAID 3, though, the parity is stored as blocks and associated with a set of data blocks. In RAID 3, every access went to all disks, however, some applications prefer smaller accesses, allowing independent accesses to occur in parallel. This is the purpose of RAID levels 4-6. Since error detection information in each sector is checked on reads, \"small reads\" to each disk can occur independently as long as the minimum access is one sector. Writes, on the other hand, would demand that all disks be accessed to read the rest of the data needed to calculate the new parity, and then write the new parity to disk. The key insight to reducing this overhead is that the parity is simply a sum of information; by watching what bits change when we write the new information, we need only change the corresponding bits on the parity disk.\nRAID 5 (Distributed Block-Interleaved Parity): One drawback to RAID 4 is that the parity disk must be updated on each write, so the parity disk is the bottleneck for back-to-back writes. RAID 5 addresses this issue by spreading the parity information throughout all the disks. This allows multiple writes to occur simultaneously, as long as the parity blocks are not located on the same disk.\nRAID 6 (P + Q Redundancy): Generalizes parity to have a second calculation over the data and another check disk of information. This second check block allows recovery from a second failure. Thus, the storage overhead is twice that of RAID 5. Some common fallacies regarding the memory hierarchy are: Fallacy: Programmers can ignore the memory hierarchy when writing applications. Programmers can significantly improve the performance of their code if they factor in the behavior of the memory hierarchy in their algorithms. Pitfall: Having less set associativity for a shared cache than the number of cores or threads sharing that cache. Without additional care, a parallel program running on processors or threads can allocate data structures to addresses that would map to the same set of a shared L2 cache. If the cache is at least -way set associative, then these accidental conflicts are hidden by the hardware from the program. If not, performance bugs due to L2 conflict misses can occur. A multicore multiprocessor integrates multiple processing cores onto a single physical chip. Hence, processors are called cores in a multicore chip. These multicore multiprocessors are almost always Shared Memory Processors (SMP), as they usually share a single physical address space. Energy consumption has emerged as a critical issue for both microprocessors and data centers, primarily due to the power wall concept, which highlights how the performance capabilities of new processors are limited by the power consumption and heat generation they produce.\nSome designs support operation in the presence of broken hardware. That is, if a single processor fails, the remaining processors can continue to provide service, hence, improving availability.\nHigh performance can refer to greater throughput for independent tasks, called task-level parallelism. This approach contrasts with running a single job on multiple processors. A program capable of running on multiple processors simultaneously is a parallel processing program. Hardware can be either: Serial: Data is transmitted one bit at a time over a single channel.\nParallel: Multiple data bits are transmitted simultaneously over multiple channels. Software can either be: Sequential: Tasks are executed one after the other in a linear order.\nConcurrent: Multiple tasks can be running simultaneously across multiple processors. The main challenge of the parallel revolution in hardware is making naturally sequential software have high performance on parallel hardware, but also to make concurrent programs have high performance as the number of parallel processors increase. To create an efficient concurrent program, the task must be broken into equal-sized pieces, to ensure that no one processor is doing a bulk of the work while the others remain idle. Another obstacle is the fact that the processors may spend a great deal of time communicating and synchronizing with each other instead of performing meaningful work. Amdahl’s law also reminds us that even small parts of a program must be parallelized if the program is to make good use of many cores.\nThere are two ways to speed-up performance of a concurrent program: Strong Scaling: Speed-up achieved on a multiprocessor without increasing the size of the problem.\nWeak Scaling: Speed-up achieved on a multiprocessor while increasing the size of the problem proportionally to the increase in the number of processors. The memory hierarchy can interfere with the intuitive wisdom about weak scaling being easier than small scaling. If the problem size grows too large relative to the available memory, performance may suffer due to increased latency and cache misses. A conventional uniprocessor has a single instruction stream and a single data stream. A conventional multiprocessor has multiple instruction streams and multiple data streams. These two categories are abbreviated SISD and MIMD respectively. Programmers normally write a single program that runs on all processors of a MIMD computer, relying on conditional statements when different processors should execute distinct sections of code. This style is called single program multiple data (SPMD), but it's just the normal way to program a MIMD computer.\nA single instruction multiple data (SIMD) computer operates on vectors of data. For example, a single SIMD instruction may add 64 numbers by sending 64 data streams to 64 ALUs to form 64 sums in a single clock cycle. The advantages of SIMD are that all parallel execution units are synchronized, and they all respond to a single instruction that stems from a single program counter (PC).\nAlthough, every unit is executing the same instruction, each execution unit has its own address registers, and so each unit can have different data addresses. For parallelism to work in SIMD, there must be a great deal of identically structured data, which is called data-level parallelism: that is, parallelism achieved by performing the same operation on multiple independent data.\nAn older interpretation of SIMD is called a vector architecture. Rather than having 64 ALUs perform 64 additions simultaneously, the vector architectures pipelined the ALU to get good performance at lower cost. The basic philosophy is to collect data elements from memory, put them in order into a large set of registers called vector registers, operate on them sequentially in registers using pipelined execution units, and then write the results to memory. Thus, a vector architecture may have 32 vector registers, each with 64 64-bit elements. RISC-V offers the vector extension V with vector instructions and vector registers. Vector instructions use the same names, but with the prefix v appended.\nPipeline stalls occur less frequently on vector architectures since they are required only once per vector operation, rather than once per vector element.\nAll modern vector computers have vector functional units with multiple parallel pipelines called vector lanes.\nVector instructions have several important properties compared to conventional ISAs, which are called scalar architectures in this context: A single vector instruction specifies a great deal of work, it is equivalent to executing an entire loop. Thus, the instruction fetch and decode bandwidth needed is dramatically reduced.\nBy using a vector instruction, the compiler indicates that the computation of each result in the vector is independent of other results in the same vector, so hardware does not have to check for data hazards within a vector instruction.\nHardware need only check for data hazards between two vector instructions once per vector operand, not once per vector element.\nVector instructions that access memory have a known access pattern. If the vector's elements are all adjacent, then fetching the vector from a set of heavily interleaved memory banks works very well.\nBecause a complete loop is replaced by a vector instruction whose behavior is predetermined, control hazards that would normally arise from the loop branch are non-existent. <br>\n<a data-href=\"Hardware Multithreading\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Hardware Multithreading</a>: Allows multiple threads to share the functional units of a single processor in an overlapping fashion to increase hardware utilization. To permit this sharing, the processor must duplicate the independent state of each thread, such as the register file and program counter. The memory itself is shared through virtual memory mechanisms. The hardware must support the ability to change to a different thread quickly. A thread switch should be much more efficient than a process switch, which typically requires hundreds to thousands of processor cycles, while a thread switch can be instantaneous.\nThere are two main approaches to hardware multithreading: Fine-Grained Multithreading: Switches between threads on each instruction, resulting in interleaved execution of multiple threads. This is typically done in a round-robin fashion, skipping any threads that are currently stalled.\nCoarse-Grained Multithreading: Switches between threads only on expensive stalls, such as last-level cache misses. This change relieves the need to have thread switching be extremely fast. The main drawback of coarse-grained multithreading is that it is limited in its ability to overcome throughput losses, especially from shorter stalls. This limitation arises from the pipelines start-up costs of coarse-grained multithreading: when a stall occurs, the pipeline must be emptied or frozen. The new thread that begins executing after the stall must fill the pipeline before instructions are able to complete. Simultaneous multithreading (SMT) is a variation on hardware multithreading that uses the resources of a multiple-issue, dynamically scheduled pipelined processor to exploit thread-level parallelism while it exploits instruction-level parallelism. The key insight is that multiple-issue processors often have more functional unit parallelism available than most single threads can use. Furthermore, with register renaming and dynamic scheduling, multiple instructions from independent threads can be issued without regard to the dependencies among them; the resolution of the dependencies can be handled by the dynamic scheduling capability. Since SMT relies on the existing dynamic mechanisms, it does not switch resources every cycle. Rather, SMT is always executing instructions from multiple threads, leaving it up to the hardware to associate instruction slots and renamed registers with their proper threads. Given the difficulty of rewriting old programs to run efficiently on parallel hardware, computer designers have attempted to make the task simpler for application developers. One solution was to provide a single physical address space that all processors can share, so that programs need not concern themselves with where their data are, merely that programs may be executed in parallel. Such processors are called shared memory multiprocessors (SMP). In this approach, all variables of a program can be made available at any time to any processor. The alternative is to have a separate address space for each processor that requires that sharing be done explicitly. When the physical address space is common, the hardware typically provides cache coherence to give a consistent view of shared memory. Such systems can run independent jobs in their own virtual address spaces, even if they all share a physical address space. There are two styles of SMPs: Uniform Memory Access (UMA): The latency to a word in memory does not depend on which processor is requesting it.\n<br><a data-href=\"Non-Uniform Memory Access\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Non-Uniform Memory Access</a> (NUMA): Some memory accesses are much faster than others, depending on which processor asks for which word, typically because main memory is divided and attached to different processors or to different memory controllers on the same chip. As processors operating in parallel will typically share data, they also need to coordinate when operating on shared data. This coordination is called synchronization. One approach uses a lock for a shared variable. Only one processor at a time can acquire the lock, and other processors attempting to access the shared data must wait until the original processor unlocks the variable. <br>\n<a data-href=\"OpenMP\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">OpenMP</a>: A parallel programming API, along with a set of compiler directives, environment variables, and runtime library routines that extends standard programming languages. Most C compilers already have support for OpenMP. OpenMP extends C using pragmas, which are just commands to the C preprocessor such as #define. <br>\n<a data-href=\"Graphics Processing Unit\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Graphics Processing Unit</a> (GPU): A processor specialized for graphics processing, designed to render graphics and perform complex calculations in parallel. Some of the main ways that GPUs differ from CPUs are: GPUs are accelerators that supplement a CPU, so they don't need to be able to perform all the tasks of a CPU.\nThe GPU problem sizes are typically hundreds of megabytes to gigabytes, rather than hundreds of gigabytes to terabytes.\nGPUs do not rely on multilevel caches to overcome the long latency to memory, like CPUs do. Instead, GPUs rely on hardware multithreading to hide memory latency. That is, between the time of a memory request and the time that data arrive, the GPU executes hundreds or thousands of threads that are independent of that request.\nGPU memory is thus oriented towards bandwidth rather than latency. There exist special graphics DRAM chips for GPUs that are wider and have higher bandwidth.\nGiven the reliance on many threads to deliver good memory bandwidth, GPUs can accommodate many parallel processors (MIMD) as well as many threads. Hence, each GPU processor is more highly multithreaded than a typical CPU, and they have more processors. Like vector architectures, GPUs only work well with data-level parallel problems. Both styles have gather-scatter data transfers, and GPU processors have even more registers than vector processors. Unlike most vector architectures, GPUs also rely on hardware multithreading within a single multithreaded SIMD processor to hide memory latency.\nA multithreaded SIMD processor is similar to a vector processor, but rather than having many parallel functional units, a multithreaded SIMD processor has just a few functional units that are deeply pipelined. A GPU is a MIMD composed of these multithreaded SIMD processors. <br>\n<a data-href=\"CUDA\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">CUDA</a>: A C-inspired programming language by NVIDIA that enables programmers to write C programs that can execute directly on GPUs, albeit with some restrictions. A CUDA thread is the smallest unit of execution within the CUDA programming model. The hardware can group thousands of CUDA threads together to utilize the various styles of parallelism within a GPU: multithreading, MIMD, SIMD, and instruction-level parallelism. These threads are blocked together and executed in groups of 32 at a time. A multithreaded processor inside a GPU executed these blocks of threads, and a GPU consists of 8-128 of these multithreaded processors. In the NVIDIA Fermi architecture, the Thread Block Scheduler hardware assigns blocks oaf threads to multithreaded SIMD processors. The machine object that the hardware creates, manages, schedules, and executes is a thread of SIMD instructions, which we will call a SIMD thread. It is a traditional thread, though it contains only SIMD instructions. The SIMD Thread Scheduler includes a controller that lets it know which threads of SIMD instructions are ready to run, and then it sends them off to the dispatch unit to be run on the multithreaded SIMD processor. This is identical to a hardware thread scheduler in a traditional multithreaded processor, except it is scheduling threads of SIMD instructions.\nTherefore, GPU hardware has two levels of hardware schedulers: The Thread Block Scheduler that assigns blocks of threads to multithreaded SIMD processors.\nThe SIMD Thread Scheduler within a SIMD processor, which schedules when SIMD threads should run.' The SIMD instructions of these threads are 32 wide, so each thread of SIMD instructions would compute 32 of the elements of the computation. Since the thread consists of SIMD instructions, the SIMD processor must have parallel functional units, called SIMD Lanes, to perform the operation.\nThe on-chip memory local to each multithreaded SIMD processor is called local memory. It is shared by the SIMD lanes within the processor, but not between the distinct multithreaded SIMD processors. An off-chip DRAM, called GPU memory is shared by the whole GPU and all thread blocks. Rather than use large caches to contain the working set of an application, GPUs typically use smaller streaming caches and rely on the extensive multithreading of threads of SIMD instructions to hide the long DRAM memory latency. Thus, the chip area used for caches in system processors is spent instead on computing resources and on the large number of registers to hold the state of the many threads of SIMD instructions. The latest GPUs and vector processors have added caches to reduce demands on GPU memory and accelerate accesses for the few variables whose latency cannot be hidden by multithreading. <br>\nThe combination of the slowdown of Moore's Law, the end of Dennard scaling, and the practical limitations on multicore performance due to Amdahl's Law has shifted the focus of computer architects towards creating domain-specific architectures (DSAs). DSAs do only a narrow <a href=\"https://emujakic.github.io/TechKB/notes/math/range.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"24\" to=\"29\" origin-text=\"range\" class=\"internal-link virtual-link-a\">range</a> of tasks, but they do them extremely well. DSAs follow five principles: Use dedicated memories to minimize the distance over which data are moved. The compiler writers and programmers of DSAs understand their domain, so there is no need for hardware to try to move data for them. Instead, data movement is reduced with software-controlled memories tailored for specific functions within the domain.\nInvest the resources saved from dropping advanced micro-architectural optimizations into more arithmetic units or bigger memories. Resource-intensive optimizations include out-of-order execution, speculation, multithreading, multiprocessing, pre-fetching, and multilevel caches.\nUse the easiest form of parallelism that matches the domain. Target domains almost always have inherent parallelism. The goal is to design the DSA around the natural granularity of the parallelism of the domain and expose that parallelism simply in the programming model.\nReduce data size and type to the simplest required for the domain. Applications in many domains are memory-bound, so you can increase the effective memory bandwidth and on-chip memory utilization by using narrower data types.\n<br>Use a domain-specific programming language to port code to the DSA. Examples include Halide for vision processing and TensorFlow for <a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a>. <br>Examples of domains that have been accelerated via DSAs include graphics, bioinformatics, image processing, simulation, and <a data-href=\"Artificial Intelligence\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Artificial Intelligence</a> (AI). <br>Google's tensor processing unit (TPU), called the TPUv1, is an example of a DSA made for computing <a data-tooltip-position=\"top\" aria-label=\"Neural Network\" data-href=\"Neural Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Deep Neural Networks</a> (DNNs). The alternative to sharing a common address space is for the processors to each have their own private physical address space. This alternative multiprocessor must communicate using explicit message passing. Providing the system has routines to send and receive messages, coordination is built-in with message passing, since one processor knows when a message is sent, and the receiving processor knows when a message arrives. Additionally, the receiving processor can send an acknowledgement message back to the sender.\nClusters are collections of computers connected via I/O over standard network switches to form a message-passing multiprocessor. Given the separate memories, each node of a cluster runs a distinct copy of the OS. Clusters improve system dependability since it is much easier to replace a computer without bringing down the system in a cluster than in a shared memory multiprocessor.\nA Warehouse-Scale Computer (WSC) is essentially a large cluster, though, their architecture and operation are more sophisticated. These computers require the construction of new buildings, as well electrical, networking, and cooling infrastructure. Multicore chips require on-chip networks to connect cores together, and clusters require local area networks (LANs) to connect nodes together. Network costs include the number of switches, the number of links on a switch to connect to the network, the width (in bits) per link, and length of the links when the network is mapped into silicon.\nNetwork performance includes the latency on an unloaded network to send and receive messages, the throughput in terms of the maximum number of messages that can be transmitted in a given time period, delays caused by contention, and variable performance depending on the pattern of communication.\nFault tolerance is also an obligation of the network, since systems may be required to operate in the presence of broken components. Energy efficiency has also emerged as a significant concern. Networks must be designed to minimize energy consumption without sacrificing performance.\nNetworks are normally drawn as graphs, where each edge of the graph represents a link of the communication network. Links can be bidirectional or unidirectional. All networks consist of switches whose links go to processor-memory nodes and to other switches.\n<br>A simple network topology, called the ring topology is depicted below: <img alt=\"ringTop.png\" src=\"https://emujakic.github.io/TechKB/resources/ringtop.png\" target=\"_self\"> Here, processor-memory node is represented as a black square, with switches depicted as blue circles. Since some nodes are not directly connected, some messages will have to hop along intermediate nodes until they arrive at their destination. Unlike a bus, a ring is capable of many simultaneous transfers. Because there are numerous topologies to choose from, the following performance metrics can be used to compare each design: Total network bandwidth is the bandwidth of each link, multiplied by the number of links. This represents the peak bandwidth. For a ring network with processors, the total network bandwidth is times the bandwidth of one link. For a bus network, the total network bandwidth is simply the bandwidth of the bus.\nThe bisection bandwidth is calculated by dividing the network into two halves. Then you sum the bandwidth of the links that cross the imaginary dividing line. The bisection bandwidth of a ring is twice the link bandwidth. Since some networks are not symmetric, the choice of where to draw the line is to choose a division that yields the most pessimistic network performance. A fully-connected network is at the other extreme from a ring topology. Here, every processor has a bidirectional link to every other processor. The total network bandwidth is , and the bisection bandwidth is . The tremendous improvement in performance of fully-connected networks is compensated by its tremendous increase in cost. This consequence has inspired engineers to invent new topologies that are between the cost of rings and the performance of fully-connected networks. An alternative to placing a processor at every node in a network is to leave only the switch at some of these nodes. The switches are smaller than processor-memory nodes, and thus, may be packed more densely. Such networks are called multistage networks. <br>A crossbar network is a type of multistage network where any node can communicate with any other node in one pass through the network. A crossbar network is depicted below:<img alt=\"crossbarNetwork.png\" src=\"https://emujakic.github.io/TechKB/resources/crossbarnetwork.png\" target=\"_self\" style=\"width: 400px; max-width: 100%;\"> Additional practical considerations in the construction of a network include the distance of each link, which affects the cost of communicating at a high clock rate. Shorter distances also make it easier to assign more wires to the link, and shorter wires are cheaper than longer wires. Another consideration is that the three-dimensional network diagrams must be mapped onto two-dimensional chips.\nThe final concern is energy. Energy concerns may force multicore chips to rely on simple grid topologies.\nThe bottom line is that topologies that seem elegant on paper may be impractical when constructed in silicon or in a data-center. <br>\n<a data-href=\"Ethernet\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ethernet</a> has dominated LAN networking for decades, thus, clusters primarily rely on Ethernet as the cluster interconnect. Today, 10 Gigabits/second Ethernet is standard, with 100 Gigabit/second Ethernet being deployed in data-centers. <br>\nPeripheral Component Interconnect Express (<a data-href=\"PCIe\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">PCIe</a>): A high-speed interface standard used for connecting components such as GPUs and network cards to a computer's motherboard. PCIe connections are made up of lanes, with each lane consisting of two wires: one for sending data, and one for receiving data. PCIe can be used to connect a network interface card (NIC) to a host. To communicate, a NIC must both send and receive messages, often abbreviated as TX (transmit) and RX (receive) respectively. <br>To give a command to the NIC, the processor must be able to address the device and to supply one or more command words. One scheme is called <a data-href=\"Memory-Mapped I/O\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Memory-Mapped I/O</a>. In memory-mapped I/O, portions of the address space are assigned to I/O devices and all subsequent reads and writes to that address region are forwarded over PCIe to that device. At boot time, PCIe devices can request to be assigned an address region of a specified length.\nUser programs are not permitted to issue I/O operations directly because the OS does not provide access to the address space assigned to I/O devices. <br>While the processor could transfer the data from user space into the I/O space by itself, the overhead of such operations could be intolerable. Thus, computer designers invented a mechanism, called <a data-href=\"Direct Memory Access\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Direct Memory Access</a> (DMA), for offloading the processor and having the device controller transfer directly to or from memory. To notify the OS that a transfer is complete, the DMA sends an I/O interrupt. An I/O interrupt is just like the exceptions from Chapters 4 and 5, with two distinctions: An I/O interrupt is asynchronous with respect to the instruction execution. That is, the interrupt is not associated with any instructions and does not prevent the instruction completion. The control unit needs only to check for a pending I/O interrupt at the time it starts a new instruction.\nIn addition to the fact that an I/O interrupt has occurred, we would like to convey further information, such as the identity of the device that generated the interrupt. Furthermore, the interrupts represent devices that may have different priorities and whose interrupt requests have different urgencies associated with them. To communicate information to the processor, such as the identity of the interrupting device, a system can use either vectored interrupts or an exception identification register, called the supervisor exception cause (SCAUSE) register in RISC-V. When the processor recognizes the interrupt, the device can send either the vector address or a status field to place in the Cause register. When the OS gets control, it knows the identity of the device that caused the interrupt and can immediately interrogate the device. The interrupt mechanism relieves the processor of the need to constantly check the device. The operating system (OS) acts as the interface between the hardware, and the program that requests I/O. The networking responsibilities of the OS arise from three characteristics of networks: Multiple programs using the processor to share the network.\n<br>Networks often use interrupts to communicate information about the operations. Since interrupts cause a transfer to kernel <a href=\"https://emujakic.github.io/TechKB/notes/math/mode.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"123\" to=\"127\" origin-text=\"mode\" class=\"internal-link virtual-link-a\">mode</a>, they must be handled by the OS.\nThe low-level control of a network is complex, because it requires managing a set of concurrent events and because the requirements for correct device control are often very detailed. These three characteristics lead to several functions the OS must provide: The OS guarantees that a user's program accesses only the portions of I/O device to which the user has rights.\nThe OS provides abstractions for accessing devices by supplying routines that handle low-level device operations.\nThe OS handles the interrupts generated by I/O devices, just as it handles exceptions generated by programs.\nThe OS tries to provide equitable access to the shared I/O resources, as well as schedules accesses to enhance system throughput. The software inside the OS that interfaces to a specific I/O device is called a device driver. The importance of networking in clusters means it is certainly worthwhile to try to improve network performance. Starting with software optimizations: The zero-copy optimization allows the DMA engine to get the message directly from the user program data space during transmission and be placed where the user wants it when the message is received, rather than pass through the intermediary buffers in the OS along the way.\nA second software optimization is to cut out the OS almost entirely by moving the communication into the user address space. By not invoking the operating system and not causing a context switch, we can considerably reduce the software overhead.\nA third optimization would be to drop interrupts. One reason is that modern processors often go into low-power mode while waiting for an interrupt, and it takes time to come out of low-power mode to service the interrupt, which increases latency. The alternative to interrupts is for the processor to periodically check status bits to see if an I/O operation is complete, which is called polling. Hardware optimizations include: <br>One potential target for improvement is in calculating the values of the fields of the Ethernet packet. The 48-bit Ethernet address, called the Media Access Control (MAC) address, is a unique number assigned to each Ethernet NIC. To improve performance, the MAC chip, actually just a portion of the <a data-tooltip-position=\"top\" aria-label=\"Field-Programmable Gate Array\" data-href=\"Field-Programmable Gate Array\" href=\"https://emujakic.github.io/TechKB/textbooks/field-programmable-gate-array.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">FPGA</a> on the NIC, calculates the value for the preamble fields and the CRC field. The driver is left with placing the MAC destination address, MAC source address, message type, the data payload, and padding if needed. Even the least expensive Ethernet NICs do CRC calculation in hardware today.\nAnother hardware optimization improves the performance of the NIC with respect to the memory hierarchy. Data Direct I/O (DDIO) enables the use of up to 10% of the last-level cache as a fast scratchpad for the DMA engine. Data are copied directly into the last-level cache rather than to DRAM by the DMA engine, and only written to DRAM upon eviction from the cache. This optimization improves latency and bandwidth. DDIO offers similar benefits to those of a write-back cache versus a write-through cache. <br>\nWhile <a data-href=\"Ethernet\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Ethernet</a> is the foundation of cluster communication, clusters commonly use higher-level protocols for reliable communication. The Transmission Control Protocol and Internet Protocol (<a data-href=\"TCP/IP\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">TCP/IP</a>), although intended for planet-wide communication, is often used inside a warehouse-scale computer, due in part to its dependability. Benchmarks are standardized tests used to evaluate the performance of a computer system. A typical rule is that you can't change the benchmark, including the source code and data sets. Furthermore, the benchmark has a single proper answer. A common exception is to be able to increase the size of the problem so that you can run the benchmark on systems with different numbers of processors. That is, many benchmarks permit weak scaling, rather than require strong scaling. The downside of such restrictions is that innovation is chiefly limited to the architecture and compiler. Better data structures, algorithms, programming languages, and so on often cannot be used. While these guidelines are understandable when the foundations of computing are relatively stable, they are undesirable during a programming revolution. Researchers at the University of California at Berkeley identified 13 design patterns that they claim will be part of applications of the future. Examples are sparse matrices, structured grids, finite-state machines, map reduce, and graph traversal. By keeping these definitions at a high level, they hope to encourage innovations at all levels of the system. Some common parallel benchmarks include: Linpack: A collection of linear algebra routines, and the routines for performing Gaussian elimination. Linpack allows weak scaling.\nSPECrate: A throughput metric based on the SPEC CPU benchmarks. Rather than report performance of the individual programs, SPECrate runs many copies of the program simultaneously. Thus, it measures task-level parallelism. Performance models are computational frameworks used to analyze the performance characteristics of systems. The 3Cs for cache performance is an example of a performance model. To find such a model for parallel computers, we can start with small kernels, such as the 13 Berkeley design patterns. Floating-point is a popular data type to use for such kernels. Hence, peak floating-point performance is a limit on the speed of such kernels on a given computer. For multicore chips, peak floating-point performance is the collective peak performance of all cores on the chip.\nThe demands on the memory system can be estimated by dividing this peak floating-point performance by the average number of floating-point operations per byte accessed: <br>The ration of floating-point operations per byte of memory accessed is called the arithmetic intensity. The figure below illustrates the arithmetic intensity of several of the Berkeley design patterns:<img alt=\"designPatternsAI.png\" src=\"https://emujakic.github.io/TechKB/resources/designpatternsai.png\" target=\"_self\"> The roofline model is a simple model which ties floating-point performance, arithmetic intensity, and memory performance together in a 2D graph. The horizontal axis is arithmetic intensity, and the vertical axis is floating-point performance. The electronics inside a computer are digital. Digital electronics operate at two voltage levels: a high and low voltage. Rather than refer to voltage levels, we talk about signals that are either logically true (1), or are asserted; or signals that are logically false (0), or are deasserted.\nLogic blocks without any memory are called combinational logic. The output of a combinational block depends only on the current input.\nIn blocks with memory, the outputs can depend on the inputs, as well as the current values stored in memory, which is called the state of the block. Such blocks are called sequential logic. <br>\n<a data-href=\"Truth Table\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Truth Table</a>: A table used in digital logic to represent the output values of a logical expression (or block) based on all possible combinations of input values. Since combinational logic contains no memory, it can be completely specified by a truth table. For a logic block with inputs, there are entries in the truth tables, corresponding to each possible combination of input values. <br>\n<a data-href=\"Boolean Algebra\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Boolean Algebra</a>: A branch of mathematics that deals with Boolean variables: variables that can be either true (1) or false (0). The main operations in Boolean algebra are: OR (+): A binary operator which returns 1 if either operand is 1. The OR operation is also called a logical sum.\nAND (): A binary operator which returns a 1 only if both of its operands are 1. The AND operator is also called a logical product.\nNOT (): A unary operator which returns the inverse of its operand. If the input is a 1, the result is a 0, and vice versa. There are several laws of Boolean algebra, including: Identity Laws: and .\nDomination Laws: and .\nInverse Laws: and .\n<br><a data-tooltip-position=\"top\" aria-label=\"Commutative Property\" data-href=\"Commutative Property\" href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Commutative</a> Laws: and .\nDistributive Laws: and . <br>In addition, <a data-href=\"De Morgan's Laws\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">De Morgan's Laws</a> are useful for relating AND and OR operations through negation: First Law: Second Law: <br>\n<a data-href=\"Verilog\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Verilog</a>: A hardware description language (HDL) used to model, design, and simulate electronic systems, especially digital circuits. Logic blocks are built from Logic Gates]]** that implement basic logic functions. <br>An AND gate implements the AND function, and an OR gate implements the OR function. Since both AND and OR are <a href=\"https://emujakic.github.io/TechKB/notes/math/commutative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"110\" to=\"121\" origin-text=\"commutative\" class=\"internal-link virtual-link-a\">commutative</a> and <a href=\"https://emujakic.github.io/TechKB/notes/math/associative-property.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"126\" to=\"137\" origin-text=\"associative\" class=\"internal-link virtual-link-a\">associative</a>, they both can have multiple inputs, with the output equivalent to the AND or OR of all the inputs. The logical function NOT is implemented with an inverter with a single input and output. Rather than drawing inverters explicitly, a common practice is to add bubbles to the inputs or outputs of a gate to cause the value on that line to be inverted.\n<br>The standard symbols for an AND gate, OR gate, and an inverter is shown below from left to right:<img alt=\"gates.png\" src=\"https://emujakic.github.io/TechKB/resources/gates.png\" target=\"_self\">\nAll possible logic functions can be constructed with only a single gate type, if that gate is inverting. The most common inverting gates are called NOR and NAND gates, and they correspond to inverted OR and AND gates, respectively. Such gates are called universal, since any logic function can be built using this one gate type. One common logic block used when building larger components is a decoder. The most common type of decoder has an -bit input and outputs, where only one output is asserted for each input combination. This decoder translates the -bit input into a signal that corresponds to the binary value of the -bit input. The outputs are usually numbered such that if the value of the input is , then Out will be asserted and all other outputs will be deasserted.\nThe inverse of a decoder is an encoder, which takes inputs and produces an -bit output. Another basic logic function is the multiplexer. A multiplexer selects its output from one of its many inputs according to a control value. Multiplexers can be created with an arbitrary number of data inputs. If there are data inputs, there will need to be control values. In this case, the multiplexer consists of three parts: A decoder that generates signals, each indicating a different input value.\nAn array of AND gates, each combining one of the inputs with a signal from the decoder.\nA single large OR gate that incorporates the outputs of the AND gate. We can represent the logic function of a two-input multiplexer as: To associate the inputs with control values, we often label the data inputs numerically (i.e., from 0 to -1) and interpret the data selector inputs as a binary number. Any logic function can be written in a canonical form, where every input is either a true or complemented variable and there are only two levels of gates: one being AND and the other OR, with a possible inversion on the final output. Such a representation is called a two-level representation, and there are two forms: Sum of Products: A logical sum (OR) of products (terms using the AND operator). A sum of products is the equivalent of a function in disjunctive normal form. For example: Product of Sums: A logical product (AND) of sums (terms using the OR operator). A product of sums is the equivalent of a function in conjunctive normal form. For example: We will use the sum-of-products form in the rest of this appendix. To construct the equivalent sum-of-products for a logic function, you can use the function's truth table. Every truth table entry for which the function is true corresponds to a product term. The product term consists of a logical product of all the inputs or their complements, depending on whether the entry in the truth table has a 0 or 1 corresponding to this variable. The logic function is then the logical sum of the product terms where the function is true. This representation corresponds to a common structured-logic implementation called a programmable logic array (PLA). <br>\n<a data-href=\"Programmable Logic Array\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Programmable Logic Array</a>: Has a set of inputs and corresponding input complements, and two stages of logic. The stages are a programmable AND plane and a programmable OR plane. Inputs can be combined in the AND plane to create product terms (minterms). These terms can then be summed in the OR plane to form the final outputs. The total size of a PLA is equal to the sum of the size of the AND plane and the size of the OR plane. The size of the AND plane is the number of inputs times the number of different product terms; the size of the OR plane is the number of outputs times the number of product terms.\nA PLA has two characteristics that make it an efficient way to implement a set of logic functions: Only the truth table entries that produce a true value for at least one output have any logic gates associated with them.\nEach different product term will have only one entry in the PLA, even if the product term is used in multiple outputs. <br>\nAnother form of structured logic that can be used to implement a set of logic functions is a <a data-href=\"Read-Only Memory\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Read-Only Memory</a> (ROM). A ROM is called a memory because it has a set of locations that can be read, though, the data at these locations is often fixed, usually at the time of manufacturing. There are programmable ROMs (PROMs) that can be programmed electronically.\nA ROM has a set of input address lines and a set of outputs. The number of addressable entries in the ROM determines the number of address lines. If the ROM contains addressable entries, called the height, then there are input lines.\nThe number of bits in each addressable entry is equal to the number of output lines and is called the width of the ROM. The total number of bits in the ROM is equal to the height times the width.\nA ROM can encode a collection of logic functions directly from the truth table. If there are functions with inputs, we need a ROM with address lines, with each entry being bits wide. The entries in the input portion of the truth table correspond to the addresses of the entries in the ROM, while the contents of the output portion of the truth table constitute the contents of the ROM.\nA ROM is fully decoded, that is, it contains a full output word for every possible input combination. A PLA, on the other hand, is only partially decoded. As the number of inputs grow, the number of entries in the ROM grow exponentially. In contrast, for most real logic functions, the number of product terms grows much slower, making PLAs generally more efficient for implementing combinational logic functions. For designing logic outside a custom or semi-custom IC, a common choice is a field programmable device. <br>\nOften when implementing combinational logic, there are situations where we don't care about the value of some output, either because another output is true or because a subset of the input combinations determines the values of the outputs. Such situations are called <a data-tooltip-position=\"top\" aria-label=\"Don't Care\" data-href=\"Don't Care\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Don't Cares</a>. Don't cares are denoted as s when they appear in truth tables. There are two types of don't cares: Output Don't Cares: Arise when we don't care about the value of an output for some input combination.\nInput Don't Cares: Arise when an output depends only on a subset of the inputs. <br>Don't cares are critical for logic minimization/optimization of circuits. One tool useful for hand minimization are <a data-tooltip-position=\"top\" aria-label=\"Karnaugh Map\" data-href=\"Karnaugh Map\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Karnaugh Maps</a>. However, manually optimizing complex logic functions with Karnaugh maps is often impractical, which is why automated logic optimization programs are available. Many of the combinational operations to be performed on data have to be done to an entire word (64 bits) of data. Thus, we often want to build an array of logic elements, which we can represent simply by showing that a given operation will happen to an entire collection of inputs. A bus is a collection of data lines that are routed together as a single logical signal. To indicate that a signal is a bus rather than a single 1-bit line, we use a thicker line and typically label their width.\nWhen we show a logic unit whose inputs and outputs are buses, this means that the unit will have to be replicated a sufficient number of times to accommodate the width of the input. Hardware Description Language (HDL): A specialized programming language used to describe the structure, behavior, and design of digital circuits. Today, most digital design of processors and related hardware systems is done using an HDL. HDLs provide an abstract d100escription of the hardware to simulate and debug the design. Additionally, with the use of logic synthesis and hardware compilation tools, this description can be compiled onto the hardware implementation.\nThe two most common HDLs are: <br><a data-href=\"Verilog\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Verilog</a>: Heavily used in industry and is based on the C programming language.\n<br><a data-href=\"VHDL\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">VHDL</a>: A strongly typed language based on Ada. With the arrival of hardware synthesis tools, most designers now used Verilog or VHDL to structurally describe only the datapath, relying on logic synthesis to generate the control from a behavioral description. Additionally, most CAD software provide extensive libraries for standardized parts such as ALUs, multiplexers, etc. We will focus on Verilog for the remainder of this appendix. Verilog can specify both a behavioral and structural definition of a digital system: Behavioral Specification: Describes how a digital system functionally operates.\nStructure Specification: Describes the detailed organization of a digital system, usually using a hierarchical description. There are two primary datatypes in Verilog: A wire specifies a combinational signal.\na reg (register) holds a value, which can vary with time. A reg does not necessarily correspond to an actual register in an implementation, though it often will. A register or wire, named X, that is 32-bits wide is declared as an array: reg[31:0] X or wire 31:0 X, which also sets the index of 0 to designate the least significant bit of the register. We can refer to a contiguous set of bits of a register or wire with the notation [startBit:endBit], where both indices must be constant values. We can also access a single bit with the notation [index]. An array of registers is used for a structure like a register file or memory. Thus, reg[31:0] registerFile[0:31] specifies a variable registerFile that is equivalent to a RISC-V registerfile where register 0 is the first. The possible values for a register or wire in Verilog are: 0 or 1, representing logical false or true.\nX, representing unknown, the initial value given to all registers or disconnected wires.\nZ, representing the high-impedance state for tristate gates. Constant values can be specified as decimal, binary, octal, or hexadecimal numbers. To specify how large a constant field is in bits, you prefix the value with a decimal number specifying a size in bits.\nVerilog also provides the full set of unary and binary operators from C, including arithmetic operators, logical operators, comparison operators, shift operators, and C's ternary operator ?. Additionally, Verilog adds a set of unary logic reduction operators (&amp;, |, ^) that yield a single bit by applying the logical operator to all the bits of an operand.\nA Verilog program is structured as a set of modules, which may represent anything from a collection of logic gates to a complete system. A module specifies its input and output ports, which describe the incoming and outgoing connections of a module. The body of a module consists of: initial constructs, which can initialize reg variables.\nContinuous assignments, which define only combinational logic.\nalways constructs, which can define either sequential or combinational logic.\nInstances of other modules, which are used to implement the module being defined. A continuous assignment, which is indicated with the keyword assign, acts like a combinational logic function: the output is continuously assigned the value, and a change in the input values is reflected immediately in the output value. Wires may only be assigned values with continuous assignments.\nFor more complex structures, assign statements may be awkward or tedious to use. The always block of a module can be used to describe a combinational logic element, although care must be taken. Using an always block allows the inclusion of Verilog control constructs, such as if-then-else or case statements. An always block specifies an optional list of signals, starting with @, on which the block is sensitive. The always block is re-evaluated if any of the listed signals changes value. If the list is omitted, the always block is constantly re-evaluated.\nWhen an always block is used to specify combinational logic, the sensitivity list should include all the input signals. If there are multiple Verilog statements in the always block, they are surrounded by the begin and end keywords.\nReg variables may only be assigned in an always block, using a procedural assignment statement, as opposed to a continuous assignment statement. There are two types of procedural assignments: Blocking Assignment (=): Behaves the same as the assignment operator in C: the right-hand side is evaluated, and the left-hand side is assigned the value. It is completed before the next statement is executed (blocking).\nNonblocking Assignment (&lt;=): All right-hand sides of the assignments in an always block are evaluated, and the assignments are done simultaneously. <br>\n<a data-href=\"Arithmetic Logic Unit\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Arithmetic Logic Unit</a>: A component of a CPU that can perform basic mathematical operations such as addition, subtraction, multiplication, and division. It can also carry out logical operations such as AND, OR, NOT, and XOR. It operates based on control signals from the CPU, which dictate what operation should be performed. Clocks are timing devices used to synchronize the components of a computer. Clocks are needed in sequential logic to determine when an element that contains state should be updated. There are two primary clocking methodologies: Edge-Triggered Clocking: All state changes occur on a clock edge. That is, on either the transition from low to high (rising-edge), or from high to low (falling-edge). We will use edge-triggered clocking in this appendix.\nLevel-Triggered Clocking: All state changes occur based on the level of the clock signal. That is, whether it is a digital low or high. The clock edge acts as a sampling signal, causing the value of the data input to a state element to be sampled and stored in the state element. Using an edge trigger means that the sampling process is nearly instantaneous, eliminating problems that can occur if signals were sampled at slightly different times.\nThe major constraint with synchronous systems is that the signals being sampled must be valid at the clock edge. A signal is valid if it is stable (i.e., not changing), and the value will not change again until the inputs change. Since combinational circuits cannot have feedback, if the inputs to a combinational logic unit are not changed, the outputs will eventually become valid. To ensure that the values written into the state element are valid, the clock must have a long enough period so that all the signals in the combinational logic block stabilize, and then the clock edge samples those values for storage in the state elements.\nSome state elements have explicit write signals, where the element is updated on the clock edge only if the write signal is asserted. Memory elements store state. The output from any memory element depends on both the inputs and the current state. Thus, all logic blocks containing a memory element contain state and are sequential. Many of the combinational operations to be performed on data have to be done to an entire word (64 bits) of data. Thus, we often want to build an array of logic elements, which we can represent simply by showing that a given operation will happen to an entire collection of inputs. A bus is a collection of data lines that are treated as a single logical signal. To indicate that a signal is a bus rather than a single 1-bit line, we use a thicker line and typically label their width.\nWhen we show a logic unit whose inputs and outputs are buses, this means that the unit will have to be replicated a sufficient number of times to accommodate the width of the input.gic blocks containing memory are sequential.\nThe simplest type of memory elements are unclocked. An unclocked latch is the simplest memory element. An S-R latch (set-reset latch), for example, is built from a pair of cross-coupled NOR gates and is depicted below: <br><img alt=\"srLatch.png\" src=\"https://emujakic.github.io/TechKB/resources/srlatch.png\" target=\"_self\">\nThis cross-coupled structure is the basis for more complex memory elements that allow us to store data signals. <br><a data-tooltip-position=\"top\" aria-label=\"Flip Flop\" data-href=\"Flip Flop\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Flip-flops</a> and latches are the simplest memory elements. The difference between them is the point at which the clock causes the state to actually change. In a clocked latch, the state changes whenever the appropriate inputs change and the clock is asserted. In a clocked flip-flop, the state is changed only on a clock edge. Flip-flops are often built from latches.\nA D latch has two inputs and two outputs. The inputs are the data value to be stored , and a clock signal . The outputs are simply the internal state and its complement . When the clock input is asserted, the latch is said to be open, and the value of output becomes the value of input . When the clock input is deasserted, the latch is said to be closed, and the output is whatever value was stored the last time the latch was open. A D latch can be implemented with two additional AND gates to the S-R latch: <br><img alt=\"dlatch.png\" src=\"https://emujakic.github.io/TechKB/resources/dlatch.png\" target=\"_self\" style=\"width: 350px; max-width: 100%;\"> Flip-flops are not transparent: their outputs change only on the clock edge. Flip-flops can be designed to be triggered on the rising edge or falling edge. A falling-edge D flip flop can be constructed from a pair of D latches, as shown in the following figure: <br><img alt=\"dflipFlop.png\" src=\"https://emujakic.github.io/TechKB/resources/dflipflop.png\" target=\"_self\"> The Verilog code for a rising-edge D flip-flop is: module DFF(clock,D,Q,Qbar); input clock, D; output reg Q; output Qbar; assign Qbar= ~ Q; always @(posedge clock) Q=D;\nendmodule Because the input is sampled on the clock edge, it must be valid for a period of time immediately before the clock edge (setup time), and immediately after the clock edge (hold time). Additionally, components have propagation delays, which describes how long it takes for the output of a signal to become valid. Register File: A set of registers that can be read and written by supplying a register number to access. A register file can be implemented with a decoder for each read/write port, and an array of registers built from D flip-flops. Reading a register only requires one signal: the register number to be read. Writes, on the other hand, take three signals: the register to be written, the data to be written, and a clock signal.\nIn an edge-triggered design, if the same register is read and written in the same clock cycle, the value returned from the read will be the value written in an earlier clock cycle. Additional logic is required if we want a read to return the value being currently written. <br>\nLarger amounts of memory are built from either <a data-tooltip-position=\"top\" aria-label=\"SRAM\" data-href=\"SRAM\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">SRAMs</a> or <a data-tooltip-position=\"top\" aria-label=\"DRAM\" data-href=\"DRAM\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">DRAMs</a>. SRAM (Static Random Access Memory): A volatile memory device where each bit is stored using a flip-flop circuit. Generally faster, and more expensive than DRAM.\nDRAM (Dynamic Random Access Memory): A volatile memory device where each bit is stored using a capacitor and transistor. Because capacitors leak charge, DRAMs have to be periodically refreshed. DRAMs are considerably denser than SRAMs, allowing them to store large amounts of data in a small package. Most computers use some form of error-checking code to detect possible data corruption. One simple code is a parity code. In a parity code the number of 1s in a data word is counted, the word has odd parity if the number of 1s is odd and even parity otherwise. When a word is written into memory, its parity bit is also written. If the parity of the memory word and the stored parity do not match, then an error has occurred. A 1-bit parity scheme can only detect odd numbers of errors, since any even number of errors will result in the same parity.\nThere are also error correction codes that can detect and correct errors. Combinational logic systems can be fully described with a truth table since the outputs depend entirely on the inputs. Sequential logic, on the other hand, has state, and thus cannot be represented with truth tables. That is where finite-state machines come into play. <br><a data-href=\"Finite-State Machine\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Finite-State Machine</a> (FSM): A sequential logic function consisting of a set of inputs, a set of outputs, a next-state function that maps the current state and the inputs to a new state, and an output function that maps the current state and possibly the inputs to a set of asserted outputs.\nThe set of states corresponds to all the possible values of the internal storage. The next-state function is a combinational function that, given the inputs and the current state, determines the next state of the system.\nThere are two types of FSMs: Moore Machine: The output depends only on the current state. Outputs change synchronously with state transitions.\nMealy Machine: The output depends on both the current state and the current inputs. Outputs can change asynchronously with respect to state transitions since the inputs can change at any time. This appendix has assumed an edge-triggered clocking methodology, primarily because it is simpler to understand and explain. If we assume that all clocks arrive at the same time, we are guaranteed that a system with edge-triggered registers between blocks of combinational logic can operate correctly without races as long as we make the clock long enough. A race occurs when the contents of a state element depend on the relative speed of different logic elements. One additional complication that must be considered is clock skew. Clock skew is the difference in absolute time between when two state elements see a clock edge. Clock skew arises because the clock signal will often use multiple paths, with slightly different delays, to reach different state elements. Designers reduce clock skew problems by carefully routing clock signals to minimize the difference in arrival times.\nEdge-triggered designs have two primary drawbacks: they require extra logic, and they are sometimes slower. An alternative to use is level-sensitive clocking, where state changes occur at either high or low clock levels. Unlike edge-sensitive clocking, where state changes occur instantaneously, level-sensitive clocking can result in state changes at any time during the clock signal. Because of this non-instantaneous change in state, races can occur more easily. To ensure that a level-sensitive design will also work correctly if the clock is slow enough, designers use two-phase clocking: Two-phase clocking is a scheme that makes use of two non-overlapping clock signals. Since the two clocks are non-overlapping, at most one of the clock signals is high at any given time. We can use these clocks to build a system that contains level-sensitive latches but is free from any race conditions, just as the edge-triggered designs were.\nOne simple way to design such a system is to alternate the use of latches that are open on with latches that are open on . Because both clocks are not asserted simultaneously, a race cannot occur. Field-programmable devices are ICs containing combinational logic, and possible memory devices, that are configurable by the end user. FPDs generally fall into two categories: Programmable Logic Devices (PLDs): Devices that can be programmed only once. PLDs are generally simpler and smaller than FPGAs.\n<br><a data-tooltip-position=\"top\" aria-label=\"Field-Programmable Gate Array\" data-href=\"Field-Programmable Gate Array\" href=\"https://emujakic.github.io/TechKB/textbooks/field-programmable-gate-array.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Field-Programmable Gate Arrays</a> (FPGAs): A more complex architecture with a matrix of programmable logic blocks. FPGAs can be programmed numerous times and may contain flip-flops. D. A. Patterson and J. L. Hennessy, Computer Organization and Design RISC-V Edition: The Hardware Software Interface. Amsterdam: Morgan Kaufmann, 2021.\n","aliases":[],"inlineTags":[],"frontmatterTags":["#textbook"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Textbook Summary: Computer Organization and Design RISC-V Edition","level":1,"id":"Textbook_Summary_Computer_Organization_and_Design_RISC-V_Edition_0"},{"heading":"Author(s):","level":3,"id":"Author(s)_0"},{"heading":"Introduction","level":2,"id":"Introduction_0"},{"heading":"Flashcard Deck","level":2,"id":"Flashcard_Deck_0"},{"heading":"Ch.2 Instructions: Language of the Computer","level":2,"id":"Ch.2_Instructions_Language_of_the_Computer_0"},{"heading":"Ch.3 Arithmetic for Computers","level":2,"id":"Ch.3_Arithmetic_for_Computers_0"},{"heading":"Ch.4 The Processor","level":2,"id":"Ch.4_The_Processor_0"},{"heading":"Ch.5 Large and Fast: Exploiting Memory Hierarchy","level":2,"id":"Ch.5_Large_and_Fast_Exploiting_Memory_Hierarchy_0"},{"heading":"Ch.6 Parallel Processors from Client to Cloud","level":2,"id":"Ch.6_Parallel_Processors_from_Client_to_Cloud_0"},{"heading":"Appendix A: The Basics of Logic Design","level":2,"id":"Appendix_A_The_Basics_of_Logic_Design_0"},{"heading":"References","level":2,"id":"References_0"}],"links":[".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/mean.html#_0","notes/math/mean.html#_0",".html",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/mode.html#_0",".html",".html",".html","notes/math/associative-property.html#_0",".html","notes/math/mean.html#_0","notes/math/mean.html#_0",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/range.html#_0",".html",".html",".html",".html",".html",".html",".html","notes/math/mode.html#_0","textbooks/field-programmable-gate-array.html",".html",".html",".html",".html","notes/math/commutative-property.html#_0",".html",".html","notes/math/commutative-property.html#_0","notes/math/associative-property.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","textbooks/field-programmable-gate-array.html"],"author":"Ernad Mujakic","coverImageURL":"https://emujakic.github.io/TechKB/HTML/resources/multiplicationhardware-1.png","fullURL":"https://emujakic.github.io/TechKB/textbooks/computer-organization-and-design-risc-v-edition-summary.html","pathToRoot":"..","attachments":["resources/multiplicationhardware-1.png","resources/multiplierparalleltree.png","resources/divisionhardware-1.png","resources/riscvfloatingpoint.png","resources/riscvdoubleprecision-1.png","resources/ieee754.png","resources/floatingpointadditionhardware-1.png","resources/risc-vdatapath.png","resources/riscvdatapath2-1.png","resources/alutruthtable.png","resources/riscvinstructionformats.png","resources/riscvcontrolunit-1.png","resources/riscvinstructionformatcontrol.png","resources/riscpipeline.png","resources/riscvpipeline2.png","resources/risvpipelinecontrol.png","resources/forwardingalu.png","resources/hazarddetectionunit.png","resources/riscvexceptions.png","resources/ringtop.png","resources/crossbarnetwork.png","resources/designpatternsai.png","resources/gates.png","resources/srlatch.png","resources/dlatch.png","resources/dflipflop.png"],"createdTime":1755654690580,"modifiedTime":1762618313844,"sourceSize":206195,"sourcePath":"TEXTBOOKS/Computer Organization and Design RISC-V Edition Summary.md","exportPath":"textbooks/computer-organization-and-design-risc-v-edition-summary.html","showInTree":true,"treeOrder":28,"backlinks":[],"type":"markdown"},"index.html":{"title":"Table of Contents","icon":"","description":"<a href=\"https://emujakic.github.io/TechKB/textbooks/computer-organization-and-design-risc-v-edition-summary.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"55\" origin-text=\"Computer Organization and Design RISC-V Edition Summary\" class=\"internal-link virtual-link-a\">Computer Organization and Design RISC-V Edition Summary</a><br><a href=\"https://emujakic.github.io/TechKB/textbooks/artificial-intelligence-a-modern-approach-summary.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"49\" origin-text=\"Artificial Intelligence A Modern Approach Summary\" class=\"internal-link virtual-link-a\">Artificial Intelligence A Modern Approach Summary</a><br><a href=\"https://emujakic.github.io/TechKB/notes/math/mean.html#_0\" target=\"_self\" rel=\"noopener noreferrer\" from=\"0\" to=\"4\" origin-text=\"Mean\" class=\"internal-link virtual-link-a\">Mean</a>Number of Notes Total: 26\n<br><a data-href=\"Computer Architecture\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Computer Architecture</a>\n<br><a data-href=\"Digital Logic Design\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Digital Logic Design</a> Boolean Algebra <br><a data-href=\"Operating Systems\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Operating Systems</a>\nEmbedded Systems\nComputer Networks <br><a data-href=\"Programming Basics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Programming Basics</a>\n<br><a data-href=\"Data Structures and Algorithms\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Data Structures and Algorithms</a>\n<br><a data-href=\"Software Engineering\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Software Engineering</a>\n<br><a data-href=\"Web Development\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Web Development</a>\n<br><a data-href=\"Database Systems\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Database Systems</a>\n<br><a data-href=\"Theory of Computation\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Theory of Computation</a> <br><a data-href=\"Machine Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Machine Learning</a> Supervised Learning\nUnsupervised Learning\nReinforcement Learning <br><a data-href=\"Deep Learning\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Deep Learning</a> <br><a data-href=\"Neural Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Neural Network</a>\n<br><a data-href=\"Convolutional Neural Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Convolutional Neural Network</a>\n<br><a data-href=\"Recurrent Neural Network\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Recurrent Neural Network</a>\nSelf-Organizing Maps AI Tools <br><a data-href=\"PyTorch\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">PyTorch</a>\n<br><a data-href=\"Scikit-Learn\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Scikit-Learn</a>\n<br><a data-href=\"OpenCV\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">OpenCV</a>\n<br><a data-href=\"Natural Language Processing\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Natural Language Processing</a>\n<br><a data-href=\"Computer Vision\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Computer Vision</a>\n<br><a data-href=\"Robotics\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Robotics</a> AI Algorithms Genetic Algorithms &amp; Evolutionary Methods\nBayesian Methods\nGraph Algorithms Data Mining Data Preprocessing\nData Exploration\nData Mining Techniques <br><a data-href=\"Algebra\" href=\"https://emujakic.github.io/TechKB/.html\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Algebra</a>\nGeometry\nTrigonometry\nCalculus\n<br><a data-href=\"Probability\" href=\"https://emujakic.github.io/TechKB/notes/math/probability.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Probability</a>\nStatistics\nSet Theory\nLogics <br><a data-href=\"Propositional Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/propositional-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">Propositional Logic</a>\n<br><a data-href=\"First-Order Logic\" href=\"https://emujakic.github.io/TechKB/notes/math/first-order-logic.html#_0\" class=\"internal-link\" target=\"_self\" rel=\"noopener nofollow\">First-Order Logic</a>\nPredicate Logic\nTemporal Logic\nModal Logic Linear Algebra\nDiscrete Mathematics Basic Electrical Concepts\nOhm's Law and Kirchhoff's Laws\nCircuit Analysis\nElectromagnetism\nAnalog Electronics\nDigital Electronics\n","aliases":[],"inlineTags":[],"frontmatterTags":["#linker-exclude"],"headers":[{"heading":"","level":1,"id":"_0"},{"heading":"Table of Contents","level":1,"id":"Table_of_Contents_0"},{"heading":"Recently Updated","level":9,"id":"Recently_Updated_0"},{"heading":"Computer Engineering","level":2,"id":"Computer_Engineering_0"},{"heading":"Computer Science","level":2,"id":"Computer_Science_0"},{"heading":"AI","level":2,"id":"AI_0"},{"heading":"Mathematics","level":2,"id":"Mathematics_0"},{"heading":"Electrical Engineering","level":2,"id":"Electrical_Engineering_0"}],"links":["textbooks/computer-organization-and-design-risc-v-edition-summary.html#_0","textbooks/artificial-intelligence-a-modern-approach-summary.html#_0","notes/math/mean.html#_0",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html",".html","notes/math/probability.html#_0","notes/math/propositional-logic.html#_0","notes/math/first-order-logic.html#_0"],"author":"Ernad Mujakic","coverImageURL":"","fullURL":"https://emujakic.github.io/TechKB/index.html","pathToRoot":".","attachments":[],"createdTime":1753993773434,"modifiedTime":1757982273302,"sourceSize":1853,"sourcePath":"Index.md","exportPath":"index.html","showInTree":true,"treeOrder":29,"backlinks":[],"type":"markdown"}},"fileInfo":{"notes/math/first-order-logic.html":{"createdTime":1756478536137,"modifiedTime":1756492064326,"sourceSize":1427,"sourcePath":"NOTES/Math/First-Order Logic.md","exportPath":"notes/math/first-order-logic.html","showInTree":true,"treeOrder":8,"backlinks":["index.html","notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/standard-deviation.html":{"createdTime":1752158879614,"modifiedTime":1756435032494,"sourceSize":2852,"sourcePath":"NOTES/Math/Standard Deviation.md","exportPath":"notes/math/standard-deviation.html","showInTree":true,"treeOrder":23,"backlinks":["notes/math/outlier.html","notes/math/variance.html"],"type":"markdown","data":null},"notes/math/commutative-property.html":{"createdTime":1753041273100,"modifiedTime":1754247519350,"sourceSize":2732,"sourcePath":"NOTES/Math/Commutative Property.md","exportPath":"notes/math/commutative-property.html","showInTree":true,"treeOrder":6,"backlinks":["notes/math/associative-property.html","notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/variance.html":{"createdTime":1752165687104,"modifiedTime":1756435151010,"sourceSize":6067,"sourcePath":"NOTES/Math/Variance.md","exportPath":"notes/math/variance.html","showInTree":true,"treeOrder":25,"backlinks":["notes/math/least-squares.html","notes/math/outlier.html","notes/math/standard-deviation.html"],"type":"markdown","data":null},"notes/math/transitive-property.html":{"createdTime":1753469739589,"modifiedTime":1755694339571,"sourceSize":3732,"sourcePath":"NOTES/Math/Transitive Property.md","exportPath":"notes/math/transitive-property.html","showInTree":true,"treeOrder":24,"backlinks":["notes/math/propositional-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/probability.html":{"createdTime":1751495555242,"modifiedTime":1756912870248,"sourceSize":10595,"sourcePath":"NOTES/Math/Probability.md","exportPath":"notes/math/probability.html","showInTree":true,"treeOrder":18,"backlinks":["index.html","notes/math/binary-data.html","notes/math/mean.html","notes/math/variance.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/range.html":{"createdTime":1752606554931,"modifiedTime":1756435173717,"sourceSize":1544,"sourcePath":"NOTES/Math/Range.md","exportPath":"notes/math/range.html","showInTree":true,"treeOrder":22,"backlinks":["notes/math/euclidean-distance.html","notes/math/manhattan-distance.html","notes/math/mean.html","notes/math/outlier.html","notes/math/standard-deviation.html","notes/math/variance.html"],"type":"markdown","data":null},"notes/math/quartile.html":{"createdTime":1751928764242,"modifiedTime":1756435200221,"sourceSize":4048,"sourcePath":"NOTES/Math/Quartile.md","exportPath":"notes/math/quartile.html","showInTree":true,"treeOrder":21,"backlinks":["notes/math/mean.html","notes/math/median.html","notes/math/outlier.html","notes/math/quantile.html","notes/math/range.html","notes/math/standard-deviation.html"],"type":"markdown","data":null},"notes/math/quantile.html":{"createdTime":1752697090804,"modifiedTime":1756435351475,"sourceSize":3483,"sourcePath":"NOTES/Math/Quantile.md","exportPath":"notes/math/quantile.html","showInTree":true,"treeOrder":20,"backlinks":["notes/math/quartile.html"],"type":"markdown","data":null},"notes/math/propositional-logic.html":{"createdTime":1754173984748,"modifiedTime":1757260326000,"sourceSize":30125,"sourcePath":"NOTES/Math/Propositional Logic.md","exportPath":"notes/math/propositional-logic.html","showInTree":true,"treeOrder":19,"backlinks":["index.html","notes/math/associative-property.html","notes/math/first-order-logic.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/outlier.html":{"createdTime":1752013301145,"modifiedTime":1756435404209,"sourceSize":8379,"sourcePath":"NOTES/Math/Outlier.md","exportPath":"notes/math/outlier.html","showInTree":true,"treeOrder":17,"backlinks":["notes/math/euclidean-distance.html","notes/math/least-squares.html","notes/math/manhattan-distance.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/quantile.html","notes/math/quartile.html","notes/math/range.html","notes/math/standard-deviation.html"],"type":"markdown","data":null},"notes/math/ordinal-data.html":{"createdTime":1751919439086,"modifiedTime":1754247549994,"sourceSize":2402,"sourcePath":"NOTES/Math/Ordinal Data.md","exportPath":"notes/math/ordinal-data.html","showInTree":true,"treeOrder":16,"backlinks":["notes/math/measure-of-central-tendency.html","notes/math/nominal-data.html","textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"notes/math/nominal-data.html":{"createdTime":1751914187819,"modifiedTime":1756434962714,"sourceSize":1919,"sourcePath":"NOTES/Math/Nominal Data.md","exportPath":"notes/math/nominal-data.html","showInTree":true,"treeOrder":15,"backlinks":["notes/math/binary-data.html","notes/math/measure-of-central-tendency.html","notes/math/ordinal-data.html"],"type":"markdown","data":null},"notes/math/mode.html":{"createdTime":1752009968333,"modifiedTime":1756435446906,"sourceSize":1719,"sourcePath":"NOTES/Math/Mode.md","exportPath":"notes/math/mode.html","showInTree":true,"treeOrder":14,"backlinks":["notes/math/binary-data.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/nominal-data.html","notes/math/ordinal-data.html"],"type":"markdown","data":null},"notes/math/median.html":{"createdTime":1751927785580,"modifiedTime":1754247536481,"sourceSize":3023,"sourcePath":"NOTES/Math/Median.md","exportPath":"notes/math/median.html","showInTree":true,"treeOrder":13,"backlinks":["notes/math/binary-data.html","notes/math/mean.html","notes/math/measure-of-central-tendency.html","notes/math/mode.html","notes/math/nominal-data.html","notes/math/ordinal-data.html","notes/math/quantile.html","notes/math/quartile.html"],"type":"markdown","data":null},"notes/math/measure-of-central-tendency.html":{"createdTime":1751847846892,"modifiedTime":1754247539565,"sourceSize":3814,"sourcePath":"NOTES/Math/Measure of Central Tendency.md","exportPath":"notes/math/measure-of-central-tendency.html","showInTree":true,"treeOrder":12,"backlinks":["notes/math/mean.html","notes/math/median.html","notes/math/mode.html","notes/math/probability.html","notes/math/quantile.html","notes/math/variance.html"],"type":"markdown","data":null},"notes/math/mean.html":{"createdTime":1751668570756,"modifiedTime":1757260326000,"sourceSize":10021,"sourcePath":"NOTES/Math/Mean.md","exportPath":"notes/math/mean.html","showInTree":true,"treeOrder":11,"backlinks":["notes/math/binary-data.html","notes/math/measure-of-central-tendency.html","notes/math/median.html","notes/math/mode.html","notes/math/nominal-data.html","notes/math/outlier.html","notes/math/probability.html","notes/math/quantile.html","notes/math/range.html","notes/math/standard-deviation.html","notes/math/variance.html","textbooks/computer-organization-and-design-risc-v-edition-summary.html"],"type":"markdown","data":null},"notes/math/manhattan-distance.html":{"createdTime":1753987116983,"modifiedTime":1754247526013,"sourceSize":3486,"sourcePath":"NOTES/Math/Manhattan Distance.md","exportPath":"notes/math/manhattan-distance.html","showInTree":true,"treeOrder":10,"backlinks":["notes/math/euclidean-distance.html","notes/math/outlier.html"],"type":"markdown","data":null},"notes/math/least-squares.html":{"createdTime":1753105505921,"modifiedTime":1754247532104,"sourceSize":6451,"sourcePath":"NOTES/Math/Least Squares.md","exportPath":"notes/math/least-squares.html","showInTree":true,"treeOrder":9,"backlinks":["notes/math/euclidean-distance.html","notes/math/variance.html"],"type":"markdown","data":null},"notes/math/associative-property.html":{"createdTime":1752965745243,"modifiedTime":1756434996484,"sourceSize":2549,"sourcePath":"NOTES/Math/Associative Property.md","exportPath":"notes/math/associative-property.html","showInTree":true,"treeOrder":4,"backlinks":["notes/math/commutative-property.html","notes/math/propositional-logic.html"],"type":"markdown","data":null},"notes/math/euclidean-distance.html":{"createdTime":1752772872723,"modifiedTime":1756435583317,"sourceSize":6032,"sourcePath":"NOTES/Math/Euclidean Distance.md","exportPath":"notes/math/euclidean-distance.html","showInTree":true,"treeOrder":7,"backlinks":["notes/math/least-squares.html","notes/math/manhattan-distance.html","notes/math/median.html","notes/math/outlier.html"],"type":"markdown","data":null},"notes/math/binary-data.html":{"createdTime":1752017585071,"modifiedTime":1754445468801,"sourceSize":4392,"sourcePath":"NOTES/Math/Binary Data.md","exportPath":"notes/math/binary-data.html","showInTree":true,"treeOrder":5,"backlinks":["notes/math/nominal-data.html","notes/math/outlier.html"],"type":"markdown","data":null},"notes/ai/turing-test.html":{"createdTime":1751502135746,"modifiedTime":1756435642674,"sourceSize":4532,"sourcePath":"NOTES/AI/Turing Test.md","exportPath":"notes/ai/turing-test.html","showInTree":true,"treeOrder":2,"backlinks":["textbooks/artificial-intelligence-a-modern-approach-summary.html"],"type":"markdown","data":null},"textbooks/artificial-intelligence-a-modern-approach-summary.html":{"createdTime":1751236285335,"modifiedTime":1761507447000,"sourceSize":183434,"sourcePath":"TEXTBOOKS/Artificial Intelligence A Modern Approach Summary.md","exportPath":"textbooks/artificial-intelligence-a-modern-approach-summary.html","showInTree":true,"treeOrder":27,"backlinks":[],"type":"markdown","data":null},"textbooks/computer-organization-and-design-risc-v-edition-summary.html":{"createdTime":1755654690580,"modifiedTime":1762618313844,"sourceSize":206195,"sourcePath":"TEXTBOOKS/Computer Organization and Design RISC-V Edition Summary.md","exportPath":"textbooks/computer-organization-and-design-risc-v-edition-summary.html","showInTree":true,"treeOrder":28,"backlinks":[],"type":"markdown","data":null},"index.html":{"createdTime":1753993773434,"modifiedTime":1757982273302,"sourceSize":1853,"sourcePath":"Index.md","exportPath":"index.html","showInTree":true,"treeOrder":29,"backlinks":[],"type":"markdown","data":null},"site-lib/html/custom-head-content-content.html":{"createdTime":1754358392671,"modifiedTime":1756842815000,"sourceSize":566,"sourcePath":"HTML/site-lib/html/custom.html","exportPath":"site-lib/html/custom-head-content-content.html","showInTree":false,"treeOrder":0,"backlinks":[],"type":"html","data":null},"site-lib/fonts/94f2f163d4b698242fef.otf":{"createdTime":1762618333301,"modifiedTime":1762618333301,"sourceSize":66800,"sourcePath":"","exportPath":"site-lib/fonts/94f2f163d4b698242fef.otf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/72505e6a122c6acd5471.woff2":{"createdTime":1762618333302,"modifiedTime":1762618333302,"sourceSize":104232,"sourcePath":"","exportPath":"site-lib/fonts/72505e6a122c6acd5471.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/2d5198822ab091ce4305.woff2":{"createdTime":1762618333302,"modifiedTime":1762618333302,"sourceSize":104332,"sourcePath":"","exportPath":"site-lib/fonts/2d5198822ab091ce4305.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/c8ba52b05a9ef10f4758.woff2":{"createdTime":1762618333301,"modifiedTime":1762618333301,"sourceSize":98868,"sourcePath":"","exportPath":"site-lib/fonts/c8ba52b05a9ef10f4758.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cb10ffd7684cd9836a05.woff2":{"createdTime":1762618333302,"modifiedTime":1762618333302,"sourceSize":106876,"sourcePath":"","exportPath":"site-lib/fonts/cb10ffd7684cd9836a05.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/293fd13dbca5a3e450ef.woff2":{"createdTime":1762618333302,"modifiedTime":1762618333302,"sourceSize":105924,"sourcePath":"","exportPath":"site-lib/fonts/293fd13dbca5a3e450ef.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/085cb93e613ba3d40d2b.woff2":{"createdTime":1762618333303,"modifiedTime":1762618333303,"sourceSize":112184,"sourcePath":"","exportPath":"site-lib/fonts/085cb93e613ba3d40d2b.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/b5f0f109bc88052d4000.woff2":{"createdTime":1762618333302,"modifiedTime":1762618333302,"sourceSize":105804,"sourcePath":"","exportPath":"site-lib/fonts/b5f0f109bc88052d4000.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cbe0ae49c52c920fd563.woff2":{"createdTime":1762618333304,"modifiedTime":1762618333304,"sourceSize":106108,"sourcePath":"","exportPath":"site-lib/fonts/cbe0ae49c52c920fd563.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/535a6cf662596b3bd6a6.woff2":{"createdTime":1762618333304,"modifiedTime":1762618333304,"sourceSize":111708,"sourcePath":"","exportPath":"site-lib/fonts/535a6cf662596b3bd6a6.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/70cc7ff27245e82ad414.ttf":{"createdTime":1762618333307,"modifiedTime":1762618333307,"sourceSize":192740,"sourcePath":"","exportPath":"site-lib/fonts/70cc7ff27245e82ad414.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/454577c22304619db035.ttf":{"createdTime":1762618333307,"modifiedTime":1762618333307,"sourceSize":161376,"sourcePath":"","exportPath":"site-lib/fonts/454577c22304619db035.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/52ac8f3034507f1d9e53.ttf":{"createdTime":1762618333307,"modifiedTime":1762618333307,"sourceSize":191568,"sourcePath":"","exportPath":"site-lib/fonts/52ac8f3034507f1d9e53.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/05b618077343fbbd92b7.ttf":{"createdTime":1762618333307,"modifiedTime":1762618333307,"sourceSize":155288,"sourcePath":"","exportPath":"site-lib/fonts/05b618077343fbbd92b7.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2":{"createdTime":1762618333285,"modifiedTime":1762618333285,"sourceSize":7876,"sourcePath":"","exportPath":"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/media/6155340132a851f6089e.svg":{"createdTime":1762618333286,"modifiedTime":1762618333286,"sourceSize":315,"sourcePath":"","exportPath":"site-lib/media/6155340132a851f6089e.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/media/2308ab1944a6bfa5c5b8.svg":{"createdTime":1762618333286,"modifiedTime":1762618333286,"sourceSize":278,"sourcePath":"","exportPath":"site-lib/media/2308ab1944a6bfa5c5b8.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/html/file-tree-content.html":{"createdTime":1762618333550,"modifiedTime":1762618333550,"sourceSize":14561,"sourcePath":"","exportPath":"site-lib/html/file-tree-content.html","showInTree":false,"treeOrder":0,"backlinks":[],"type":"html","data":null},"site-lib/scripts/webpage.js":{"createdTime":1762570772738,"modifiedTime":1762570772738,"sourceSize":110729,"sourcePath":"","exportPath":"site-lib/scripts/webpage.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/media/favicon.png":{"createdTime":1762618333186,"modifiedTime":1762618333186,"sourceSize":1105,"sourcePath":"","exportPath":"site-lib/media/favicon.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/styles/snippets.css":{"createdTime":1762618333295,"modifiedTime":1762618333295,"sourceSize":579,"sourcePath":"","exportPath":"site-lib/styles/snippets.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/obsidian.css":{"createdTime":1762618333352,"modifiedTime":1762618333352,"sourceSize":198273,"sourcePath":"","exportPath":"site-lib/styles/obsidian.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/theme.css":{"createdTime":1762570772958,"modifiedTime":1762570772958,"sourceSize":2121232,"sourcePath":"","exportPath":"site-lib/styles/theme.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/global-variable-styles.css":{"createdTime":1762618333244,"modifiedTime":1762618333244,"sourceSize":305,"sourcePath":"","exportPath":"site-lib/styles/global-variable-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/supported-plugins.css":{"createdTime":1762618333294,"modifiedTime":1762618333294,"sourceSize":2020,"sourcePath":"","exportPath":"site-lib/styles/supported-plugins.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/main-styles.css":{"createdTime":1762570772753,"modifiedTime":1762570772753,"sourceSize":19521,"sourcePath":"","exportPath":"site-lib/styles/main-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"resources/multiplicationhardware-1.png":{"createdTime":1757948129000,"modifiedTime":1757948129000,"sourceSize":31906,"sourcePath":"RESOURCES/MultiplicationHardware 1.png","exportPath":"resources/multiplicationhardware-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/multiplierparalleltree.png":{"createdTime":1757949374000,"modifiedTime":1757949374000,"sourceSize":56797,"sourcePath":"RESOURCES/MultiplierParallelTree.png","exportPath":"resources/multiplierparalleltree.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/divisionhardware-1.png":{"createdTime":1757950148000,"modifiedTime":1757950148000,"sourceSize":33255,"sourcePath":"RESOURCES/DivisionHardware 1.png","exportPath":"resources/divisionhardware-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvfloatingpoint.png":{"createdTime":1758035648000,"modifiedTime":1758035648000,"sourceSize":22555,"sourcePath":"RESOURCES/riscvFloatingPoint.png","exportPath":"resources/riscvfloatingpoint.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvdoubleprecision-1.png":{"createdTime":1758036055000,"modifiedTime":1758036055000,"sourceSize":48903,"sourcePath":"RESOURCES/riscvDoublePrecision 1.png","exportPath":"resources/riscvdoubleprecision-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/ieee754.png":{"createdTime":1758037265000,"modifiedTime":1758037265000,"sourceSize":47549,"sourcePath":"RESOURCES/ieee754.png","exportPath":"resources/ieee754.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/floatingpointadditionhardware-1.png":{"createdTime":1758040590000,"modifiedTime":1758040590000,"sourceSize":94138,"sourcePath":"RESOURCES/floatingPointAdditionHardware 1.png","exportPath":"resources/floatingpointadditionhardware-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/risc-vdatapath.png":{"createdTime":1759075924000,"modifiedTime":1759075924000,"sourceSize":92028,"sourcePath":"RESOURCES/risc-vDatapath.png","exportPath":"resources/risc-vdatapath.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvdatapath2-1.png":{"createdTime":1759336867000,"modifiedTime":1759336867000,"sourceSize":117693,"sourcePath":"RESOURCES/riscvDatapath2 1.png","exportPath":"resources/riscvdatapath2-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/alutruthtable.png":{"createdTime":1759336373000,"modifiedTime":1759336373000,"sourceSize":71647,"sourcePath":"RESOURCES/aluTruthTable.png","exportPath":"resources/alutruthtable.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvinstructionformats.png":{"createdTime":1759336789000,"modifiedTime":1759336789000,"sourceSize":80467,"sourcePath":"RESOURCES/riscVinstructionFormats.png","exportPath":"resources/riscvinstructionformats.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvcontrolunit-1.png":{"createdTime":1759418299000,"modifiedTime":1759418299000,"sourceSize":125310,"sourcePath":"RESOURCES/riscVControlUnit 1.png","exportPath":"resources/riscvcontrolunit-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvinstructionformatcontrol.png":{"createdTime":1759418456000,"modifiedTime":1759418456000,"sourceSize":30543,"sourcePath":"RESOURCES/riscVInstructionFormatControl.png","exportPath":"resources/riscvinstructionformatcontrol.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscpipeline.png":{"createdTime":1759510497000,"modifiedTime":1759510497000,"sourceSize":91132,"sourcePath":"RESOURCES/riscpipeline.png","exportPath":"resources/riscpipeline.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvpipeline2.png":{"createdTime":1759511484000,"modifiedTime":1759511484000,"sourceSize":58710,"sourcePath":"RESOURCES/riscvpipeline2.png","exportPath":"resources/riscvpipeline2.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/risvpipelinecontrol.png":{"createdTime":1759513724000,"modifiedTime":1759513724000,"sourceSize":31274,"sourcePath":"RESOURCES/risvpipelinecontrol.png","exportPath":"resources/risvpipelinecontrol.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/forwardingalu.png":{"createdTime":1759680504000,"modifiedTime":1759680504000,"sourceSize":57210,"sourcePath":"RESOURCES/forwardingALU.png","exportPath":"resources/forwardingalu.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/hazarddetectionunit.png":{"createdTime":1759682560000,"modifiedTime":1759682560000,"sourceSize":97121,"sourcePath":"RESOURCES/hazarddetectionUnit.png","exportPath":"resources/hazarddetectionunit.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/riscvexceptions.png":{"createdTime":1759768658000,"modifiedTime":1759768658000,"sourceSize":89268,"sourcePath":"RESOURCES/riscVExceptions.png","exportPath":"resources/riscvexceptions.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/utilityofmoney.png":{"createdTime":1760372244000,"modifiedTime":1760372244000,"sourceSize":10718,"sourcePath":"RESOURCES/utilityOfMoney.png","exportPath":"resources/utilityofmoney.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/decisionnetwork-1.png":{"createdTime":1760637253000,"modifiedTime":1760637253000,"sourceSize":64406,"sourcePath":"RESOURCES/decisionNetwork 1.png","exportPath":"resources/decisionnetwork-1.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/pasted-image-20250708093049.png":{"createdTime":1751985050065,"modifiedTime":1751985049041,"sourceSize":33853,"sourcePath":"RESOURCES/Pasted image 20250708093049.png","exportPath":"resources/pasted-image-20250708093049.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/highvslowstd.png":{"createdTime":1752162585317,"modifiedTime":1752162585318,"sourceSize":27029,"sourcePath":"RESOURCES/HighVsLowSTD.png","exportPath":"resources/highvslowstd.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/pasted-image-20250708171735.png":{"createdTime":1752013056598,"modifiedTime":1752013055594,"sourceSize":23535,"sourcePath":"RESOURCES/Pasted image 20250708171735.png","exportPath":"resources/pasted-image-20250708171735.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/linearregression.png":{"createdTime":1753106412811,"modifiedTime":1753106412812,"sourceSize":19594,"sourcePath":"RESOURCES/linearRegression.png","exportPath":"resources/linearregression.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/rss.xml":{"createdTime":1762618335640,"modifiedTime":1762618335640,"sourceSize":1036370,"sourcePath":"","exportPath":"site-lib/rss.xml","showInTree":false,"treeOrder":0,"backlinks":[],"type":"other","data":null},"resources/ringtop.png":{"createdTime":1762027459000,"modifiedTime":1762027459000,"sourceSize":3826,"sourcePath":"RESOURCES/ringTop.png","exportPath":"resources/ringtop.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/crossbarnetwork.png":{"createdTime":1762111830000,"modifiedTime":1762111830000,"sourceSize":34946,"sourcePath":"RESOURCES/crossbarNetwork.png","exportPath":"resources/crossbarnetwork.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/designpatternsai.png":{"createdTime":1762199008000,"modifiedTime":1762199008000,"sourceSize":58667,"sourcePath":"RESOURCES/designPatternsAI.png","exportPath":"resources/designpatternsai.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/gates.png":{"createdTime":1762279312000,"modifiedTime":1762279312000,"sourceSize":5576,"sourcePath":"RESOURCES/gates.png","exportPath":"resources/gates.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/srlatch.png":{"createdTime":1762456178000,"modifiedTime":1762456178000,"sourceSize":16679,"sourcePath":"RESOURCES/srLatch.png","exportPath":"resources/srlatch.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/dlatch.png":{"createdTime":1762457347000,"modifiedTime":1762457347000,"sourceSize":18714,"sourcePath":"RESOURCES/dlatch.png","exportPath":"resources/dlatch.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"resources/dflipflop.png":{"createdTime":1762537842000,"modifiedTime":1762537842000,"sourceSize":11927,"sourcePath":"RESOURCES/dflipFlop.png","exportPath":"resources/dflipflop.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/fonts/mathjax_zero.woff":{"createdTime":1762618333282,"modifiedTime":1762618333282,"sourceSize":1368,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_zero.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":34160,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-bold.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":34464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-italic.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":19360,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-italic.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":20832,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-bolditalic.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":19776,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-bolditalic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size1-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":5792,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size1-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size2-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":5464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size2-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size3-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":3244,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size3-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size4-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":5148,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size4-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_ams-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":40808,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_ams-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-regular.woff":{"createdTime":1762618333283,"modifiedTime":1762618333283,"sourceSize":9600,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-bold.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":9908,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-regular.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":21480,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-bold.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":22340,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-regular.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":12660,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-bold.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":15944,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-italic.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":14628,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_script-regular.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":11852,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_script-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_typewriter-regular.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":17604,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_typewriter-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-regular.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":1136,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-bold.woff":{"createdTime":1762618333284,"modifiedTime":1762618333284,"sourceSize":1116,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null}},"sourceToTarget":{"NOTES/Math/First-Order Logic.md":"notes/math/first-order-logic.html","NOTES/Math/Standard Deviation.md":"notes/math/standard-deviation.html","NOTES/Math/Commutative Property.md":"notes/math/commutative-property.html","NOTES/Math/Variance.md":"notes/math/variance.html","NOTES/Math/Transitive Property.md":"notes/math/transitive-property.html","NOTES/Math/Probability.md":"notes/math/probability.html","NOTES/Math/Range.md":"notes/math/range.html","NOTES/Math/Quartile.md":"notes/math/quartile.html","NOTES/Math/Quantile.md":"notes/math/quantile.html","NOTES/Math/Propositional Logic.md":"notes/math/propositional-logic.html","NOTES/Math/Outlier.md":"notes/math/outlier.html","NOTES/Math/Ordinal Data.md":"notes/math/ordinal-data.html","NOTES/Math/Nominal Data.md":"notes/math/nominal-data.html","NOTES/Math/Mode.md":"notes/math/mode.html","NOTES/Math/Median.md":"notes/math/median.html","NOTES/Math/Measure of Central Tendency.md":"notes/math/measure-of-central-tendency.html","NOTES/Math/Mean.md":"notes/math/mean.html","NOTES/Math/Manhattan Distance.md":"notes/math/manhattan-distance.html","NOTES/Math/Least Squares.md":"notes/math/least-squares.html","NOTES/Math/Associative Property.md":"notes/math/associative-property.html","NOTES/Math/Euclidean Distance.md":"notes/math/euclidean-distance.html","NOTES/Math/Binary Data.md":"notes/math/binary-data.html","NOTES/AI/Turing Test.md":"notes/ai/turing-test.html","TEXTBOOKS/Artificial Intelligence A Modern Approach Summary.md":"textbooks/artificial-intelligence-a-modern-approach-summary.html","TEXTBOOKS/Computer Organization and Design RISC-V Edition Summary.md":"textbooks/computer-organization-and-design-risc-v-edition-summary.html","Index.md":"index.html","HTML/site-lib/html/custom.html":"site-lib/html/custom-head-content-content.html","":"site-lib/rss.xml","RESOURCES/MultiplicationHardware 1.png":"resources/multiplicationhardware-1.png","RESOURCES/MultiplierParallelTree.png":"resources/multiplierparalleltree.png","RESOURCES/DivisionHardware 1.png":"resources/divisionhardware-1.png","RESOURCES/riscvFloatingPoint.png":"resources/riscvfloatingpoint.png","RESOURCES/riscvDoublePrecision 1.png":"resources/riscvdoubleprecision-1.png","RESOURCES/ieee754.png":"resources/ieee754.png","RESOURCES/floatingPointAdditionHardware 1.png":"resources/floatingpointadditionhardware-1.png","RESOURCES/risc-vDatapath.png":"resources/risc-vdatapath.png","RESOURCES/riscvDatapath2 1.png":"resources/riscvdatapath2-1.png","RESOURCES/aluTruthTable.png":"resources/alutruthtable.png","RESOURCES/riscVinstructionFormats.png":"resources/riscvinstructionformats.png","RESOURCES/riscVControlUnit 1.png":"resources/riscvcontrolunit-1.png","RESOURCES/riscVInstructionFormatControl.png":"resources/riscvinstructionformatcontrol.png","RESOURCES/riscpipeline.png":"resources/riscpipeline.png","RESOURCES/riscvpipeline2.png":"resources/riscvpipeline2.png","RESOURCES/risvpipelinecontrol.png":"resources/risvpipelinecontrol.png","RESOURCES/forwardingALU.png":"resources/forwardingalu.png","RESOURCES/hazarddetectionUnit.png":"resources/hazarddetectionunit.png","RESOURCES/riscVExceptions.png":"resources/riscvexceptions.png","RESOURCES/utilityOfMoney.png":"resources/utilityofmoney.png","RESOURCES/decisionNetwork 1.png":"resources/decisionnetwork-1.png","RESOURCES/Pasted image 20250708093049.png":"resources/pasted-image-20250708093049.png","RESOURCES/HighVsLowSTD.png":"resources/highvslowstd.png","RESOURCES/Pasted image 20250708171735.png":"resources/pasted-image-20250708171735.png","RESOURCES/linearRegression.png":"resources/linearregression.png","RESOURCES/ringTop.png":"resources/ringtop.png","RESOURCES/crossbarNetwork.png":"resources/crossbarnetwork.png","RESOURCES/designPatternsAI.png":"resources/designpatternsai.png","RESOURCES/gates.png":"resources/gates.png","RESOURCES/srLatch.png":"resources/srlatch.png","RESOURCES/dlatch.png":"resources/dlatch.png","RESOURCES/dflipFlop.png":"resources/dflipflop.png"},"featureOptions":{"backlinks":{"featureId":"backlinks","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".footer","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Backlinks","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"tags":{"featureId":"tags","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showInlineTags":true,"showFrontmatterTags":true,"info_showInlineTags":{"show":true,"name":"","description":"Show tags defined inside the document at the top of the page.","placeholder":""},"info_showFrontmatterTags":{"show":true,"name":"","description":"Show tags defined in the frontmatter of the document at the top of the page.","placeholder":""}},"alias":{"featureId":"aliases","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Aliases","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"properties":{"featureId":"properties","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Properties","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"info_hideProperties":{"show":true,"name":"","description":"A list of properties to hide from the properties view","placeholder":""}},"fileNavigation":{"featureId":"file-navigation","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"showCustomIcons":false,"showDefaultFolderIcons":false,"showDefaultFileIcons":false,"defaultFolderIcon":"lucide//folder","defaultFileIcon":"lucide//file","defaultMediaIcon":"lucide//file-image","exposeStartingPath":true,"info_showCustomIcons":{"show":true,"name":"","description":"Show custom icons for files and folders","placeholder":""},"info_showDefaultFolderIcons":{"show":true,"name":"","description":"Show a default icon of a folder for every folder in the tree","placeholder":""},"info_showDefaultFileIcons":{"show":true,"name":"","description":"Show a default icon of a file for every file in the tree","placeholder":""},"info_defaultFolderIcon":{"show":true,"name":"","description":"The icon to use for folders. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultFileIcon":{"show":true,"name":"","description":"The icon to use for files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultMediaIcon":{"show":true,"name":"","description":"The icon to use for media files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_exposeStartingPath":{"show":true,"name":"","description":"Whether or not to show the current file in the file tree when the page is first loaded","placeholder":""},"includePath":"site-lib/html/file-tree.html"},"search":{"featureId":"search","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Search...","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"outline":{"featureId":"outline","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Outline","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"startCollapsed":true,"minCollapseDepth":"2","info_startCollapsed":{"show":true,"name":"","description":"Should the outline start collapsed?","placeholder":""},"info_minCollapseDepth":{"show":true,"name":"","description":"Only allow outline items to be collapsed if they are at least this many levels deep in the tree.","placeholder":"","dropdownOptions":{"1":1,"2":2,"No Collapse":100}}},"themeToggle":{"featureId":"theme-toggle","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"graphView":{"featureId":"graph-view","enabled":false,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Graph View","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showOrphanNodes":true,"showAttachments":false,"allowGlobalGraph":true,"allowExpand":true,"attractionForce":1,"linkLength":15,"repulsionForce":80,"centralForce":2,"edgePruning":100,"minNodeRadius":3,"maxNodeRadius":7,"info_showOrphanNodes":{"show":true,"name":"","description":"Show nodes that are not connected to any other nodes.","placeholder":""},"info_showAttachments":{"show":true,"name":"","description":"Show attachments like images and PDFs as nodes in the graph.","placeholder":""},"info_allowGlobalGraph":{"show":true,"name":"","description":"Allow the user to view the global graph of all nodes.","placeholder":""},"info_allowExpand":{"show":true,"name":"","description":"Allow the user to pop-out the graph view to take up the whole screen","placeholder":""},"info_attractionForce":{"show":true,"name":"","description":"How much should linked nodes attract each other? This will make the graph appear more clustered.","placeholder":""},"info_linkLength":{"show":true,"name":"","description":"How long should the links between nodes be? The shorter the links the more connected nodes will cluster together.","placeholder":""},"info_repulsionForce":{"show":true,"name":"","description":"How much should nodes repel each other? This will make disconnected parts more spread out.","placeholder":""},"info_centralForce":{"show":true,"name":"","description":"How much should nodes be attracted to the center? This will make the graph appear more dense and circular.","placeholder":""},"info_edgePruning":{"show":true,"name":"","description":"Edges with a length above this threshold will not be rendered, however they will still contribute to the simulation. This can help large tangled graphs look more organised. Hovering over a node will still display these links.","placeholder":""},"info_minNodeRadius":{"show":true,"name":"","description":"How small should the smallest nodes be? The smaller a node is the less it will attract other nodes.","placeholder":""},"info_maxNodeRadius":{"show":true,"name":"","description":"How large should the largest nodes be? Nodes are sized by how many links they have. The larger a node is the more it will attract other nodes. This can be used to create a good grouping around the most important nodes.","placeholder":""}},"sidebar":{"featureId":"sidebar","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"allowResizing":true,"allowCollapsing":true,"rightDefaultWidth":"19em","leftDefaultWidth":"18em","info_allowResizing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be resized","placeholder":""},"info_allowCollapsing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be collapsed","placeholder":""},"info_rightDefaultWidth":{"show":true,"name":"","description":"The default width of the right sidebar","placeholder":""},"info_leftDefaultWidth":{"show":true,"name":"","description":"The default width of the left sidebar","placeholder":""}},"customHead":{"featureId":"custom-head","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"sourcePath":"HTML/site-lib/html/custom.html","info_sourcePath":{"show":true,"name":"","description":"The local path to the source .html file which will be included.","placeholder":"","fileInputOptions":{"makeRelativeToVault":true,"browseButton":true}},"includePath":"site-lib/html/custom-head.html"},"document":{"featureId":"obsidian-document","enabled":true,"unavailable":false,"alwaysEnabled":true,"hideSettingsButton":false,"allowFoldingLists":true,"allowFoldingHeadings":true,"documentWidth":"40em","info_allowFoldingLists":{"show":true,"name":"","description":"Whether or not to allow lists to be folded","placeholder":""},"info_allowFoldingHeadings":{"show":true,"name":"","description":"Whether or not to allow headings to be folded","placeholder":""},"info_documentWidth":{"show":true,"name":"","description":"The width of the document","placeholder":""}},"rss":{"featureId":"rss","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"siteUrl":"https://emujakic.github.io/TechKB/","authorName":"Ernad Mujakic","info_siteUrl":{"show":true,"name":"","description":"The url that this site will be hosted at","placeholder":"https://example.com/mysite"},"info_authorName":{"show":true,"name":"","description":"The name of the author of the site","placeholder":""}},"linkPreview":{"featureId":"link-preview","enabled":false,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":true}},"modifiedTime":1762618333359,"siteName":"Ernad Mujakic's Knowledge Base","vaultName":"OBSIDIAN KB","exportRoot":"","baseURL":"https://emujakic.github.io/TechKB/","pluginVersion":"1.9.2","themeName":"","bodyClasses":"publish css-settings-manager show-inline-title show-ribbon ss-title-gradient heading-ligatures body-ligatures ordinary-ol ss-links-spectral callout-border-gradient is-focused","hasFavicon":false}